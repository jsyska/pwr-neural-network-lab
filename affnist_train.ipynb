{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# affNIST Classification with Neural Networks\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec3a4e55cc017db3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "### Import all necessary libraries and define constants.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8eff3ef4d59e58b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-19T14:33:50.990661500Z",
     "start_time": "2023-11-19T14:33:49.757082900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import MyDataClass\n",
    "from models import Layer_Dense, Activation_ReLU, Activation_Softmax, Loss_CategoricalCrossentropy, Accuracy_Categorical, Optimizer_Adam, Model\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing\n",
    "### Load and preprocess the affNIST data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5ba4a0f80a1af04"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = MyDataClass()\n",
    "\n",
    "data.load_and_preprocess_affnist('data/processed/affnist')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T14:34:04.636460100Z",
     "start_time": "2023-11-19T14:34:03.162998200Z"
    }
   },
   "id": "d4e0f63ac98873cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Building\n",
    "### Define and compile the neural network model.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "661743bef4c17903"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "model.add(Layer_Dense(1600, 128)) \n",
    "model.add(Activation_ReLU())\n",
    "model.add(Layer_Dense(128, 10)) \n",
    "model.add(Activation_Softmax())\n",
    "\n",
    "model.set(\n",
    "    loss=Loss_CategoricalCrossentropy(),\n",
    "    optimizer=Optimizer_Adam(learning_rate=1e-3, decay=1e-5),\n",
    "    accuracy=Accuracy_Categorical()\n",
    ")\n",
    "\n",
    "model.finalize()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T14:34:06.384418800Z",
     "start_time": "2023-11-19T14:34:06.350980800Z"
    }
   },
   "id": "b18cabe836eb805e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "### Train the model with the affNIST dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f55ba8f81443f5c5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "step: 0, acc: 0.141, loss: 2.303 (data_loss: 2.303, reg_loss: 0.000), lr: 0.001\n",
      "step: 1, acc: 0.094, loss: 2.303 (data_loss: 2.303, reg_loss: 0.000), lr: 0.0009999900000999989\n",
      "step: 2, acc: 0.203, loss: 2.302 (data_loss: 2.302, reg_loss: 0.000), lr: 0.0009999800003999922\n",
      "step: 3, acc: 0.180, loss: 2.302 (data_loss: 2.302, reg_loss: 0.000), lr: 0.000999970000899973\n",
      "step: 4, acc: 0.117, loss: 2.302 (data_loss: 2.302, reg_loss: 0.000), lr: 0.000999960001599936\n",
      "step: 5, acc: 0.125, loss: 2.302 (data_loss: 2.302, reg_loss: 0.000), lr: 0.000999950002499875\n",
      "step: 6, acc: 0.117, loss: 2.302 (data_loss: 2.302, reg_loss: 0.000), lr: 0.000999940003599784\n",
      "step: 7, acc: 0.109, loss: 2.302 (data_loss: 2.302, reg_loss: 0.000), lr: 0.000999930004899657\n",
      "step: 8, acc: 0.125, loss: 2.302 (data_loss: 2.302, reg_loss: 0.000), lr: 0.000999920006399488\n",
      "step: 9, acc: 0.109, loss: 2.302 (data_loss: 2.302, reg_loss: 0.000), lr: 0.0009999100080992712\n",
      "step: 10, acc: 0.109, loss: 2.302 (data_loss: 2.302, reg_loss: 0.000), lr: 0.000999900009999\n",
      "step: 11, acc: 0.117, loss: 2.301 (data_loss: 2.301, reg_loss: 0.000), lr: 0.000999890012098669\n",
      "step: 12, acc: 0.109, loss: 2.301 (data_loss: 2.301, reg_loss: 0.000), lr: 0.0009998800143982724\n",
      "step: 13, acc: 0.109, loss: 2.301 (data_loss: 2.301, reg_loss: 0.000), lr: 0.0009998700168978034\n",
      "step: 14, acc: 0.117, loss: 2.301 (data_loss: 2.301, reg_loss: 0.000), lr: 0.0009998600195972563\n",
      "step: 15, acc: 0.109, loss: 2.301 (data_loss: 2.301, reg_loss: 0.000), lr: 0.0009998500224966255\n",
      "step: 16, acc: 0.109, loss: 2.301 (data_loss: 2.301, reg_loss: 0.000), lr: 0.0009998400255959046\n",
      "step: 17, acc: 0.117, loss: 2.300 (data_loss: 2.300, reg_loss: 0.000), lr: 0.0009998300288950879\n",
      "step: 18, acc: 0.109, loss: 2.300 (data_loss: 2.300, reg_loss: 0.000), lr: 0.000999820032394169\n",
      "step: 19, acc: 0.117, loss: 2.300 (data_loss: 2.300, reg_loss: 0.000), lr: 0.0009998100360931424\n",
      "step: 20, acc: 0.109, loss: 2.300 (data_loss: 2.300, reg_loss: 0.000), lr: 0.0009998000399920016\n",
      "step: 21, acc: 0.109, loss: 2.299 (data_loss: 2.299, reg_loss: 0.000), lr: 0.000999790044090741\n",
      "step: 22, acc: 0.117, loss: 2.299 (data_loss: 2.299, reg_loss: 0.000), lr: 0.0009997800483893542\n",
      "step: 23, acc: 0.109, loss: 2.298 (data_loss: 2.298, reg_loss: 0.000), lr: 0.000999770052887836\n",
      "step: 24, acc: 0.109, loss: 2.299 (data_loss: 2.299, reg_loss: 0.000), lr: 0.0009997600575861792\n",
      "step: 25, acc: 0.117, loss: 2.298 (data_loss: 2.298, reg_loss: 0.000), lr: 0.0009997500624843788\n",
      "step: 26, acc: 0.109, loss: 2.298 (data_loss: 2.298, reg_loss: 0.000), lr: 0.0009997400675824286\n",
      "step: 27, acc: 0.117, loss: 2.297 (data_loss: 2.297, reg_loss: 0.000), lr: 0.0009997300728803223\n",
      "step: 28, acc: 0.109, loss: 2.297 (data_loss: 2.297, reg_loss: 0.000), lr: 0.0009997200783780542\n",
      "step: 29, acc: 0.117, loss: 2.297 (data_loss: 2.297, reg_loss: 0.000), lr: 0.0009997100840756182\n",
      "step: 30, acc: 0.109, loss: 2.296 (data_loss: 2.296, reg_loss: 0.000), lr: 0.000999700089973008\n",
      "step: 31, acc: 0.109, loss: 2.296 (data_loss: 2.296, reg_loss: 0.000), lr: 0.0009996900960702183\n",
      "step: 32, acc: 0.117, loss: 2.295 (data_loss: 2.295, reg_loss: 0.000), lr: 0.0009996801023672425\n",
      "step: 33, acc: 0.109, loss: 2.295 (data_loss: 2.295, reg_loss: 0.000), lr: 0.000999670108864075\n",
      "step: 34, acc: 0.109, loss: 2.295 (data_loss: 2.295, reg_loss: 0.000), lr: 0.0009996601155607093\n",
      "step: 35, acc: 0.117, loss: 2.293 (data_loss: 2.293, reg_loss: 0.000), lr: 0.0009996501224571398\n",
      "step: 36, acc: 0.109, loss: 2.294 (data_loss: 2.294, reg_loss: 0.000), lr: 0.0009996401295533609\n",
      "step: 37, acc: 0.117, loss: 2.292 (data_loss: 2.292, reg_loss: 0.000), lr: 0.0009996301368493659\n",
      "step: 38, acc: 0.109, loss: 2.293 (data_loss: 2.293, reg_loss: 0.000), lr: 0.0009996201443451488\n",
      "step: 39, acc: 0.109, loss: 2.292 (data_loss: 2.292, reg_loss: 0.000), lr: 0.0009996101520407042\n",
      "step: 40, acc: 0.117, loss: 2.290 (data_loss: 2.290, reg_loss: 0.000), lr: 0.0009996001599360256\n",
      "step: 41, acc: 0.109, loss: 2.291 (data_loss: 2.291, reg_loss: 0.000), lr: 0.0009995901680311073\n",
      "step: 42, acc: 0.109, loss: 2.290 (data_loss: 2.290, reg_loss: 0.000), lr: 0.000999580176325943\n",
      "step: 43, acc: 0.117, loss: 2.288 (data_loss: 2.288, reg_loss: 0.000), lr: 0.0009995701848205273\n",
      "step: 44, acc: 0.109, loss: 2.289 (data_loss: 2.289, reg_loss: 0.000), lr: 0.0009995601935148535\n",
      "step: 45, acc: 0.109, loss: 2.288 (data_loss: 2.288, reg_loss: 0.000), lr: 0.0009995502024089159\n",
      "step: 46, acc: 0.125, loss: 2.287 (data_loss: 2.287, reg_loss: 0.000), lr: 0.000999540211502709\n",
      "step: 47, acc: 0.109, loss: 2.287 (data_loss: 2.287, reg_loss: 0.000), lr: 0.0009995302207962257\n",
      "step: 48, acc: 0.117, loss: 2.285 (data_loss: 2.285, reg_loss: 0.000), lr: 0.000999520230289461\n",
      "step: 49, acc: 0.117, loss: 2.284 (data_loss: 2.284, reg_loss: 0.000), lr: 0.0009995102399824086\n",
      "step: 50, acc: 0.109, loss: 2.284 (data_loss: 2.284, reg_loss: 0.000), lr: 0.0009995002498750624\n",
      "step: 51, acc: 0.117, loss: 2.282 (data_loss: 2.282, reg_loss: 0.000), lr: 0.0009994902599674165\n",
      "step: 52, acc: 0.109, loss: 2.283 (data_loss: 2.283, reg_loss: 0.000), lr: 0.000999480270259465\n",
      "step: 53, acc: 0.125, loss: 2.282 (data_loss: 2.282, reg_loss: 0.000), lr: 0.000999470280751202\n",
      "step: 54, acc: 0.109, loss: 2.281 (data_loss: 2.281, reg_loss: 0.000), lr: 0.000999460291442621\n",
      "step: 55, acc: 0.125, loss: 2.281 (data_loss: 2.281, reg_loss: 0.000), lr: 0.0009994503023337165\n",
      "step: 56, acc: 0.125, loss: 2.278 (data_loss: 2.278, reg_loss: 0.000), lr: 0.0009994403134244824\n",
      "step: 57, acc: 0.125, loss: 2.278 (data_loss: 2.278, reg_loss: 0.000), lr: 0.0009994303247149127\n",
      "step: 58, acc: 0.164, loss: 2.274 (data_loss: 2.274, reg_loss: 0.000), lr: 0.0009994203362050011\n",
      "step: 59, acc: 0.141, loss: 2.277 (data_loss: 2.277, reg_loss: 0.000), lr: 0.0009994103478947421\n",
      "step: 60, acc: 0.125, loss: 2.277 (data_loss: 2.277, reg_loss: 0.000), lr: 0.0009994003597841295\n",
      "step: 61, acc: 0.156, loss: 2.271 (data_loss: 2.271, reg_loss: 0.000), lr: 0.0009993903718731574\n",
      "step: 62, acc: 0.148, loss: 2.273 (data_loss: 2.273, reg_loss: 0.000), lr: 0.0009993803841618196\n",
      "step: 63, acc: 0.180, loss: 2.270 (data_loss: 2.270, reg_loss: 0.000), lr: 0.0009993703966501106\n",
      "step: 64, acc: 0.156, loss: 2.269 (data_loss: 2.269, reg_loss: 0.000), lr: 0.0009993604093380237\n",
      "step: 65, acc: 0.148, loss: 2.272 (data_loss: 2.272, reg_loss: 0.000), lr: 0.0009993504222255533\n",
      "step: 66, acc: 0.195, loss: 2.265 (data_loss: 2.265, reg_loss: 0.000), lr: 0.0009993404353126935\n",
      "step: 67, acc: 0.148, loss: 2.270 (data_loss: 2.270, reg_loss: 0.000), lr: 0.0009993304485994385\n",
      "step: 68, acc: 0.180, loss: 2.265 (data_loss: 2.265, reg_loss: 0.000), lr: 0.0009993204620857817\n",
      "step: 69, acc: 0.172, loss: 2.263 (data_loss: 2.263, reg_loss: 0.000), lr: 0.0009993104757717174\n",
      "step: 70, acc: 0.211, loss: 2.259 (data_loss: 2.259, reg_loss: 0.000), lr: 0.0009993004896572402\n",
      "step: 71, acc: 0.227, loss: 2.259 (data_loss: 2.259, reg_loss: 0.000), lr: 0.0009992905037423429\n",
      "step: 72, acc: 0.203, loss: 2.259 (data_loss: 2.259, reg_loss: 0.000), lr: 0.0009992805180270205\n",
      "step: 73, acc: 0.219, loss: 2.257 (data_loss: 2.257, reg_loss: 0.000), lr: 0.0009992705325112669\n",
      "step: 74, acc: 0.219, loss: 2.258 (data_loss: 2.258, reg_loss: 0.000), lr: 0.0009992605471950758\n",
      "step: 75, acc: 0.203, loss: 2.258 (data_loss: 2.258, reg_loss: 0.000), lr: 0.0009992505620784412\n",
      "step: 76, acc: 0.234, loss: 2.252 (data_loss: 2.252, reg_loss: 0.000), lr: 0.0009992405771613573\n",
      "step: 77, acc: 0.242, loss: 2.249 (data_loss: 2.249, reg_loss: 0.000), lr: 0.0009992305924438182\n",
      "step: 78, acc: 0.211, loss: 2.255 (data_loss: 2.255, reg_loss: 0.000), lr: 0.0009992206079258179\n",
      "step: 79, acc: 0.250, loss: 2.250 (data_loss: 2.250, reg_loss: 0.000), lr: 0.0009992106236073502\n",
      "step: 80, acc: 0.258, loss: 2.248 (data_loss: 2.248, reg_loss: 0.000), lr: 0.0009992006394884093\n",
      "step: 81, acc: 0.250, loss: 2.248 (data_loss: 2.248, reg_loss: 0.000), lr: 0.0009991906555689891\n",
      "step: 82, acc: 0.250, loss: 2.241 (data_loss: 2.241, reg_loss: 0.000), lr: 0.0009991806718490836\n",
      "step: 83, acc: 0.266, loss: 2.242 (data_loss: 2.242, reg_loss: 0.000), lr: 0.000999170688328687\n",
      "step: 84, acc: 0.289, loss: 2.240 (data_loss: 2.240, reg_loss: 0.000), lr: 0.0009991607050077935\n",
      "step: 85, acc: 0.281, loss: 2.242 (data_loss: 2.242, reg_loss: 0.000), lr: 0.0009991507218863964\n",
      "step: 86, acc: 0.312, loss: 2.238 (data_loss: 2.238, reg_loss: 0.000), lr: 0.0009991407389644904\n",
      "step: 87, acc: 0.266, loss: 2.238 (data_loss: 2.238, reg_loss: 0.000), lr: 0.0009991307562420696\n",
      "step: 88, acc: 0.242, loss: 2.236 (data_loss: 2.236, reg_loss: 0.000), lr: 0.0009991207737191272\n",
      "step: 89, acc: 0.320, loss: 2.227 (data_loss: 2.227, reg_loss: 0.000), lr: 0.0009991107913956579\n",
      "step: 90, acc: 0.305, loss: 2.227 (data_loss: 2.227, reg_loss: 0.000), lr: 0.0009991008092716555\n",
      "step: 91, acc: 0.273, loss: 2.226 (data_loss: 2.226, reg_loss: 0.000), lr: 0.0009990908273471142\n",
      "step: 92, acc: 0.289, loss: 2.229 (data_loss: 2.229, reg_loss: 0.000), lr: 0.0009990808456220278\n",
      "step: 93, acc: 0.289, loss: 2.221 (data_loss: 2.221, reg_loss: 0.000), lr: 0.0009990708640963903\n",
      "step: 94, acc: 0.336, loss: 2.224 (data_loss: 2.224, reg_loss: 0.000), lr: 0.000999060882770196\n",
      "step: 95, acc: 0.320, loss: 2.223 (data_loss: 2.223, reg_loss: 0.000), lr: 0.0009990509016434388\n",
      "step: 96, acc: 0.344, loss: 2.217 (data_loss: 2.217, reg_loss: 0.000), lr: 0.0009990409207161126\n",
      "step: 97, acc: 0.336, loss: 2.216 (data_loss: 2.216, reg_loss: 0.000), lr: 0.0009990309399882115\n",
      "step: 98, acc: 0.312, loss: 2.218 (data_loss: 2.218, reg_loss: 0.000), lr: 0.0009990209594597295\n",
      "step: 99, acc: 0.352, loss: 2.211 (data_loss: 2.211, reg_loss: 0.000), lr: 0.0009990109791306607\n",
      "step: 100, acc: 0.336, loss: 2.212 (data_loss: 2.212, reg_loss: 0.000), lr: 0.0009990009990009992\n",
      "step: 101, acc: 0.352, loss: 2.202 (data_loss: 2.202, reg_loss: 0.000), lr: 0.0009989910190707385\n",
      "step: 102, acc: 0.414, loss: 2.199 (data_loss: 2.199, reg_loss: 0.000), lr: 0.0009989810393398733\n",
      "step: 103, acc: 0.336, loss: 2.211 (data_loss: 2.211, reg_loss: 0.000), lr: 0.0009989710598083974\n",
      "step: 104, acc: 0.328, loss: 2.205 (data_loss: 2.205, reg_loss: 0.000), lr: 0.0009989610804763047\n",
      "step: 105, acc: 0.367, loss: 2.196 (data_loss: 2.196, reg_loss: 0.000), lr: 0.0009989511013435892\n",
      "step: 106, acc: 0.391, loss: 2.189 (data_loss: 2.189, reg_loss: 0.000), lr: 0.000998941122410245\n",
      "step: 107, acc: 0.297, loss: 2.207 (data_loss: 2.207, reg_loss: 0.000), lr: 0.0009989311436762664\n",
      "step: 108, acc: 0.367, loss: 2.192 (data_loss: 2.192, reg_loss: 0.000), lr: 0.0009989211651416472\n",
      "step: 109, acc: 0.430, loss: 2.178 (data_loss: 2.178, reg_loss: 0.000), lr: 0.000998911186806381\n",
      "step: 110, acc: 0.398, loss: 2.184 (data_loss: 2.184, reg_loss: 0.000), lr: 0.0009989012086704624\n",
      "step: 111, acc: 0.398, loss: 2.187 (data_loss: 2.187, reg_loss: 0.000), lr: 0.0009988912307338854\n",
      "step: 112, acc: 0.383, loss: 2.192 (data_loss: 2.192, reg_loss: 0.000), lr: 0.0009988812529966439\n",
      "step: 113, acc: 0.391, loss: 2.178 (data_loss: 2.178, reg_loss: 0.000), lr: 0.0009988712754587315\n",
      "step: 114, acc: 0.406, loss: 2.179 (data_loss: 2.179, reg_loss: 0.000), lr: 0.0009988612981201431\n",
      "step: 115, acc: 0.375, loss: 2.177 (data_loss: 2.177, reg_loss: 0.000), lr: 0.0009988513209808721\n",
      "step: 116, acc: 0.367, loss: 2.178 (data_loss: 2.178, reg_loss: 0.000), lr: 0.0009988413440409126\n",
      "step: 117, acc: 0.414, loss: 2.168 (data_loss: 2.168, reg_loss: 0.000), lr: 0.0009988313673002587\n",
      "step: 118, acc: 0.391, loss: 2.173 (data_loss: 2.173, reg_loss: 0.000), lr: 0.0009988213907589046\n",
      "step: 119, acc: 0.391, loss: 2.163 (data_loss: 2.163, reg_loss: 0.000), lr: 0.000998811414416844\n",
      "step: 120, acc: 0.383, loss: 2.163 (data_loss: 2.163, reg_loss: 0.000), lr: 0.000998801438274071\n",
      "step: 121, acc: 0.414, loss: 2.160 (data_loss: 2.160, reg_loss: 0.000), lr: 0.00099879146233058\n",
      "step: 122, acc: 0.414, loss: 2.156 (data_loss: 2.156, reg_loss: 0.000), lr: 0.0009987814865863648\n",
      "step: 123, acc: 0.406, loss: 2.154 (data_loss: 2.154, reg_loss: 0.000), lr: 0.0009987715110414191\n",
      "step: 124, acc: 0.414, loss: 2.153 (data_loss: 2.153, reg_loss: 0.000), lr: 0.0009987615356957373\n",
      "step: 125, acc: 0.445, loss: 2.148 (data_loss: 2.148, reg_loss: 0.000), lr: 0.0009987515605493133\n",
      "step: 126, acc: 0.367, loss: 2.151 (data_loss: 2.151, reg_loss: 0.000), lr: 0.0009987415856021413\n",
      "step: 127, acc: 0.430, loss: 2.139 (data_loss: 2.139, reg_loss: 0.000), lr: 0.000998731610854215\n",
      "step: 128, acc: 0.367, loss: 2.153 (data_loss: 2.153, reg_loss: 0.000), lr: 0.000998721636305529\n",
      "step: 129, acc: 0.414, loss: 2.128 (data_loss: 2.128, reg_loss: 0.000), lr: 0.0009987116619560768\n",
      "step: 130, acc: 0.445, loss: 2.142 (data_loss: 2.142, reg_loss: 0.000), lr: 0.0009987016878058523\n",
      "step: 131, acc: 0.430, loss: 2.143 (data_loss: 2.143, reg_loss: 0.000), lr: 0.0009986917138548504\n",
      "step: 132, acc: 0.398, loss: 2.129 (data_loss: 2.129, reg_loss: 0.000), lr: 0.000998681740103064\n",
      "step: 133, acc: 0.414, loss: 2.132 (data_loss: 2.132, reg_loss: 0.000), lr: 0.0009986717665504878\n",
      "step: 134, acc: 0.359, loss: 2.121 (data_loss: 2.121, reg_loss: 0.000), lr: 0.000998661793197116\n",
      "step: 135, acc: 0.422, loss: 2.115 (data_loss: 2.115, reg_loss: 0.000), lr: 0.0009986518200429421\n",
      "step: 136, acc: 0.430, loss: 2.110 (data_loss: 2.110, reg_loss: 0.000), lr: 0.0009986418470879603\n",
      "step: 137, acc: 0.469, loss: 2.116 (data_loss: 2.116, reg_loss: 0.000), lr: 0.0009986318743321649\n",
      "step: 138, acc: 0.383, loss: 2.109 (data_loss: 2.109, reg_loss: 0.000), lr: 0.0009986219017755497\n",
      "step: 139, acc: 0.438, loss: 2.113 (data_loss: 2.113, reg_loss: 0.000), lr: 0.0009986119294181088\n",
      "step: 140, acc: 0.414, loss: 2.106 (data_loss: 2.106, reg_loss: 0.000), lr: 0.000998601957259836\n",
      "step: 141, acc: 0.438, loss: 2.113 (data_loss: 2.113, reg_loss: 0.000), lr: 0.000998591985300726\n",
      "step: 142, acc: 0.445, loss: 2.088 (data_loss: 2.088, reg_loss: 0.000), lr: 0.0009985820135407723\n",
      "step: 143, acc: 0.445, loss: 2.107 (data_loss: 2.107, reg_loss: 0.000), lr: 0.0009985720419799686\n",
      "step: 144, acc: 0.430, loss: 2.099 (data_loss: 2.099, reg_loss: 0.000), lr: 0.0009985620706183095\n",
      "step: 145, acc: 0.508, loss: 2.085 (data_loss: 2.085, reg_loss: 0.000), lr: 0.000998552099455789\n",
      "step: 146, acc: 0.375, loss: 2.109 (data_loss: 2.109, reg_loss: 0.000), lr: 0.000998542128492401\n",
      "step: 147, acc: 0.430, loss: 2.087 (data_loss: 2.087, reg_loss: 0.000), lr: 0.0009985321577281395\n",
      "step: 148, acc: 0.398, loss: 2.100 (data_loss: 2.100, reg_loss: 0.000), lr: 0.0009985221871629988\n",
      "step: 149, acc: 0.430, loss: 2.090 (data_loss: 2.090, reg_loss: 0.000), lr: 0.0009985122167969725\n",
      "step: 150, acc: 0.430, loss: 2.065 (data_loss: 2.065, reg_loss: 0.000), lr: 0.0009985022466300548\n",
      "step: 151, acc: 0.453, loss: 2.069 (data_loss: 2.069, reg_loss: 0.000), lr: 0.0009984922766622401\n",
      "step: 152, acc: 0.453, loss: 2.073 (data_loss: 2.073, reg_loss: 0.000), lr: 0.0009984823068935219\n",
      "step: 153, acc: 0.461, loss: 2.081 (data_loss: 2.081, reg_loss: 0.000), lr: 0.0009984723373238943\n",
      "step: 154, acc: 0.500, loss: 2.047 (data_loss: 2.047, reg_loss: 0.000), lr: 0.0009984623679533517\n",
      "step: 155, acc: 0.461, loss: 2.036 (data_loss: 2.036, reg_loss: 0.000), lr: 0.0009984523987818883\n",
      "step: 156, acc: 0.477, loss: 2.046 (data_loss: 2.046, reg_loss: 0.000), lr: 0.0009984424298094972\n",
      "step: 157, acc: 0.477, loss: 2.067 (data_loss: 2.067, reg_loss: 0.000), lr: 0.000998432461036173\n",
      "step: 158, acc: 0.461, loss: 2.059 (data_loss: 2.059, reg_loss: 0.000), lr: 0.0009984224924619103\n",
      "step: 159, acc: 0.477, loss: 2.054 (data_loss: 2.054, reg_loss: 0.000), lr: 0.0009984125240867022\n",
      "step: 160, acc: 0.469, loss: 2.049 (data_loss: 2.049, reg_loss: 0.000), lr: 0.000998402555910543\n",
      "step: 161, acc: 0.500, loss: 2.047 (data_loss: 2.047, reg_loss: 0.000), lr: 0.0009983925879334273\n",
      "step: 162, acc: 0.461, loss: 2.037 (data_loss: 2.037, reg_loss: 0.000), lr: 0.0009983826201553484\n",
      "step: 163, acc: 0.500, loss: 2.033 (data_loss: 2.033, reg_loss: 0.000), lr: 0.0009983726525763007\n",
      "step: 164, acc: 0.492, loss: 2.021 (data_loss: 2.021, reg_loss: 0.000), lr: 0.000998362685196278\n",
      "step: 165, acc: 0.469, loss: 2.037 (data_loss: 2.037, reg_loss: 0.000), lr: 0.000998352718015275\n",
      "step: 166, acc: 0.508, loss: 2.025 (data_loss: 2.025, reg_loss: 0.000), lr: 0.0009983427510332848\n",
      "step: 167, acc: 0.477, loss: 2.039 (data_loss: 2.039, reg_loss: 0.000), lr: 0.0009983327842503018\n",
      "step: 168, acc: 0.430, loss: 2.032 (data_loss: 2.032, reg_loss: 0.000), lr: 0.0009983228176663208\n",
      "step: 169, acc: 0.523, loss: 2.007 (data_loss: 2.007, reg_loss: 0.000), lr: 0.0009983128512813346\n",
      "step: 170, acc: 0.484, loss: 2.030 (data_loss: 2.030, reg_loss: 0.000), lr: 0.000998302885095338\n",
      "step: 171, acc: 0.438, loss: 2.015 (data_loss: 2.015, reg_loss: 0.000), lr: 0.0009982929191083246\n",
      "step: 172, acc: 0.508, loss: 1.995 (data_loss: 1.995, reg_loss: 0.000), lr: 0.000998282953320289\n",
      "step: 173, acc: 0.484, loss: 2.002 (data_loss: 2.002, reg_loss: 0.000), lr: 0.000998272987731225\n",
      "step: 174, acc: 0.430, loss: 2.010 (data_loss: 2.010, reg_loss: 0.000), lr: 0.0009982630223411264\n",
      "step: 175, acc: 0.445, loss: 2.010 (data_loss: 2.010, reg_loss: 0.000), lr: 0.0009982530571499876\n",
      "step: 176, acc: 0.508, loss: 1.988 (data_loss: 1.988, reg_loss: 0.000), lr: 0.0009982430921578022\n",
      "step: 177, acc: 0.492, loss: 2.000 (data_loss: 2.000, reg_loss: 0.000), lr: 0.0009982331273645647\n",
      "step: 178, acc: 0.453, loss: 1.985 (data_loss: 1.985, reg_loss: 0.000), lr: 0.000998223162770269\n",
      "step: 179, acc: 0.500, loss: 1.994 (data_loss: 1.994, reg_loss: 0.000), lr: 0.000998213198374909\n",
      "step: 180, acc: 0.539, loss: 1.954 (data_loss: 1.954, reg_loss: 0.000), lr: 0.0009982032341784787\n",
      "step: 181, acc: 0.500, loss: 1.945 (data_loss: 1.945, reg_loss: 0.000), lr: 0.0009981932701809723\n",
      "step: 182, acc: 0.477, loss: 1.987 (data_loss: 1.987, reg_loss: 0.000), lr: 0.0009981833063823842\n",
      "step: 183, acc: 0.484, loss: 1.977 (data_loss: 1.977, reg_loss: 0.000), lr: 0.0009981733427827076\n",
      "step: 184, acc: 0.508, loss: 1.965 (data_loss: 1.965, reg_loss: 0.000), lr: 0.0009981633793819372\n",
      "step: 185, acc: 0.477, loss: 1.968 (data_loss: 1.968, reg_loss: 0.000), lr: 0.0009981534161800669\n",
      "step: 186, acc: 0.508, loss: 1.952 (data_loss: 1.952, reg_loss: 0.000), lr: 0.0009981434531770906\n",
      "step: 187, acc: 0.484, loss: 1.941 (data_loss: 1.941, reg_loss: 0.000), lr: 0.0009981334903730024\n",
      "step: 188, acc: 0.500, loss: 1.956 (data_loss: 1.956, reg_loss: 0.000), lr: 0.0009981235277677965\n",
      "step: 189, acc: 0.539, loss: 1.957 (data_loss: 1.957, reg_loss: 0.000), lr: 0.000998113565361467\n",
      "step: 190, acc: 0.469, loss: 1.959 (data_loss: 1.959, reg_loss: 0.000), lr: 0.0009981036031540074\n",
      "step: 191, acc: 0.523, loss: 1.915 (data_loss: 1.915, reg_loss: 0.000), lr: 0.0009980936411454122\n",
      "step: 192, acc: 0.539, loss: 1.918 (data_loss: 1.918, reg_loss: 0.000), lr: 0.0009980836793356755\n",
      "step: 193, acc: 0.562, loss: 1.942 (data_loss: 1.942, reg_loss: 0.000), lr: 0.0009980737177247912\n",
      "step: 194, acc: 0.570, loss: 1.930 (data_loss: 1.930, reg_loss: 0.000), lr: 0.0009980637563127533\n",
      "step: 195, acc: 0.516, loss: 1.927 (data_loss: 1.927, reg_loss: 0.000), lr: 0.000998053795099556\n",
      "step: 196, acc: 0.523, loss: 1.932 (data_loss: 1.932, reg_loss: 0.000), lr: 0.0009980438340851932\n",
      "step: 197, acc: 0.461, loss: 1.925 (data_loss: 1.925, reg_loss: 0.000), lr: 0.0009980338732696588\n",
      "step: 198, acc: 0.445, loss: 1.948 (data_loss: 1.948, reg_loss: 0.000), lr: 0.0009980239126529471\n",
      "step: 199, acc: 0.562, loss: 1.910 (data_loss: 1.910, reg_loss: 0.000), lr: 0.0009980139522350524\n",
      "step: 200, acc: 0.484, loss: 1.902 (data_loss: 1.902, reg_loss: 0.000), lr: 0.000998003992015968\n",
      "step: 201, acc: 0.547, loss: 1.924 (data_loss: 1.924, reg_loss: 0.000), lr: 0.0009979940319956885\n",
      "step: 202, acc: 0.516, loss: 1.914 (data_loss: 1.914, reg_loss: 0.000), lr: 0.0009979840721742082\n",
      "step: 203, acc: 0.523, loss: 1.908 (data_loss: 1.908, reg_loss: 0.000), lr: 0.0009979741125515204\n",
      "step: 204, acc: 0.555, loss: 1.912 (data_loss: 1.912, reg_loss: 0.000), lr: 0.0009979641531276196\n",
      "step: 205, acc: 0.602, loss: 1.870 (data_loss: 1.870, reg_loss: 0.000), lr: 0.0009979541939024999\n",
      "step: 206, acc: 0.484, loss: 1.893 (data_loss: 1.893, reg_loss: 0.000), lr: 0.0009979442348761552\n",
      "step: 207, acc: 0.570, loss: 1.889 (data_loss: 1.889, reg_loss: 0.000), lr: 0.0009979342760485794\n",
      "step: 208, acc: 0.555, loss: 1.887 (data_loss: 1.887, reg_loss: 0.000), lr: 0.0009979243174197668\n",
      "step: 209, acc: 0.562, loss: 1.881 (data_loss: 1.881, reg_loss: 0.000), lr: 0.0009979143589897116\n",
      "step: 210, acc: 0.508, loss: 1.871 (data_loss: 1.871, reg_loss: 0.000), lr: 0.0009979044007584073\n",
      "step: 211, acc: 0.562, loss: 1.869 (data_loss: 1.869, reg_loss: 0.000), lr: 0.0009978944427258484\n",
      "step: 212, acc: 0.562, loss: 1.862 (data_loss: 1.862, reg_loss: 0.000), lr: 0.000997884484892029\n",
      "step: 213, acc: 0.539, loss: 1.856 (data_loss: 1.856, reg_loss: 0.000), lr: 0.0009978745272569427\n",
      "step: 214, acc: 0.570, loss: 1.845 (data_loss: 1.845, reg_loss: 0.000), lr: 0.000997864569820584\n",
      "step: 215, acc: 0.555, loss: 1.878 (data_loss: 1.878, reg_loss: 0.000), lr: 0.0009978546125829467\n",
      "step: 216, acc: 0.570, loss: 1.872 (data_loss: 1.872, reg_loss: 0.000), lr: 0.000997844655544025\n",
      "step: 217, acc: 0.500, loss: 1.841 (data_loss: 1.841, reg_loss: 0.000), lr: 0.0009978346987038126\n",
      "step: 218, acc: 0.539, loss: 1.865 (data_loss: 1.865, reg_loss: 0.000), lr: 0.0009978247420623042\n",
      "step: 219, acc: 0.516, loss: 1.832 (data_loss: 1.832, reg_loss: 0.000), lr: 0.0009978147856194934\n",
      "step: 220, acc: 0.547, loss: 1.835 (data_loss: 1.835, reg_loss: 0.000), lr: 0.0009978048293753743\n",
      "step: 221, acc: 0.516, loss: 1.871 (data_loss: 1.871, reg_loss: 0.000), lr: 0.0009977948733299407\n",
      "step: 222, acc: 0.531, loss: 1.853 (data_loss: 1.853, reg_loss: 0.000), lr: 0.0009977849174831871\n",
      "step: 223, acc: 0.547, loss: 1.843 (data_loss: 1.843, reg_loss: 0.000), lr: 0.0009977749618351078\n",
      "step: 224, acc: 0.539, loss: 1.837 (data_loss: 1.837, reg_loss: 0.000), lr: 0.000997765006385696\n",
      "step: 225, acc: 0.500, loss: 1.867 (data_loss: 1.867, reg_loss: 0.000), lr: 0.0009977550511349464\n",
      "step: 226, acc: 0.547, loss: 1.841 (data_loss: 1.841, reg_loss: 0.000), lr: 0.0009977450960828528\n",
      "step: 227, acc: 0.516, loss: 1.837 (data_loss: 1.837, reg_loss: 0.000), lr: 0.0009977351412294093\n",
      "step: 228, acc: 0.594, loss: 1.784 (data_loss: 1.784, reg_loss: 0.000), lr: 0.0009977251865746098\n",
      "step: 229, acc: 0.570, loss: 1.825 (data_loss: 1.825, reg_loss: 0.000), lr: 0.0009977152321184487\n",
      "step: 230, acc: 0.594, loss: 1.802 (data_loss: 1.802, reg_loss: 0.000), lr: 0.0009977052778609198\n",
      "step: 231, acc: 0.617, loss: 1.781 (data_loss: 1.781, reg_loss: 0.000), lr: 0.0009976953238020174\n",
      "step: 232, acc: 0.586, loss: 1.793 (data_loss: 1.793, reg_loss: 0.000), lr: 0.0009976853699417351\n",
      "step: 233, acc: 0.508, loss: 1.823 (data_loss: 1.823, reg_loss: 0.000), lr: 0.0009976754162800674\n",
      "step: 234, acc: 0.555, loss: 1.815 (data_loss: 1.815, reg_loss: 0.000), lr: 0.0009976654628170083\n",
      "step: 235, acc: 0.602, loss: 1.785 (data_loss: 1.785, reg_loss: 0.000), lr: 0.0009976555095525515\n",
      "step: 236, acc: 0.594, loss: 1.759 (data_loss: 1.759, reg_loss: 0.000), lr: 0.0009976455564866915\n",
      "step: 237, acc: 0.578, loss: 1.757 (data_loss: 1.757, reg_loss: 0.000), lr: 0.000997635603619422\n",
      "step: 238, acc: 0.578, loss: 1.770 (data_loss: 1.770, reg_loss: 0.000), lr: 0.0009976256509507371\n",
      "step: 239, acc: 0.602, loss: 1.770 (data_loss: 1.770, reg_loss: 0.000), lr: 0.0009976156984806313\n",
      "step: 240, acc: 0.641, loss: 1.760 (data_loss: 1.760, reg_loss: 0.000), lr: 0.0009976057462090984\n",
      "step: 241, acc: 0.586, loss: 1.787 (data_loss: 1.787, reg_loss: 0.000), lr: 0.0009975957941361318\n",
      "step: 242, acc: 0.609, loss: 1.759 (data_loss: 1.759, reg_loss: 0.000), lr: 0.0009975858422617266\n",
      "step: 243, acc: 0.602, loss: 1.746 (data_loss: 1.746, reg_loss: 0.000), lr: 0.0009975758905858764\n",
      "step: 244, acc: 0.594, loss: 1.749 (data_loss: 1.749, reg_loss: 0.000), lr: 0.0009975659391085751\n",
      "step: 245, acc: 0.578, loss: 1.770 (data_loss: 1.770, reg_loss: 0.000), lr: 0.0009975559878298169\n",
      "step: 246, acc: 0.578, loss: 1.741 (data_loss: 1.741, reg_loss: 0.000), lr: 0.0009975460367495962\n",
      "step: 247, acc: 0.594, loss: 1.746 (data_loss: 1.746, reg_loss: 0.000), lr: 0.0009975360858679064\n",
      "step: 248, acc: 0.578, loss: 1.731 (data_loss: 1.731, reg_loss: 0.000), lr: 0.0009975261351847418\n",
      "step: 249, acc: 0.594, loss: 1.764 (data_loss: 1.764, reg_loss: 0.000), lr: 0.0009975161847000967\n",
      "step: 250, acc: 0.609, loss: 1.733 (data_loss: 1.733, reg_loss: 0.000), lr: 0.0009975062344139652\n",
      "step: 251, acc: 0.539, loss: 1.731 (data_loss: 1.731, reg_loss: 0.000), lr: 0.000997496284326341\n",
      "step: 252, acc: 0.547, loss: 1.731 (data_loss: 1.731, reg_loss: 0.000), lr: 0.000997486334437218\n",
      "step: 253, acc: 0.617, loss: 1.683 (data_loss: 1.683, reg_loss: 0.000), lr: 0.000997476384746591\n",
      "step: 254, acc: 0.523, loss: 1.749 (data_loss: 1.749, reg_loss: 0.000), lr: 0.0009974664352544536\n",
      "step: 255, acc: 0.633, loss: 1.717 (data_loss: 1.717, reg_loss: 0.000), lr: 0.0009974564859608\n",
      "step: 256, acc: 0.531, loss: 1.712 (data_loss: 1.712, reg_loss: 0.000), lr: 0.0009974465368656241\n",
      "step: 257, acc: 0.578, loss: 1.730 (data_loss: 1.730, reg_loss: 0.000), lr: 0.0009974365879689198\n",
      "step: 258, acc: 0.586, loss: 1.710 (data_loss: 1.710, reg_loss: 0.000), lr: 0.0009974266392706816\n",
      "step: 259, acc: 0.586, loss: 1.715 (data_loss: 1.715, reg_loss: 0.000), lr: 0.0009974166907709033\n",
      "step: 260, acc: 0.617, loss: 1.705 (data_loss: 1.705, reg_loss: 0.000), lr: 0.0009974067424695793\n",
      "step: 261, acc: 0.641, loss: 1.671 (data_loss: 1.671, reg_loss: 0.000), lr: 0.0009973967943667028\n",
      "step: 262, acc: 0.570, loss: 1.695 (data_loss: 1.695, reg_loss: 0.000), lr: 0.0009973868464622688\n",
      "step: 263, acc: 0.609, loss: 1.715 (data_loss: 1.715, reg_loss: 0.000), lr: 0.0009973768987562711\n",
      "step: 264, acc: 0.555, loss: 1.715 (data_loss: 1.715, reg_loss: 0.000), lr: 0.0009973669512487035\n",
      "step: 265, acc: 0.617, loss: 1.677 (data_loss: 1.677, reg_loss: 0.000), lr: 0.0009973570039395602\n",
      "step: 266, acc: 0.578, loss: 1.710 (data_loss: 1.710, reg_loss: 0.000), lr: 0.0009973470568288352\n",
      "step: 267, acc: 0.578, loss: 1.672 (data_loss: 1.672, reg_loss: 0.000), lr: 0.000997337109916523\n",
      "step: 268, acc: 0.578, loss: 1.723 (data_loss: 1.723, reg_loss: 0.000), lr: 0.000997327163202617\n",
      "step: 269, acc: 0.656, loss: 1.664 (data_loss: 1.664, reg_loss: 0.000), lr: 0.0009973172166871116\n",
      "step: 270, acc: 0.570, loss: 1.708 (data_loss: 1.708, reg_loss: 0.000), lr: 0.0009973072703700011\n",
      "step: 271, acc: 0.586, loss: 1.671 (data_loss: 1.671, reg_loss: 0.000), lr: 0.0009972973242512791\n",
      "step: 272, acc: 0.633, loss: 1.618 (data_loss: 1.618, reg_loss: 0.000), lr: 0.0009972873783309398\n",
      "step: 273, acc: 0.641, loss: 1.638 (data_loss: 1.638, reg_loss: 0.000), lr: 0.0009972774326089777\n",
      "step: 274, acc: 0.555, loss: 1.697 (data_loss: 1.697, reg_loss: 0.000), lr: 0.0009972674870853862\n",
      "step: 275, acc: 0.555, loss: 1.700 (data_loss: 1.700, reg_loss: 0.000), lr: 0.0009972575417601596\n",
      "step: 276, acc: 0.625, loss: 1.665 (data_loss: 1.665, reg_loss: 0.000), lr: 0.000997247596633292\n",
      "step: 277, acc: 0.602, loss: 1.644 (data_loss: 1.644, reg_loss: 0.000), lr: 0.0009972376517047778\n",
      "step: 278, acc: 0.641, loss: 1.643 (data_loss: 1.643, reg_loss: 0.000), lr: 0.0009972277069746106\n",
      "step: 279, acc: 0.586, loss: 1.669 (data_loss: 1.669, reg_loss: 0.000), lr: 0.0009972177624427846\n",
      "step: 280, acc: 0.672, loss: 1.613 (data_loss: 1.613, reg_loss: 0.000), lr: 0.000997207818109294\n",
      "step: 281, acc: 0.617, loss: 1.651 (data_loss: 1.651, reg_loss: 0.000), lr: 0.0009971978739741327\n",
      "step: 282, acc: 0.570, loss: 1.652 (data_loss: 1.652, reg_loss: 0.000), lr: 0.0009971879300372949\n",
      "step: 283, acc: 0.562, loss: 1.627 (data_loss: 1.627, reg_loss: 0.000), lr: 0.0009971779862987743\n",
      "step: 284, acc: 0.633, loss: 1.637 (data_loss: 1.637, reg_loss: 0.000), lr: 0.0009971680427585657\n",
      "step: 285, acc: 0.711, loss: 1.566 (data_loss: 1.566, reg_loss: 0.000), lr: 0.0009971580994166626\n",
      "step: 286, acc: 0.672, loss: 1.585 (data_loss: 1.585, reg_loss: 0.000), lr: 0.000997148156273059\n",
      "step: 287, acc: 0.562, loss: 1.660 (data_loss: 1.660, reg_loss: 0.000), lr: 0.0009971382133277494\n",
      "step: 288, acc: 0.617, loss: 1.626 (data_loss: 1.626, reg_loss: 0.000), lr: 0.0009971282705807274\n",
      "step: 289, acc: 0.609, loss: 1.593 (data_loss: 1.593, reg_loss: 0.000), lr: 0.0009971183280319876\n",
      "step: 290, acc: 0.648, loss: 1.585 (data_loss: 1.585, reg_loss: 0.000), lr: 0.0009971083856815236\n",
      "step: 291, acc: 0.594, loss: 1.587 (data_loss: 1.587, reg_loss: 0.000), lr: 0.0009970984435293297\n",
      "step: 292, acc: 0.602, loss: 1.614 (data_loss: 1.614, reg_loss: 0.000), lr: 0.0009970885015753998\n",
      "step: 293, acc: 0.664, loss: 1.559 (data_loss: 1.559, reg_loss: 0.000), lr: 0.000997078559819728\n",
      "step: 294, acc: 0.617, loss: 1.599 (data_loss: 1.599, reg_loss: 0.000), lr: 0.0009970686182623088\n",
      "step: 295, acc: 0.602, loss: 1.605 (data_loss: 1.605, reg_loss: 0.000), lr: 0.0009970586769031359\n",
      "step: 296, acc: 0.672, loss: 1.571 (data_loss: 1.571, reg_loss: 0.000), lr: 0.000997048735742203\n",
      "step: 297, acc: 0.633, loss: 1.576 (data_loss: 1.576, reg_loss: 0.000), lr: 0.000997038794779505\n",
      "step: 298, acc: 0.602, loss: 1.597 (data_loss: 1.597, reg_loss: 0.000), lr: 0.0009970288540150352\n",
      "step: 299, acc: 0.609, loss: 1.587 (data_loss: 1.587, reg_loss: 0.000), lr: 0.000997018913448788\n",
      "step: 300, acc: 0.656, loss: 1.562 (data_loss: 1.562, reg_loss: 0.000), lr: 0.0009970089730807579\n",
      "step: 301, acc: 0.586, loss: 1.589 (data_loss: 1.589, reg_loss: 0.000), lr: 0.0009969990329109382\n",
      "step: 302, acc: 0.594, loss: 1.599 (data_loss: 1.599, reg_loss: 0.000), lr: 0.0009969890929393233\n",
      "step: 303, acc: 0.641, loss: 1.556 (data_loss: 1.556, reg_loss: 0.000), lr: 0.0009969791531659073\n",
      "step: 304, acc: 0.625, loss: 1.602 (data_loss: 1.602, reg_loss: 0.000), lr: 0.0009969692135906843\n",
      "step: 305, acc: 0.648, loss: 1.564 (data_loss: 1.564, reg_loss: 0.000), lr: 0.0009969592742136485\n",
      "step: 306, acc: 0.641, loss: 1.531 (data_loss: 1.531, reg_loss: 0.000), lr: 0.0009969493350347935\n",
      "step: 307, acc: 0.664, loss: 1.544 (data_loss: 1.544, reg_loss: 0.000), lr: 0.000996939396054114\n",
      "step: 308, acc: 0.648, loss: 1.561 (data_loss: 1.561, reg_loss: 0.000), lr: 0.0009969294572716035\n",
      "step: 309, acc: 0.656, loss: 1.586 (data_loss: 1.586, reg_loss: 0.000), lr: 0.0009969195186872563\n",
      "step: 310, acc: 0.680, loss: 1.514 (data_loss: 1.514, reg_loss: 0.000), lr: 0.0009969095803010666\n",
      "step: 311, acc: 0.641, loss: 1.544 (data_loss: 1.544, reg_loss: 0.000), lr: 0.0009968996421130284\n",
      "step: 312, acc: 0.656, loss: 1.555 (data_loss: 1.555, reg_loss: 0.000), lr: 0.0009968897041231358\n",
      "step: 313, acc: 0.680, loss: 1.531 (data_loss: 1.531, reg_loss: 0.000), lr: 0.0009968797663313827\n",
      "step: 314, acc: 0.633, loss: 1.528 (data_loss: 1.528, reg_loss: 0.000), lr: 0.0009968698287377636\n",
      "step: 315, acc: 0.609, loss: 1.559 (data_loss: 1.559, reg_loss: 0.000), lr: 0.0009968598913422718\n",
      "step: 316, acc: 0.680, loss: 1.492 (data_loss: 1.492, reg_loss: 0.000), lr: 0.0009968499541449021\n",
      "step: 317, acc: 0.633, loss: 1.503 (data_loss: 1.503, reg_loss: 0.000), lr: 0.0009968400171456483\n",
      "step: 318, acc: 0.625, loss: 1.556 (data_loss: 1.556, reg_loss: 0.000), lr: 0.0009968300803445045\n",
      "step: 319, acc: 0.680, loss: 1.492 (data_loss: 1.492, reg_loss: 0.000), lr: 0.0009968201437414647\n",
      "step: 320, acc: 0.609, loss: 1.525 (data_loss: 1.525, reg_loss: 0.000), lr: 0.000996810207336523\n",
      "step: 321, acc: 0.625, loss: 1.546 (data_loss: 1.546, reg_loss: 0.000), lr: 0.0009968002711296738\n",
      "step: 322, acc: 0.703, loss: 1.497 (data_loss: 1.497, reg_loss: 0.000), lr: 0.0009967903351209106\n",
      "step: 323, acc: 0.680, loss: 1.472 (data_loss: 1.472, reg_loss: 0.000), lr: 0.000996780399310228\n",
      "step: 324, acc: 0.641, loss: 1.502 (data_loss: 1.502, reg_loss: 0.000), lr: 0.00099677046369762\n",
      "step: 325, acc: 0.648, loss: 1.513 (data_loss: 1.513, reg_loss: 0.000), lr: 0.00099676052828308\n",
      "step: 326, acc: 0.617, loss: 1.502 (data_loss: 1.502, reg_loss: 0.000), lr: 0.0009967505930666028\n",
      "step: 327, acc: 0.648, loss: 1.512 (data_loss: 1.512, reg_loss: 0.000), lr: 0.0009967406580481824\n",
      "step: 328, acc: 0.664, loss: 1.502 (data_loss: 1.502, reg_loss: 0.000), lr: 0.0009967307232278128\n",
      "step: 329, acc: 0.672, loss: 1.452 (data_loss: 1.452, reg_loss: 0.000), lr: 0.000996720788605488\n",
      "step: 330, acc: 0.656, loss: 1.483 (data_loss: 1.483, reg_loss: 0.000), lr: 0.000996710854181202\n",
      "step: 331, acc: 0.711, loss: 1.488 (data_loss: 1.488, reg_loss: 0.000), lr: 0.0009967009199549493\n",
      "step: 332, acc: 0.680, loss: 1.479 (data_loss: 1.479, reg_loss: 0.000), lr: 0.0009966909859267235\n",
      "step: 333, acc: 0.625, loss: 1.501 (data_loss: 1.501, reg_loss: 0.000), lr: 0.0009966810520965186\n",
      "step: 334, acc: 0.633, loss: 1.560 (data_loss: 1.560, reg_loss: 0.000), lr: 0.0009966711184643292\n",
      "step: 335, acc: 0.680, loss: 1.453 (data_loss: 1.453, reg_loss: 0.000), lr: 0.000996661185030149\n",
      "step: 336, acc: 0.602, loss: 1.482 (data_loss: 1.482, reg_loss: 0.000), lr: 0.0009966512517939723\n",
      "step: 337, acc: 0.688, loss: 1.455 (data_loss: 1.455, reg_loss: 0.000), lr: 0.000996641318755793\n",
      "step: 338, acc: 0.703, loss: 1.429 (data_loss: 1.429, reg_loss: 0.000), lr: 0.0009966313859156052\n",
      "step: 339, acc: 0.680, loss: 1.476 (data_loss: 1.476, reg_loss: 0.000), lr: 0.0009966214532734032\n",
      "step: 340, acc: 0.664, loss: 1.410 (data_loss: 1.410, reg_loss: 0.000), lr: 0.0009966115208291807\n",
      "step: 341, acc: 0.633, loss: 1.476 (data_loss: 1.476, reg_loss: 0.000), lr: 0.0009966015885829323\n",
      "step: 342, acc: 0.664, loss: 1.473 (data_loss: 1.473, reg_loss: 0.000), lr: 0.0009965916565346515\n",
      "step: 343, acc: 0.617, loss: 1.432 (data_loss: 1.432, reg_loss: 0.000), lr: 0.0009965817246843328\n",
      "step: 344, acc: 0.719, loss: 1.417 (data_loss: 1.417, reg_loss: 0.000), lr: 0.00099657179303197\n",
      "step: 345, acc: 0.695, loss: 1.455 (data_loss: 1.455, reg_loss: 0.000), lr: 0.0009965618615775575\n",
      "step: 346, acc: 0.688, loss: 1.478 (data_loss: 1.478, reg_loss: 0.000), lr: 0.000996551930321089\n",
      "step: 347, acc: 0.688, loss: 1.433 (data_loss: 1.433, reg_loss: 0.000), lr: 0.0009965419992625589\n",
      "step: 348, acc: 0.664, loss: 1.437 (data_loss: 1.437, reg_loss: 0.000), lr: 0.0009965320684019612\n",
      "step: 349, acc: 0.742, loss: 1.456 (data_loss: 1.456, reg_loss: 0.000), lr: 0.00099652213773929\n",
      "step: 350, acc: 0.680, loss: 1.457 (data_loss: 1.457, reg_loss: 0.000), lr: 0.000996512207274539\n",
      "step: 351, acc: 0.664, loss: 1.419 (data_loss: 1.419, reg_loss: 0.000), lr: 0.000996502277007703\n",
      "step: 352, acc: 0.617, loss: 1.449 (data_loss: 1.449, reg_loss: 0.000), lr: 0.0009964923469387755\n",
      "step: 353, acc: 0.586, loss: 1.457 (data_loss: 1.457, reg_loss: 0.000), lr: 0.0009964824170677507\n",
      "step: 354, acc: 0.656, loss: 1.440 (data_loss: 1.440, reg_loss: 0.000), lr: 0.000996472487394623\n",
      "step: 355, acc: 0.672, loss: 1.415 (data_loss: 1.415, reg_loss: 0.000), lr: 0.0009964625579193863\n",
      "step: 356, acc: 0.609, loss: 1.452 (data_loss: 1.452, reg_loss: 0.000), lr: 0.0009964526286420344\n",
      "step: 357, acc: 0.727, loss: 1.363 (data_loss: 1.363, reg_loss: 0.000), lr: 0.0009964426995625617\n",
      "step: 358, acc: 0.688, loss: 1.374 (data_loss: 1.374, reg_loss: 0.000), lr: 0.0009964327706809622\n",
      "step: 359, acc: 0.711, loss: 1.367 (data_loss: 1.367, reg_loss: 0.000), lr: 0.00099642284199723\n",
      "step: 360, acc: 0.664, loss: 1.410 (data_loss: 1.410, reg_loss: 0.000), lr: 0.0009964129135113591\n",
      "step: 361, acc: 0.672, loss: 1.372 (data_loss: 1.372, reg_loss: 0.000), lr: 0.0009964029852233438\n",
      "step: 362, acc: 0.648, loss: 1.360 (data_loss: 1.360, reg_loss: 0.000), lr: 0.000996393057133178\n",
      "step: 363, acc: 0.664, loss: 1.391 (data_loss: 1.391, reg_loss: 0.000), lr: 0.0009963831292408556\n",
      "step: 364, acc: 0.664, loss: 1.374 (data_loss: 1.374, reg_loss: 0.000), lr: 0.0009963732015463712\n",
      "step: 365, acc: 0.695, loss: 1.399 (data_loss: 1.399, reg_loss: 0.000), lr: 0.0009963632740497186\n",
      "step: 366, acc: 0.633, loss: 1.402 (data_loss: 1.402, reg_loss: 0.000), lr: 0.0009963533467508916\n",
      "step: 367, acc: 0.727, loss: 1.315 (data_loss: 1.315, reg_loss: 0.000), lr: 0.000996343419649885\n",
      "step: 368, acc: 0.648, loss: 1.358 (data_loss: 1.358, reg_loss: 0.000), lr: 0.0009963334927466923\n",
      "step: 369, acc: 0.680, loss: 1.397 (data_loss: 1.397, reg_loss: 0.000), lr: 0.0009963235660413075\n",
      "step: 370, acc: 0.672, loss: 1.392 (data_loss: 1.392, reg_loss: 0.000), lr: 0.0009963136395337252\n",
      "step: 371, acc: 0.688, loss: 1.318 (data_loss: 1.318, reg_loss: 0.000), lr: 0.0009963037132239391\n",
      "step: 372, acc: 0.680, loss: 1.354 (data_loss: 1.354, reg_loss: 0.000), lr: 0.0009962937871119436\n",
      "step: 373, acc: 0.727, loss: 1.337 (data_loss: 1.337, reg_loss: 0.000), lr: 0.0009962838611977324\n",
      "step: 374, acc: 0.680, loss: 1.339 (data_loss: 1.339, reg_loss: 0.000), lr: 0.0009962739354812998\n",
      "step: 375, acc: 0.695, loss: 1.394 (data_loss: 1.394, reg_loss: 0.000), lr: 0.0009962640099626403\n",
      "step: 376, acc: 0.672, loss: 1.351 (data_loss: 1.351, reg_loss: 0.000), lr: 0.000996254084641747\n",
      "step: 377, acc: 0.719, loss: 1.316 (data_loss: 1.316, reg_loss: 0.000), lr: 0.0009962441595186148\n",
      "step: 378, acc: 0.664, loss: 1.343 (data_loss: 1.343, reg_loss: 0.000), lr: 0.0009962342345932378\n",
      "step: 379, acc: 0.688, loss: 1.392 (data_loss: 1.392, reg_loss: 0.000), lr: 0.0009962243098656095\n",
      "step: 380, acc: 0.672, loss: 1.388 (data_loss: 1.388, reg_loss: 0.000), lr: 0.0009962143853357243\n",
      "step: 381, acc: 0.719, loss: 1.357 (data_loss: 1.357, reg_loss: 0.000), lr: 0.0009962044610035763\n",
      "step: 382, acc: 0.664, loss: 1.336 (data_loss: 1.336, reg_loss: 0.000), lr: 0.0009961945368691597\n",
      "step: 383, acc: 0.656, loss: 1.345 (data_loss: 1.345, reg_loss: 0.000), lr: 0.0009961846129324687\n",
      "step: 384, acc: 0.648, loss: 1.396 (data_loss: 1.396, reg_loss: 0.000), lr: 0.000996174689193497\n",
      "step: 385, acc: 0.695, loss: 1.317 (data_loss: 1.317, reg_loss: 0.000), lr: 0.000996164765652239\n",
      "step: 386, acc: 0.688, loss: 1.364 (data_loss: 1.364, reg_loss: 0.000), lr: 0.0009961548423086885\n",
      "step: 387, acc: 0.719, loss: 1.278 (data_loss: 1.278, reg_loss: 0.000), lr: 0.0009961449191628398\n",
      "step: 388, acc: 0.734, loss: 1.304 (data_loss: 1.304, reg_loss: 0.000), lr: 0.000996134996214687\n",
      "step: 389, acc: 0.703, loss: 1.283 (data_loss: 1.283, reg_loss: 0.000), lr: 0.0009961250734642241\n",
      "step: 390, acc: 0.787, loss: 1.270 (data_loss: 1.270, reg_loss: 0.000), lr: 0.0009961151509114453\n",
      "training, acc: 0.461, loss: 1.895 (data_loss: 1.895, reg_loss: 0.000), lr: 0.0009961151509114453\n",
      "validation, acc: 0.701, loss: 1.316\n",
      "epoch: 2\n",
      "step: 0, acc: 0.609, loss: 1.351 (data_loss: 1.351, reg_loss: 0.000), lr: 0.0009961052285563446\n",
      "step: 1, acc: 0.719, loss: 1.350 (data_loss: 1.350, reg_loss: 0.000), lr: 0.0009960953063989162\n",
      "step: 2, acc: 0.672, loss: 1.341 (data_loss: 1.341, reg_loss: 0.000), lr: 0.0009960853844391542\n",
      "step: 3, acc: 0.688, loss: 1.310 (data_loss: 1.310, reg_loss: 0.000), lr: 0.0009960754626770524\n",
      "step: 4, acc: 0.695, loss: 1.329 (data_loss: 1.329, reg_loss: 0.000), lr: 0.0009960655411126052\n",
      "step: 5, acc: 0.664, loss: 1.341 (data_loss: 1.341, reg_loss: 0.000), lr: 0.0009960556197458068\n",
      "step: 6, acc: 0.688, loss: 1.335 (data_loss: 1.335, reg_loss: 0.000), lr: 0.0009960456985766508\n",
      "step: 7, acc: 0.711, loss: 1.264 (data_loss: 1.264, reg_loss: 0.000), lr: 0.0009960357776051315\n",
      "step: 8, acc: 0.719, loss: 1.271 (data_loss: 1.271, reg_loss: 0.000), lr: 0.0009960258568312435\n",
      "step: 9, acc: 0.680, loss: 1.336 (data_loss: 1.336, reg_loss: 0.000), lr: 0.00099601593625498\n",
      "step: 10, acc: 0.734, loss: 1.287 (data_loss: 1.287, reg_loss: 0.000), lr: 0.0009960060158763359\n",
      "step: 11, acc: 0.727, loss: 1.288 (data_loss: 1.288, reg_loss: 0.000), lr: 0.000995996095695305\n",
      "step: 12, acc: 0.688, loss: 1.272 (data_loss: 1.272, reg_loss: 0.000), lr: 0.0009959861757118812\n",
      "step: 13, acc: 0.648, loss: 1.313 (data_loss: 1.313, reg_loss: 0.000), lr: 0.0009959762559260588\n",
      "step: 14, acc: 0.703, loss: 1.267 (data_loss: 1.267, reg_loss: 0.000), lr: 0.0009959663363378318\n",
      "step: 15, acc: 0.734, loss: 1.295 (data_loss: 1.295, reg_loss: 0.000), lr: 0.0009959564169471943\n",
      "step: 16, acc: 0.742, loss: 1.260 (data_loss: 1.260, reg_loss: 0.000), lr: 0.0009959464977541408\n",
      "step: 17, acc: 0.703, loss: 1.250 (data_loss: 1.250, reg_loss: 0.000), lr: 0.0009959365787586647\n",
      "step: 18, acc: 0.633, loss: 1.361 (data_loss: 1.361, reg_loss: 0.000), lr: 0.0009959266599607606\n",
      "step: 19, acc: 0.656, loss: 1.298 (data_loss: 1.298, reg_loss: 0.000), lr: 0.0009959167413604224\n",
      "step: 20, acc: 0.695, loss: 1.290 (data_loss: 1.290, reg_loss: 0.000), lr: 0.000995906822957644\n",
      "step: 21, acc: 0.695, loss: 1.298 (data_loss: 1.298, reg_loss: 0.000), lr: 0.0009958969047524201\n",
      "step: 22, acc: 0.758, loss: 1.238 (data_loss: 1.238, reg_loss: 0.000), lr: 0.0009958869867447442\n",
      "step: 23, acc: 0.711, loss: 1.246 (data_loss: 1.246, reg_loss: 0.000), lr: 0.0009958770689346107\n",
      "step: 24, acc: 0.727, loss: 1.222 (data_loss: 1.222, reg_loss: 0.000), lr: 0.0009958671513220136\n",
      "step: 25, acc: 0.727, loss: 1.258 (data_loss: 1.258, reg_loss: 0.000), lr: 0.0009958572339069471\n",
      "step: 26, acc: 0.695, loss: 1.271 (data_loss: 1.271, reg_loss: 0.000), lr: 0.0009958473166894052\n",
      "step: 27, acc: 0.742, loss: 1.245 (data_loss: 1.245, reg_loss: 0.000), lr: 0.0009958373996693819\n",
      "step: 28, acc: 0.695, loss: 1.279 (data_loss: 1.279, reg_loss: 0.000), lr: 0.0009958274828468718\n",
      "step: 29, acc: 0.727, loss: 1.263 (data_loss: 1.263, reg_loss: 0.000), lr: 0.0009958175662218682\n",
      "step: 30, acc: 0.719, loss: 1.226 (data_loss: 1.226, reg_loss: 0.000), lr: 0.0009958076497943657\n",
      "step: 31, acc: 0.695, loss: 1.283 (data_loss: 1.283, reg_loss: 0.000), lr: 0.0009957977335643587\n",
      "step: 32, acc: 0.719, loss: 1.218 (data_loss: 1.218, reg_loss: 0.000), lr: 0.0009957878175318403\n",
      "step: 33, acc: 0.727, loss: 1.263 (data_loss: 1.263, reg_loss: 0.000), lr: 0.0009957779016968055\n",
      "step: 34, acc: 0.727, loss: 1.263 (data_loss: 1.263, reg_loss: 0.000), lr: 0.0009957679860592482\n",
      "step: 35, acc: 0.695, loss: 1.248 (data_loss: 1.248, reg_loss: 0.000), lr: 0.0009957580706191624\n",
      "step: 36, acc: 0.711, loss: 1.247 (data_loss: 1.247, reg_loss: 0.000), lr: 0.0009957481553765422\n",
      "step: 37, acc: 0.758, loss: 1.193 (data_loss: 1.193, reg_loss: 0.000), lr: 0.0009957382403313817\n",
      "step: 38, acc: 0.641, loss: 1.288 (data_loss: 1.288, reg_loss: 0.000), lr: 0.0009957283254836751\n",
      "step: 39, acc: 0.719, loss: 1.236 (data_loss: 1.236, reg_loss: 0.000), lr: 0.0009957184108334164\n",
      "step: 40, acc: 0.711, loss: 1.228 (data_loss: 1.228, reg_loss: 0.000), lr: 0.0009957084963805995\n",
      "step: 41, acc: 0.750, loss: 1.218 (data_loss: 1.218, reg_loss: 0.000), lr: 0.000995698582125219\n",
      "step: 42, acc: 0.688, loss: 1.274 (data_loss: 1.274, reg_loss: 0.000), lr: 0.0009956886680672688\n",
      "step: 43, acc: 0.664, loss: 1.224 (data_loss: 1.224, reg_loss: 0.000), lr: 0.0009956787542067427\n",
      "step: 44, acc: 0.680, loss: 1.252 (data_loss: 1.252, reg_loss: 0.000), lr: 0.0009956688405436352\n",
      "step: 45, acc: 0.672, loss: 1.222 (data_loss: 1.222, reg_loss: 0.000), lr: 0.0009956589270779402\n",
      "step: 46, acc: 0.750, loss: 1.225 (data_loss: 1.225, reg_loss: 0.000), lr: 0.000995649013809652\n",
      "step: 47, acc: 0.703, loss: 1.274 (data_loss: 1.274, reg_loss: 0.000), lr: 0.000995639100738764\n",
      "step: 48, acc: 0.750, loss: 1.183 (data_loss: 1.183, reg_loss: 0.000), lr: 0.0009956291878652716\n",
      "step: 49, acc: 0.711, loss: 1.179 (data_loss: 1.179, reg_loss: 0.000), lr: 0.0009956192751891678\n",
      "step: 50, acc: 0.703, loss: 1.201 (data_loss: 1.201, reg_loss: 0.000), lr: 0.000995609362710447\n",
      "step: 51, acc: 0.727, loss: 1.230 (data_loss: 1.230, reg_loss: 0.000), lr: 0.0009955994504291033\n",
      "step: 52, acc: 0.719, loss: 1.216 (data_loss: 1.216, reg_loss: 0.000), lr: 0.0009955895383451311\n",
      "step: 53, acc: 0.648, loss: 1.316 (data_loss: 1.316, reg_loss: 0.000), lr: 0.0009955796264585243\n",
      "step: 54, acc: 0.719, loss: 1.202 (data_loss: 1.202, reg_loss: 0.000), lr: 0.0009955697147692767\n",
      "step: 55, acc: 0.695, loss: 1.285 (data_loss: 1.285, reg_loss: 0.000), lr: 0.000995559803277383\n",
      "step: 56, acc: 0.695, loss: 1.244 (data_loss: 1.244, reg_loss: 0.000), lr: 0.0009955498919828366\n",
      "step: 57, acc: 0.797, loss: 1.160 (data_loss: 1.160, reg_loss: 0.000), lr: 0.0009955399808856324\n",
      "step: 58, acc: 0.758, loss: 1.165 (data_loss: 1.165, reg_loss: 0.000), lr: 0.0009955300699857638\n",
      "step: 59, acc: 0.727, loss: 1.227 (data_loss: 1.227, reg_loss: 0.000), lr: 0.0009955201592832257\n",
      "step: 60, acc: 0.734, loss: 1.233 (data_loss: 1.233, reg_loss: 0.000), lr: 0.0009955102487780112\n",
      "step: 61, acc: 0.664, loss: 1.174 (data_loss: 1.174, reg_loss: 0.000), lr: 0.000995500338470115\n",
      "step: 62, acc: 0.742, loss: 1.223 (data_loss: 1.223, reg_loss: 0.000), lr: 0.0009954904283595314\n",
      "step: 63, acc: 0.773, loss: 1.211 (data_loss: 1.211, reg_loss: 0.000), lr: 0.000995480518446254\n",
      "step: 64, acc: 0.664, loss: 1.197 (data_loss: 1.197, reg_loss: 0.000), lr: 0.0009954706087302772\n",
      "step: 65, acc: 0.680, loss: 1.283 (data_loss: 1.283, reg_loss: 0.000), lr: 0.0009954606992115952\n",
      "step: 66, acc: 0.766, loss: 1.152 (data_loss: 1.152, reg_loss: 0.000), lr: 0.0009954507898902018\n",
      "step: 67, acc: 0.734, loss: 1.269 (data_loss: 1.269, reg_loss: 0.000), lr: 0.0009954408807660914\n",
      "step: 68, acc: 0.742, loss: 1.193 (data_loss: 1.193, reg_loss: 0.000), lr: 0.0009954309718392578\n",
      "step: 69, acc: 0.727, loss: 1.187 (data_loss: 1.187, reg_loss: 0.000), lr: 0.0009954210631096954\n",
      "step: 70, acc: 0.711, loss: 1.116 (data_loss: 1.116, reg_loss: 0.000), lr: 0.0009954111545773983\n",
      "step: 71, acc: 0.742, loss: 1.136 (data_loss: 1.136, reg_loss: 0.000), lr: 0.0009954012462423602\n",
      "step: 72, acc: 0.750, loss: 1.174 (data_loss: 1.174, reg_loss: 0.000), lr: 0.000995391338104576\n",
      "step: 73, acc: 0.742, loss: 1.135 (data_loss: 1.135, reg_loss: 0.000), lr: 0.000995381430164039\n",
      "step: 74, acc: 0.680, loss: 1.255 (data_loss: 1.255, reg_loss: 0.000), lr: 0.0009953715224207435\n",
      "step: 75, acc: 0.695, loss: 1.227 (data_loss: 1.227, reg_loss: 0.000), lr: 0.0009953616148746839\n",
      "step: 76, acc: 0.680, loss: 1.129 (data_loss: 1.129, reg_loss: 0.000), lr: 0.0009953517075258543\n",
      "step: 77, acc: 0.828, loss: 1.096 (data_loss: 1.096, reg_loss: 0.000), lr: 0.0009953418003742485\n",
      "step: 78, acc: 0.680, loss: 1.230 (data_loss: 1.230, reg_loss: 0.000), lr: 0.0009953318934198608\n",
      "step: 79, acc: 0.719, loss: 1.200 (data_loss: 1.200, reg_loss: 0.000), lr: 0.0009953219866626855\n",
      "step: 80, acc: 0.680, loss: 1.181 (data_loss: 1.181, reg_loss: 0.000), lr: 0.0009953120801027163\n",
      "step: 81, acc: 0.703, loss: 1.194 (data_loss: 1.194, reg_loss: 0.000), lr: 0.0009953021737399473\n",
      "step: 82, acc: 0.742, loss: 1.102 (data_loss: 1.102, reg_loss: 0.000), lr: 0.0009952922675743733\n",
      "step: 83, acc: 0.711, loss: 1.184 (data_loss: 1.184, reg_loss: 0.000), lr: 0.0009952823616059877\n",
      "step: 84, acc: 0.688, loss: 1.212 (data_loss: 1.212, reg_loss: 0.000), lr: 0.0009952724558347848\n",
      "step: 85, acc: 0.734, loss: 1.164 (data_loss: 1.164, reg_loss: 0.000), lr: 0.0009952625502607586\n",
      "step: 86, acc: 0.758, loss: 1.177 (data_loss: 1.177, reg_loss: 0.000), lr: 0.000995252644883904\n",
      "step: 87, acc: 0.711, loss: 1.186 (data_loss: 1.186, reg_loss: 0.000), lr: 0.0009952427397042138\n",
      "step: 88, acc: 0.672, loss: 1.224 (data_loss: 1.224, reg_loss: 0.000), lr: 0.0009952328347216832\n",
      "step: 89, acc: 0.789, loss: 1.106 (data_loss: 1.106, reg_loss: 0.000), lr: 0.0009952229299363057\n",
      "step: 90, acc: 0.750, loss: 1.108 (data_loss: 1.108, reg_loss: 0.000), lr: 0.0009952130253480759\n",
      "step: 91, acc: 0.734, loss: 1.102 (data_loss: 1.102, reg_loss: 0.000), lr: 0.0009952031209569873\n",
      "step: 92, acc: 0.750, loss: 1.159 (data_loss: 1.159, reg_loss: 0.000), lr: 0.0009951932167630347\n",
      "step: 93, acc: 0.742, loss: 1.106 (data_loss: 1.106, reg_loss: 0.000), lr: 0.0009951833127662115\n",
      "step: 94, acc: 0.734, loss: 1.152 (data_loss: 1.152, reg_loss: 0.000), lr: 0.0009951734089665124\n",
      "step: 95, acc: 0.734, loss: 1.186 (data_loss: 1.186, reg_loss: 0.000), lr: 0.0009951635053639311\n",
      "step: 96, acc: 0.727, loss: 1.122 (data_loss: 1.122, reg_loss: 0.000), lr: 0.0009951536019584624\n",
      "step: 97, acc: 0.789, loss: 1.106 (data_loss: 1.106, reg_loss: 0.000), lr: 0.0009951436987500996\n",
      "step: 98, acc: 0.688, loss: 1.182 (data_loss: 1.182, reg_loss: 0.000), lr: 0.000995133795738837\n",
      "step: 99, acc: 0.758, loss: 1.104 (data_loss: 1.104, reg_loss: 0.000), lr: 0.0009951238929246692\n",
      "step: 100, acc: 0.734, loss: 1.155 (data_loss: 1.155, reg_loss: 0.000), lr: 0.0009951139903075898\n",
      "step: 101, acc: 0.766, loss: 1.091 (data_loss: 1.091, reg_loss: 0.000), lr: 0.000995104087887593\n",
      "step: 102, acc: 0.758, loss: 1.087 (data_loss: 1.087, reg_loss: 0.000), lr: 0.000995094185664673\n",
      "step: 103, acc: 0.719, loss: 1.216 (data_loss: 1.216, reg_loss: 0.000), lr: 0.0009950842836388243\n",
      "step: 104, acc: 0.703, loss: 1.144 (data_loss: 1.144, reg_loss: 0.000), lr: 0.0009950743818100403\n",
      "step: 105, acc: 0.766, loss: 1.071 (data_loss: 1.071, reg_loss: 0.000), lr: 0.0009950644801783154\n",
      "step: 106, acc: 0.812, loss: 1.059 (data_loss: 1.059, reg_loss: 0.000), lr: 0.0009950545787436441\n",
      "step: 107, acc: 0.664, loss: 1.266 (data_loss: 1.266, reg_loss: 0.000), lr: 0.00099504467750602\n",
      "step: 108, acc: 0.758, loss: 1.106 (data_loss: 1.106, reg_loss: 0.000), lr: 0.0009950347764654374\n",
      "step: 109, acc: 0.758, loss: 1.031 (data_loss: 1.031, reg_loss: 0.000), lr: 0.0009950248756218907\n",
      "step: 110, acc: 0.812, loss: 1.040 (data_loss: 1.040, reg_loss: 0.000), lr: 0.0009950149749753735\n",
      "step: 111, acc: 0.750, loss: 1.105 (data_loss: 1.105, reg_loss: 0.000), lr: 0.00099500507452588\n",
      "step: 112, acc: 0.719, loss: 1.168 (data_loss: 1.168, reg_loss: 0.000), lr: 0.0009949951742734048\n",
      "step: 113, acc: 0.742, loss: 1.111 (data_loss: 1.111, reg_loss: 0.000), lr: 0.0009949852742179416\n",
      "step: 114, acc: 0.727, loss: 1.117 (data_loss: 1.117, reg_loss: 0.000), lr: 0.0009949753743594845\n",
      "step: 115, acc: 0.820, loss: 1.085 (data_loss: 1.085, reg_loss: 0.000), lr: 0.0009949654746980278\n",
      "step: 116, acc: 0.734, loss: 1.149 (data_loss: 1.149, reg_loss: 0.000), lr: 0.000994955575233566\n",
      "step: 117, acc: 0.742, loss: 1.074 (data_loss: 1.074, reg_loss: 0.000), lr: 0.0009949456759660922\n",
      "step: 118, acc: 0.742, loss: 1.102 (data_loss: 1.102, reg_loss: 0.000), lr: 0.0009949357768956014\n",
      "step: 119, acc: 0.719, loss: 1.108 (data_loss: 1.108, reg_loss: 0.000), lr: 0.0009949258780220871\n",
      "step: 120, acc: 0.805, loss: 1.042 (data_loss: 1.042, reg_loss: 0.000), lr: 0.0009949159793455444\n",
      "step: 121, acc: 0.766, loss: 1.090 (data_loss: 1.090, reg_loss: 0.000), lr: 0.0009949060808659663\n",
      "step: 122, acc: 0.742, loss: 1.089 (data_loss: 1.089, reg_loss: 0.000), lr: 0.0009948961825833474\n",
      "step: 123, acc: 0.727, loss: 1.120 (data_loss: 1.120, reg_loss: 0.000), lr: 0.000994886284497682\n",
      "step: 124, acc: 0.750, loss: 1.087 (data_loss: 1.087, reg_loss: 0.000), lr: 0.0009948763866089638\n",
      "step: 125, acc: 0.766, loss: 1.094 (data_loss: 1.094, reg_loss: 0.000), lr: 0.0009948664889171872\n",
      "step: 126, acc: 0.680, loss: 1.121 (data_loss: 1.121, reg_loss: 0.000), lr: 0.0009948565914223466\n",
      "step: 127, acc: 0.836, loss: 1.019 (data_loss: 1.019, reg_loss: 0.000), lr: 0.0009948466941244354\n",
      "step: 128, acc: 0.742, loss: 1.143 (data_loss: 1.143, reg_loss: 0.000), lr: 0.0009948367970234484\n",
      "step: 129, acc: 0.820, loss: 1.015 (data_loss: 1.015, reg_loss: 0.000), lr: 0.000994826900119379\n",
      "step: 130, acc: 0.711, loss: 1.139 (data_loss: 1.139, reg_loss: 0.000), lr: 0.0009948170034122224\n",
      "step: 131, acc: 0.672, loss: 1.168 (data_loss: 1.168, reg_loss: 0.000), lr: 0.0009948071069019718\n",
      "step: 132, acc: 0.742, loss: 1.081 (data_loss: 1.081, reg_loss: 0.000), lr: 0.0009947972105886216\n",
      "step: 133, acc: 0.734, loss: 1.077 (data_loss: 1.077, reg_loss: 0.000), lr: 0.000994787314472166\n",
      "step: 134, acc: 0.812, loss: 1.051 (data_loss: 1.051, reg_loss: 0.000), lr: 0.000994777418552599\n",
      "step: 135, acc: 0.797, loss: 1.023 (data_loss: 1.023, reg_loss: 0.000), lr: 0.0009947675228299147\n",
      "step: 136, acc: 0.758, loss: 1.043 (data_loss: 1.043, reg_loss: 0.000), lr: 0.0009947576273041073\n",
      "step: 137, acc: 0.805, loss: 1.014 (data_loss: 1.014, reg_loss: 0.000), lr: 0.0009947477319751713\n",
      "step: 138, acc: 0.758, loss: 1.074 (data_loss: 1.074, reg_loss: 0.000), lr: 0.0009947378368431001\n",
      "step: 139, acc: 0.703, loss: 1.071 (data_loss: 1.071, reg_loss: 0.000), lr: 0.0009947279419078882\n",
      "step: 140, acc: 0.742, loss: 1.073 (data_loss: 1.073, reg_loss: 0.000), lr: 0.00099471804716953\n",
      "step: 141, acc: 0.805, loss: 1.076 (data_loss: 1.076, reg_loss: 0.000), lr: 0.000994708152628019\n",
      "step: 142, acc: 0.812, loss: 0.987 (data_loss: 0.987, reg_loss: 0.000), lr: 0.0009946982582833496\n",
      "step: 143, acc: 0.789, loss: 1.083 (data_loss: 1.083, reg_loss: 0.000), lr: 0.0009946883641355165\n",
      "step: 144, acc: 0.727, loss: 1.069 (data_loss: 1.069, reg_loss: 0.000), lr: 0.000994678470184513\n",
      "step: 145, acc: 0.781, loss: 1.030 (data_loss: 1.030, reg_loss: 0.000), lr: 0.0009946685764303334\n",
      "step: 146, acc: 0.734, loss: 1.160 (data_loss: 1.160, reg_loss: 0.000), lr: 0.000994658682872972\n",
      "step: 147, acc: 0.672, loss: 1.096 (data_loss: 1.096, reg_loss: 0.000), lr: 0.0009946487895124232\n",
      "step: 148, acc: 0.695, loss: 1.142 (data_loss: 1.142, reg_loss: 0.000), lr: 0.0009946388963486806\n",
      "step: 149, acc: 0.781, loss: 1.038 (data_loss: 1.038, reg_loss: 0.000), lr: 0.0009946290033817386\n",
      "step: 150, acc: 0.797, loss: 0.991 (data_loss: 0.991, reg_loss: 0.000), lr: 0.0009946191106115915\n",
      "step: 151, acc: 0.742, loss: 1.042 (data_loss: 1.042, reg_loss: 0.000), lr: 0.0009946092180382327\n",
      "step: 152, acc: 0.805, loss: 1.057 (data_loss: 1.057, reg_loss: 0.000), lr: 0.0009945993256616572\n",
      "step: 153, acc: 0.758, loss: 1.098 (data_loss: 1.098, reg_loss: 0.000), lr: 0.0009945894334818586\n",
      "step: 154, acc: 0.812, loss: 0.958 (data_loss: 0.958, reg_loss: 0.000), lr: 0.0009945795414988314\n",
      "step: 155, acc: 0.789, loss: 0.955 (data_loss: 0.955, reg_loss: 0.000), lr: 0.0009945696497125694\n",
      "step: 156, acc: 0.781, loss: 0.994 (data_loss: 0.994, reg_loss: 0.000), lr: 0.0009945597581230668\n",
      "step: 157, acc: 0.758, loss: 1.068 (data_loss: 1.068, reg_loss: 0.000), lr: 0.000994549866730318\n",
      "step: 158, acc: 0.727, loss: 1.119 (data_loss: 1.119, reg_loss: 0.000), lr: 0.0009945399755343165\n",
      "step: 159, acc: 0.805, loss: 1.041 (data_loss: 1.041, reg_loss: 0.000), lr: 0.000994530084535057\n",
      "step: 160, acc: 0.727, loss: 1.029 (data_loss: 1.029, reg_loss: 0.000), lr: 0.000994520193732534\n",
      "step: 161, acc: 0.703, loss: 1.076 (data_loss: 1.076, reg_loss: 0.000), lr: 0.0009945103031267404\n",
      "step: 162, acc: 0.797, loss: 1.025 (data_loss: 1.025, reg_loss: 0.000), lr: 0.0009945004127176712\n",
      "step: 163, acc: 0.758, loss: 1.043 (data_loss: 1.043, reg_loss: 0.000), lr: 0.0009944905225053205\n",
      "step: 164, acc: 0.812, loss: 0.965 (data_loss: 0.965, reg_loss: 0.000), lr: 0.0009944806324896824\n",
      "step: 165, acc: 0.742, loss: 1.011 (data_loss: 1.011, reg_loss: 0.000), lr: 0.0009944707426707508\n",
      "step: 166, acc: 0.727, loss: 1.063 (data_loss: 1.063, reg_loss: 0.000), lr: 0.0009944608530485198\n",
      "step: 167, acc: 0.750, loss: 1.090 (data_loss: 1.090, reg_loss: 0.000), lr: 0.0009944509636229837\n",
      "step: 168, acc: 0.672, loss: 1.100 (data_loss: 1.100, reg_loss: 0.000), lr: 0.0009944410743941367\n",
      "step: 169, acc: 0.734, loss: 1.000 (data_loss: 1.000, reg_loss: 0.000), lr: 0.000994431185361973\n",
      "step: 170, acc: 0.758, loss: 1.083 (data_loss: 1.083, reg_loss: 0.000), lr: 0.0009944212965264864\n",
      "step: 171, acc: 0.773, loss: 1.044 (data_loss: 1.044, reg_loss: 0.000), lr: 0.0009944114078876713\n",
      "step: 172, acc: 0.742, loss: 1.005 (data_loss: 1.005, reg_loss: 0.000), lr: 0.0009944015194455218\n",
      "step: 173, acc: 0.742, loss: 1.031 (data_loss: 1.031, reg_loss: 0.000), lr: 0.0009943916312000318\n",
      "step: 174, acc: 0.719, loss: 1.045 (data_loss: 1.045, reg_loss: 0.000), lr: 0.0009943817431511959\n",
      "step: 175, acc: 0.758, loss: 1.057 (data_loss: 1.057, reg_loss: 0.000), lr: 0.0009943718552990076\n",
      "step: 176, acc: 0.781, loss: 0.986 (data_loss: 0.986, reg_loss: 0.000), lr: 0.0009943619676434615\n",
      "step: 177, acc: 0.781, loss: 1.060 (data_loss: 1.060, reg_loss: 0.000), lr: 0.0009943520801845517\n",
      "step: 178, acc: 0.695, loss: 1.045 (data_loss: 1.045, reg_loss: 0.000), lr: 0.0009943421929222724\n",
      "step: 179, acc: 0.781, loss: 1.057 (data_loss: 1.057, reg_loss: 0.000), lr: 0.0009943323058566173\n",
      "step: 180, acc: 0.789, loss: 0.955 (data_loss: 0.955, reg_loss: 0.000), lr: 0.0009943224189875807\n",
      "step: 181, acc: 0.828, loss: 0.915 (data_loss: 0.915, reg_loss: 0.000), lr: 0.0009943125323151575\n",
      "step: 182, acc: 0.789, loss: 1.036 (data_loss: 1.036, reg_loss: 0.000), lr: 0.0009943026458393406\n",
      "step: 183, acc: 0.758, loss: 1.038 (data_loss: 1.038, reg_loss: 0.000), lr: 0.0009942927595601248\n",
      "step: 184, acc: 0.781, loss: 1.001 (data_loss: 1.001, reg_loss: 0.000), lr: 0.0009942828734775045\n",
      "step: 185, acc: 0.695, loss: 1.061 (data_loss: 1.061, reg_loss: 0.000), lr: 0.000994272987591473\n",
      "step: 186, acc: 0.742, loss: 1.015 (data_loss: 1.015, reg_loss: 0.000), lr: 0.0009942631019020252\n",
      "step: 187, acc: 0.773, loss: 0.971 (data_loss: 0.971, reg_loss: 0.000), lr: 0.0009942532164091552\n",
      "step: 188, acc: 0.820, loss: 0.952 (data_loss: 0.952, reg_loss: 0.000), lr: 0.0009942433311128567\n",
      "step: 189, acc: 0.750, loss: 0.976 (data_loss: 0.976, reg_loss: 0.000), lr: 0.0009942334460131238\n",
      "step: 190, acc: 0.719, loss: 1.041 (data_loss: 1.041, reg_loss: 0.000), lr: 0.000994223561109951\n",
      "step: 191, acc: 0.789, loss: 0.917 (data_loss: 0.917, reg_loss: 0.000), lr: 0.0009942136764033327\n",
      "step: 192, acc: 0.828, loss: 0.913 (data_loss: 0.913, reg_loss: 0.000), lr: 0.0009942037918932623\n",
      "step: 193, acc: 0.797, loss: 1.004 (data_loss: 1.004, reg_loss: 0.000), lr: 0.0009941939075797342\n",
      "step: 194, acc: 0.750, loss: 1.013 (data_loss: 1.013, reg_loss: 0.000), lr: 0.000994184023462743\n",
      "step: 195, acc: 0.773, loss: 0.988 (data_loss: 0.988, reg_loss: 0.000), lr: 0.0009941741395422823\n",
      "step: 196, acc: 0.766, loss: 0.994 (data_loss: 0.994, reg_loss: 0.000), lr: 0.0009941642558183462\n",
      "step: 197, acc: 0.750, loss: 1.011 (data_loss: 1.011, reg_loss: 0.000), lr: 0.0009941543722909291\n",
      "step: 198, acc: 0.742, loss: 1.062 (data_loss: 1.062, reg_loss: 0.000), lr: 0.0009941444889600254\n",
      "step: 199, acc: 0.820, loss: 0.945 (data_loss: 0.945, reg_loss: 0.000), lr: 0.0009941346058256288\n",
      "step: 200, acc: 0.727, loss: 1.005 (data_loss: 1.005, reg_loss: 0.000), lr: 0.0009941247228877335\n",
      "step: 201, acc: 0.742, loss: 1.047 (data_loss: 1.047, reg_loss: 0.000), lr: 0.0009941148401463337\n",
      "step: 202, acc: 0.750, loss: 1.036 (data_loss: 1.036, reg_loss: 0.000), lr: 0.0009941049576014237\n",
      "step: 203, acc: 0.727, loss: 1.018 (data_loss: 1.018, reg_loss: 0.000), lr: 0.0009940950752529972\n",
      "step: 204, acc: 0.820, loss: 0.944 (data_loss: 0.944, reg_loss: 0.000), lr: 0.0009940851931010488\n",
      "step: 205, acc: 0.781, loss: 0.908 (data_loss: 0.908, reg_loss: 0.000), lr: 0.0009940753111455725\n",
      "step: 206, acc: 0.750, loss: 1.007 (data_loss: 1.007, reg_loss: 0.000), lr: 0.0009940654293865623\n",
      "step: 207, acc: 0.758, loss: 0.967 (data_loss: 0.967, reg_loss: 0.000), lr: 0.0009940555478240123\n",
      "step: 208, acc: 0.758, loss: 0.961 (data_loss: 0.961, reg_loss: 0.000), lr: 0.000994045666457917\n",
      "step: 209, acc: 0.789, loss: 0.989 (data_loss: 0.989, reg_loss: 0.000), lr: 0.0009940357852882705\n",
      "step: 210, acc: 0.766, loss: 0.971 (data_loss: 0.971, reg_loss: 0.000), lr: 0.0009940259043150663\n",
      "step: 211, acc: 0.781, loss: 0.957 (data_loss: 0.957, reg_loss: 0.000), lr: 0.0009940160235382995\n",
      "step: 212, acc: 0.828, loss: 0.940 (data_loss: 0.940, reg_loss: 0.000), lr: 0.0009940061429579636\n",
      "step: 213, acc: 0.789, loss: 0.973 (data_loss: 0.973, reg_loss: 0.000), lr: 0.0009939962625740528\n",
      "step: 214, acc: 0.805, loss: 0.935 (data_loss: 0.935, reg_loss: 0.000), lr: 0.0009939863823865613\n",
      "step: 215, acc: 0.812, loss: 0.987 (data_loss: 0.987, reg_loss: 0.000), lr: 0.0009939765023954834\n",
      "step: 216, acc: 0.711, loss: 1.015 (data_loss: 1.015, reg_loss: 0.000), lr: 0.0009939666226008131\n",
      "step: 217, acc: 0.719, loss: 0.968 (data_loss: 0.968, reg_loss: 0.000), lr: 0.0009939567430025445\n",
      "step: 218, acc: 0.773, loss: 0.999 (data_loss: 0.999, reg_loss: 0.000), lr: 0.000993946863600672\n",
      "step: 219, acc: 0.750, loss: 0.963 (data_loss: 0.963, reg_loss: 0.000), lr: 0.0009939369843951894\n",
      "step: 220, acc: 0.836, loss: 0.947 (data_loss: 0.947, reg_loss: 0.000), lr: 0.000993927105386091\n",
      "step: 221, acc: 0.758, loss: 0.992 (data_loss: 0.992, reg_loss: 0.000), lr: 0.0009939172265733712\n",
      "step: 222, acc: 0.711, loss: 1.026 (data_loss: 1.026, reg_loss: 0.000), lr: 0.0009939073479570235\n",
      "step: 223, acc: 0.781, loss: 0.998 (data_loss: 0.998, reg_loss: 0.000), lr: 0.0009938974695370426\n",
      "step: 224, acc: 0.734, loss: 0.968 (data_loss: 0.968, reg_loss: 0.000), lr: 0.0009938875913134224\n",
      "step: 225, acc: 0.680, loss: 1.087 (data_loss: 1.087, reg_loss: 0.000), lr: 0.0009938777132861574\n",
      "step: 226, acc: 0.805, loss: 0.967 (data_loss: 0.967, reg_loss: 0.000), lr: 0.000993867835455241\n",
      "step: 227, acc: 0.789, loss: 0.995 (data_loss: 0.995, reg_loss: 0.000), lr: 0.0009938579578206682\n",
      "step: 228, acc: 0.766, loss: 0.962 (data_loss: 0.962, reg_loss: 0.000), lr: 0.0009938480803824328\n",
      "step: 229, acc: 0.789, loss: 0.980 (data_loss: 0.980, reg_loss: 0.000), lr: 0.0009938382031405288\n",
      "step: 230, acc: 0.852, loss: 0.948 (data_loss: 0.948, reg_loss: 0.000), lr: 0.0009938283260949503\n",
      "step: 231, acc: 0.812, loss: 0.881 (data_loss: 0.881, reg_loss: 0.000), lr: 0.000993818449245692\n",
      "step: 232, acc: 0.820, loss: 0.907 (data_loss: 0.907, reg_loss: 0.000), lr: 0.0009938085725927472\n",
      "step: 233, acc: 0.750, loss: 1.028 (data_loss: 1.028, reg_loss: 0.000), lr: 0.0009937986961361107\n",
      "step: 234, acc: 0.805, loss: 0.988 (data_loss: 0.988, reg_loss: 0.000), lr: 0.0009937888198757762\n",
      "step: 235, acc: 0.844, loss: 0.946 (data_loss: 0.946, reg_loss: 0.000), lr: 0.0009937789438117387\n",
      "step: 236, acc: 0.781, loss: 0.914 (data_loss: 0.914, reg_loss: 0.000), lr: 0.0009937690679439912\n",
      "step: 237, acc: 0.805, loss: 0.893 (data_loss: 0.893, reg_loss: 0.000), lr: 0.0009937591922725285\n",
      "step: 238, acc: 0.789, loss: 0.889 (data_loss: 0.889, reg_loss: 0.000), lr: 0.0009937493167973448\n",
      "step: 239, acc: 0.828, loss: 0.926 (data_loss: 0.926, reg_loss: 0.000), lr: 0.0009937394415184338\n",
      "step: 240, acc: 0.836, loss: 0.890 (data_loss: 0.890, reg_loss: 0.000), lr: 0.0009937295664357903\n",
      "step: 241, acc: 0.773, loss: 0.973 (data_loss: 0.973, reg_loss: 0.000), lr: 0.0009937196915494077\n",
      "step: 242, acc: 0.875, loss: 0.866 (data_loss: 0.866, reg_loss: 0.000), lr: 0.000993709816859281\n",
      "step: 243, acc: 0.844, loss: 0.856 (data_loss: 0.856, reg_loss: 0.000), lr: 0.0009936999423654034\n",
      "step: 244, acc: 0.750, loss: 0.909 (data_loss: 0.909, reg_loss: 0.000), lr: 0.0009936900680677697\n",
      "step: 245, acc: 0.758, loss: 0.971 (data_loss: 0.971, reg_loss: 0.000), lr: 0.000993680193966374\n",
      "step: 246, acc: 0.797, loss: 0.890 (data_loss: 0.890, reg_loss: 0.000), lr: 0.00099367032006121\n",
      "step: 247, acc: 0.758, loss: 0.906 (data_loss: 0.906, reg_loss: 0.000), lr: 0.0009936604463522726\n",
      "step: 248, acc: 0.750, loss: 0.927 (data_loss: 0.927, reg_loss: 0.000), lr: 0.0009936505728395553\n",
      "step: 249, acc: 0.742, loss: 0.976 (data_loss: 0.976, reg_loss: 0.000), lr: 0.0009936406995230524\n",
      "step: 250, acc: 0.836, loss: 0.886 (data_loss: 0.886, reg_loss: 0.000), lr: 0.0009936308264027582\n",
      "step: 251, acc: 0.766, loss: 0.905 (data_loss: 0.905, reg_loss: 0.000), lr: 0.0009936209534786669\n",
      "step: 252, acc: 0.789, loss: 0.922 (data_loss: 0.922, reg_loss: 0.000), lr: 0.0009936110807507728\n",
      "step: 253, acc: 0.758, loss: 0.851 (data_loss: 0.851, reg_loss: 0.000), lr: 0.0009936012082190691\n",
      "step: 254, acc: 0.742, loss: 0.979 (data_loss: 0.979, reg_loss: 0.000), lr: 0.000993591335883551\n",
      "step: 255, acc: 0.773, loss: 0.930 (data_loss: 0.930, reg_loss: 0.000), lr: 0.0009935814637442126\n",
      "step: 256, acc: 0.766, loss: 0.924 (data_loss: 0.924, reg_loss: 0.000), lr: 0.0009935715918010474\n",
      "step: 257, acc: 0.695, loss: 0.970 (data_loss: 0.970, reg_loss: 0.000), lr: 0.0009935617200540498\n",
      "step: 258, acc: 0.797, loss: 0.913 (data_loss: 0.913, reg_loss: 0.000), lr: 0.000993551848503214\n",
      "step: 259, acc: 0.797, loss: 0.909 (data_loss: 0.909, reg_loss: 0.000), lr: 0.0009935419771485345\n",
      "step: 260, acc: 0.789, loss: 0.948 (data_loss: 0.948, reg_loss: 0.000), lr: 0.000993532105990005\n",
      "step: 261, acc: 0.758, loss: 0.868 (data_loss: 0.868, reg_loss: 0.000), lr: 0.00099352223502762\n",
      "step: 262, acc: 0.812, loss: 0.913 (data_loss: 0.913, reg_loss: 0.000), lr: 0.0009935123642613734\n",
      "step: 263, acc: 0.773, loss: 0.916 (data_loss: 0.916, reg_loss: 0.000), lr: 0.0009935024936912592\n",
      "step: 264, acc: 0.781, loss: 0.946 (data_loss: 0.946, reg_loss: 0.000), lr: 0.0009934926233172718\n",
      "step: 265, acc: 0.789, loss: 0.909 (data_loss: 0.909, reg_loss: 0.000), lr: 0.0009934827531394056\n",
      "step: 266, acc: 0.789, loss: 0.964 (data_loss: 0.964, reg_loss: 0.000), lr: 0.0009934728831576542\n",
      "step: 267, acc: 0.773, loss: 0.927 (data_loss: 0.927, reg_loss: 0.000), lr: 0.0009934630133720122\n",
      "step: 268, acc: 0.750, loss: 1.036 (data_loss: 1.036, reg_loss: 0.000), lr: 0.0009934531437824734\n",
      "step: 269, acc: 0.789, loss: 0.879 (data_loss: 0.879, reg_loss: 0.000), lr: 0.0009934432743890324\n",
      "step: 270, acc: 0.734, loss: 0.980 (data_loss: 0.980, reg_loss: 0.000), lr: 0.000993433405191683\n",
      "step: 271, acc: 0.805, loss: 0.908 (data_loss: 0.908, reg_loss: 0.000), lr: 0.0009934235361904193\n",
      "step: 272, acc: 0.805, loss: 0.828 (data_loss: 0.828, reg_loss: 0.000), lr: 0.000993413667385236\n",
      "step: 273, acc: 0.828, loss: 0.846 (data_loss: 0.846, reg_loss: 0.000), lr: 0.0009934037987761265\n",
      "step: 274, acc: 0.734, loss: 0.956 (data_loss: 0.956, reg_loss: 0.000), lr: 0.0009933939303630854\n",
      "step: 275, acc: 0.750, loss: 0.996 (data_loss: 0.996, reg_loss: 0.000), lr: 0.000993384062146107\n",
      "step: 276, acc: 0.797, loss: 0.928 (data_loss: 0.928, reg_loss: 0.000), lr: 0.000993374194125185\n",
      "step: 277, acc: 0.750, loss: 0.909 (data_loss: 0.909, reg_loss: 0.000), lr: 0.0009933643263003139\n",
      "step: 278, acc: 0.789, loss: 0.876 (data_loss: 0.876, reg_loss: 0.000), lr: 0.0009933544586714876\n",
      "step: 279, acc: 0.773, loss: 0.963 (data_loss: 0.963, reg_loss: 0.000), lr: 0.0009933445912387007\n",
      "step: 280, acc: 0.781, loss: 0.870 (data_loss: 0.870, reg_loss: 0.000), lr: 0.000993334724001947\n",
      "step: 281, acc: 0.797, loss: 0.919 (data_loss: 0.919, reg_loss: 0.000), lr: 0.0009933248569612206\n",
      "step: 282, acc: 0.742, loss: 0.934 (data_loss: 0.934, reg_loss: 0.000), lr: 0.000993314990116516\n",
      "step: 283, acc: 0.711, loss: 0.920 (data_loss: 0.920, reg_loss: 0.000), lr: 0.0009933051234678268\n",
      "step: 284, acc: 0.797, loss: 0.879 (data_loss: 0.879, reg_loss: 0.000), lr: 0.0009932952570151478\n",
      "step: 285, acc: 0.859, loss: 0.760 (data_loss: 0.760, reg_loss: 0.000), lr: 0.0009932853907584727\n",
      "step: 286, acc: 0.836, loss: 0.803 (data_loss: 0.803, reg_loss: 0.000), lr: 0.0009932755246977961\n",
      "step: 287, acc: 0.703, loss: 0.971 (data_loss: 0.971, reg_loss: 0.000), lr: 0.0009932656588331115\n",
      "step: 288, acc: 0.812, loss: 0.897 (data_loss: 0.897, reg_loss: 0.000), lr: 0.0009932557931644137\n",
      "step: 289, acc: 0.820, loss: 0.853 (data_loss: 0.853, reg_loss: 0.000), lr: 0.0009932459276916965\n",
      "step: 290, acc: 0.828, loss: 0.838 (data_loss: 0.838, reg_loss: 0.000), lr: 0.0009932360624149543\n",
      "step: 291, acc: 0.773, loss: 0.920 (data_loss: 0.920, reg_loss: 0.000), lr: 0.000993226197334181\n",
      "step: 292, acc: 0.781, loss: 0.905 (data_loss: 0.905, reg_loss: 0.000), lr: 0.0009932163324493709\n",
      "step: 293, acc: 0.852, loss: 0.783 (data_loss: 0.783, reg_loss: 0.000), lr: 0.0009932064677605182\n",
      "step: 294, acc: 0.766, loss: 0.910 (data_loss: 0.910, reg_loss: 0.000), lr: 0.0009931966032676169\n",
      "step: 295, acc: 0.805, loss: 0.922 (data_loss: 0.922, reg_loss: 0.000), lr: 0.0009931867389706612\n",
      "step: 296, acc: 0.789, loss: 0.830 (data_loss: 0.830, reg_loss: 0.000), lr: 0.0009931768748696456\n",
      "step: 297, acc: 0.781, loss: 0.901 (data_loss: 0.901, reg_loss: 0.000), lr: 0.0009931670109645638\n",
      "step: 298, acc: 0.789, loss: 0.886 (data_loss: 0.886, reg_loss: 0.000), lr: 0.0009931571472554103\n",
      "step: 299, acc: 0.867, loss: 0.860 (data_loss: 0.860, reg_loss: 0.000), lr: 0.000993147283742179\n",
      "step: 300, acc: 0.820, loss: 0.850 (data_loss: 0.850, reg_loss: 0.000), lr: 0.0009931374204248642\n",
      "step: 301, acc: 0.773, loss: 0.900 (data_loss: 0.900, reg_loss: 0.000), lr: 0.00099312755730346\n",
      "step: 302, acc: 0.758, loss: 0.930 (data_loss: 0.930, reg_loss: 0.000), lr: 0.0009931176943779607\n",
      "step: 303, acc: 0.766, loss: 0.856 (data_loss: 0.856, reg_loss: 0.000), lr: 0.0009931078316483604\n",
      "step: 304, acc: 0.781, loss: 0.913 (data_loss: 0.913, reg_loss: 0.000), lr: 0.0009930979691146532\n",
      "step: 305, acc: 0.820, loss: 0.878 (data_loss: 0.878, reg_loss: 0.000), lr: 0.000993088106776833\n",
      "step: 306, acc: 0.828, loss: 0.835 (data_loss: 0.835, reg_loss: 0.000), lr: 0.000993078244634895\n",
      "step: 307, acc: 0.828, loss: 0.845 (data_loss: 0.845, reg_loss: 0.000), lr: 0.000993068382688832\n",
      "step: 308, acc: 0.773, loss: 0.887 (data_loss: 0.887, reg_loss: 0.000), lr: 0.0009930585209386388\n",
      "step: 309, acc: 0.820, loss: 0.911 (data_loss: 0.911, reg_loss: 0.000), lr: 0.00099304865938431\n",
      "step: 310, acc: 0.867, loss: 0.801 (data_loss: 0.801, reg_loss: 0.000), lr: 0.000993038798025839\n",
      "step: 311, acc: 0.820, loss: 0.871 (data_loss: 0.871, reg_loss: 0.000), lr: 0.0009930289368632202\n",
      "step: 312, acc: 0.789, loss: 0.896 (data_loss: 0.896, reg_loss: 0.000), lr: 0.000993019075896448\n",
      "step: 313, acc: 0.781, loss: 0.856 (data_loss: 0.856, reg_loss: 0.000), lr: 0.0009930092151255164\n",
      "step: 314, acc: 0.844, loss: 0.816 (data_loss: 0.816, reg_loss: 0.000), lr: 0.0009929993545504195\n",
      "step: 315, acc: 0.773, loss: 0.909 (data_loss: 0.909, reg_loss: 0.000), lr: 0.0009929894941711516\n",
      "step: 316, acc: 0.812, loss: 0.799 (data_loss: 0.799, reg_loss: 0.000), lr: 0.0009929796339877071\n",
      "step: 317, acc: 0.797, loss: 0.810 (data_loss: 0.810, reg_loss: 0.000), lr: 0.0009929697740000795\n",
      "step: 318, acc: 0.773, loss: 0.901 (data_loss: 0.901, reg_loss: 0.000), lr: 0.0009929599142082634\n",
      "step: 319, acc: 0.844, loss: 0.786 (data_loss: 0.786, reg_loss: 0.000), lr: 0.000992950054612253\n",
      "step: 320, acc: 0.766, loss: 0.880 (data_loss: 0.880, reg_loss: 0.000), lr: 0.0009929401952120426\n",
      "step: 321, acc: 0.789, loss: 0.911 (data_loss: 0.911, reg_loss: 0.000), lr: 0.0009929303360076257\n",
      "step: 322, acc: 0.789, loss: 0.841 (data_loss: 0.841, reg_loss: 0.000), lr: 0.0009929204769989972\n",
      "step: 323, acc: 0.812, loss: 0.823 (data_loss: 0.823, reg_loss: 0.000), lr: 0.000992910618186151\n",
      "step: 324, acc: 0.789, loss: 0.878 (data_loss: 0.878, reg_loss: 0.000), lr: 0.0009929007595690811\n",
      "step: 325, acc: 0.812, loss: 0.877 (data_loss: 0.877, reg_loss: 0.000), lr: 0.0009928909011477818\n",
      "step: 326, acc: 0.797, loss: 0.858 (data_loss: 0.858, reg_loss: 0.000), lr: 0.0009928810429222475\n",
      "step: 327, acc: 0.820, loss: 0.865 (data_loss: 0.865, reg_loss: 0.000), lr: 0.000992871184892472\n",
      "step: 328, acc: 0.844, loss: 0.858 (data_loss: 0.858, reg_loss: 0.000), lr: 0.0009928613270584498\n",
      "step: 329, acc: 0.820, loss: 0.795 (data_loss: 0.795, reg_loss: 0.000), lr: 0.0009928514694201747\n",
      "step: 330, acc: 0.812, loss: 0.835 (data_loss: 0.835, reg_loss: 0.000), lr: 0.0009928416119776413\n",
      "step: 331, acc: 0.789, loss: 0.858 (data_loss: 0.858, reg_loss: 0.000), lr: 0.0009928317547308434\n",
      "step: 332, acc: 0.828, loss: 0.857 (data_loss: 0.857, reg_loss: 0.000), lr: 0.0009928218976797752\n",
      "step: 333, acc: 0.797, loss: 0.872 (data_loss: 0.872, reg_loss: 0.000), lr: 0.0009928120408244311\n",
      "step: 334, acc: 0.766, loss: 0.954 (data_loss: 0.954, reg_loss: 0.000), lr: 0.0009928021841648052\n",
      "step: 335, acc: 0.820, loss: 0.811 (data_loss: 0.811, reg_loss: 0.000), lr: 0.0009927923277008915\n",
      "step: 336, acc: 0.773, loss: 0.828 (data_loss: 0.828, reg_loss: 0.000), lr: 0.0009927824714326843\n",
      "step: 337, acc: 0.805, loss: 0.840 (data_loss: 0.840, reg_loss: 0.000), lr: 0.000992772615360178\n",
      "step: 338, acc: 0.820, loss: 0.739 (data_loss: 0.739, reg_loss: 0.000), lr: 0.0009927627594833663\n",
      "step: 339, acc: 0.797, loss: 0.850 (data_loss: 0.850, reg_loss: 0.000), lr: 0.0009927529038022435\n",
      "step: 340, acc: 0.844, loss: 0.760 (data_loss: 0.760, reg_loss: 0.000), lr: 0.0009927430483168043\n",
      "step: 341, acc: 0.750, loss: 0.886 (data_loss: 0.886, reg_loss: 0.000), lr: 0.000992733193027042\n",
      "step: 342, acc: 0.758, loss: 0.886 (data_loss: 0.886, reg_loss: 0.000), lr: 0.0009927233379329514\n",
      "step: 343, acc: 0.773, loss: 0.848 (data_loss: 0.848, reg_loss: 0.000), lr: 0.0009927134830345268\n",
      "step: 344, acc: 0.758, loss: 0.808 (data_loss: 0.808, reg_loss: 0.000), lr: 0.0009927036283317616\n",
      "step: 345, acc: 0.844, loss: 0.824 (data_loss: 0.824, reg_loss: 0.000), lr: 0.0009926937738246506\n",
      "step: 346, acc: 0.805, loss: 0.873 (data_loss: 0.873, reg_loss: 0.000), lr: 0.0009926839195131877\n",
      "step: 347, acc: 0.812, loss: 0.782 (data_loss: 0.782, reg_loss: 0.000), lr: 0.0009926740653973675\n",
      "step: 348, acc: 0.805, loss: 0.835 (data_loss: 0.835, reg_loss: 0.000), lr: 0.0009926642114771837\n",
      "step: 349, acc: 0.789, loss: 0.851 (data_loss: 0.851, reg_loss: 0.000), lr: 0.0009926543577526304\n",
      "step: 350, acc: 0.812, loss: 0.866 (data_loss: 0.866, reg_loss: 0.000), lr: 0.0009926445042237025\n",
      "step: 351, acc: 0.820, loss: 0.794 (data_loss: 0.794, reg_loss: 0.000), lr: 0.0009926346508903933\n",
      "step: 352, acc: 0.789, loss: 0.851 (data_loss: 0.851, reg_loss: 0.000), lr: 0.0009926247977526973\n",
      "step: 353, acc: 0.758, loss: 0.895 (data_loss: 0.895, reg_loss: 0.000), lr: 0.0009926149448106093\n",
      "step: 354, acc: 0.758, loss: 0.882 (data_loss: 0.882, reg_loss: 0.000), lr: 0.0009926050920641223\n",
      "step: 355, acc: 0.836, loss: 0.796 (data_loss: 0.796, reg_loss: 0.000), lr: 0.0009925952395132313\n",
      "step: 356, acc: 0.727, loss: 0.901 (data_loss: 0.901, reg_loss: 0.000), lr: 0.0009925853871579303\n",
      "step: 357, acc: 0.859, loss: 0.739 (data_loss: 0.739, reg_loss: 0.000), lr: 0.0009925755349982134\n",
      "step: 358, acc: 0.875, loss: 0.752 (data_loss: 0.752, reg_loss: 0.000), lr: 0.0009925656830340748\n",
      "step: 359, acc: 0.820, loss: 0.764 (data_loss: 0.764, reg_loss: 0.000), lr: 0.0009925558312655087\n",
      "step: 360, acc: 0.773, loss: 0.843 (data_loss: 0.843, reg_loss: 0.000), lr: 0.0009925459796925095\n",
      "step: 361, acc: 0.836, loss: 0.794 (data_loss: 0.794, reg_loss: 0.000), lr: 0.0009925361283150706\n",
      "step: 362, acc: 0.812, loss: 0.763 (data_loss: 0.763, reg_loss: 0.000), lr: 0.0009925262771331871\n",
      "step: 363, acc: 0.781, loss: 0.854 (data_loss: 0.854, reg_loss: 0.000), lr: 0.0009925164261468528\n",
      "step: 364, acc: 0.781, loss: 0.798 (data_loss: 0.798, reg_loss: 0.000), lr: 0.0009925065753560618\n",
      "step: 365, acc: 0.797, loss: 0.806 (data_loss: 0.806, reg_loss: 0.000), lr: 0.0009924967247608083\n",
      "step: 366, acc: 0.750, loss: 0.850 (data_loss: 0.850, reg_loss: 0.000), lr: 0.0009924868743610865\n",
      "step: 367, acc: 0.852, loss: 0.708 (data_loss: 0.708, reg_loss: 0.000), lr: 0.000992477024156891\n",
      "step: 368, acc: 0.820, loss: 0.794 (data_loss: 0.794, reg_loss: 0.000), lr: 0.000992467174148215\n",
      "step: 369, acc: 0.766, loss: 0.819 (data_loss: 0.819, reg_loss: 0.000), lr: 0.0009924573243350536\n",
      "step: 370, acc: 0.805, loss: 0.824 (data_loss: 0.824, reg_loss: 0.000), lr: 0.0009924474747174006\n",
      "step: 371, acc: 0.836, loss: 0.740 (data_loss: 0.740, reg_loss: 0.000), lr: 0.0009924376252952504\n",
      "step: 372, acc: 0.805, loss: 0.777 (data_loss: 0.777, reg_loss: 0.000), lr: 0.0009924277760685965\n",
      "step: 373, acc: 0.852, loss: 0.756 (data_loss: 0.756, reg_loss: 0.000), lr: 0.000992417927037434\n",
      "step: 374, acc: 0.789, loss: 0.753 (data_loss: 0.753, reg_loss: 0.000), lr: 0.0009924080782017567\n",
      "step: 375, acc: 0.828, loss: 0.820 (data_loss: 0.820, reg_loss: 0.000), lr: 0.0009923982295615584\n",
      "step: 376, acc: 0.820, loss: 0.802 (data_loss: 0.802, reg_loss: 0.000), lr: 0.000992388381116834\n",
      "step: 377, acc: 0.867, loss: 0.733 (data_loss: 0.733, reg_loss: 0.000), lr: 0.000992378532867577\n",
      "step: 378, acc: 0.797, loss: 0.800 (data_loss: 0.800, reg_loss: 0.000), lr: 0.000992368684813782\n",
      "step: 379, acc: 0.766, loss: 0.839 (data_loss: 0.839, reg_loss: 0.000), lr: 0.0009923588369554431\n",
      "step: 380, acc: 0.812, loss: 0.839 (data_loss: 0.839, reg_loss: 0.000), lr: 0.0009923489892925544\n",
      "step: 381, acc: 0.836, loss: 0.790 (data_loss: 0.790, reg_loss: 0.000), lr: 0.00099233914182511\n",
      "step: 382, acc: 0.812, loss: 0.779 (data_loss: 0.779, reg_loss: 0.000), lr: 0.0009923292945531045\n",
      "step: 383, acc: 0.805, loss: 0.799 (data_loss: 0.799, reg_loss: 0.000), lr: 0.0009923194474765315\n",
      "step: 384, acc: 0.734, loss: 0.878 (data_loss: 0.878, reg_loss: 0.000), lr: 0.000992309600595386\n",
      "step: 385, acc: 0.844, loss: 0.735 (data_loss: 0.735, reg_loss: 0.000), lr: 0.0009922997539096611\n",
      "step: 386, acc: 0.820, loss: 0.831 (data_loss: 0.831, reg_loss: 0.000), lr: 0.0009922899074193516\n",
      "step: 387, acc: 0.844, loss: 0.716 (data_loss: 0.716, reg_loss: 0.000), lr: 0.000992280061124452\n",
      "step: 388, acc: 0.852, loss: 0.738 (data_loss: 0.738, reg_loss: 0.000), lr: 0.0009922702150249557\n",
      "step: 389, acc: 0.852, loss: 0.734 (data_loss: 0.734, reg_loss: 0.000), lr: 0.0009922603691208572\n",
      "step: 390, acc: 0.825, loss: 0.688 (data_loss: 0.688, reg_loss: 0.000), lr: 0.0009922505234121512\n",
      "training, acc: 0.764, loss: 1.015 (data_loss: 1.015, reg_loss: 0.000), lr: 0.0009922505234121512\n",
      "validation, acc: 0.814, loss: 0.784\n",
      "epoch: 3\n",
      "step: 0, acc: 0.781, loss: 0.864 (data_loss: 0.864, reg_loss: 0.000), lr: 0.0009922406778988312\n",
      "step: 1, acc: 0.789, loss: 0.874 (data_loss: 0.874, reg_loss: 0.000), lr: 0.0009922308325808916\n",
      "step: 2, acc: 0.781, loss: 0.808 (data_loss: 0.808, reg_loss: 0.000), lr: 0.0009922209874583267\n",
      "step: 3, acc: 0.852, loss: 0.752 (data_loss: 0.752, reg_loss: 0.000), lr: 0.0009922111425311308\n",
      "step: 4, acc: 0.812, loss: 0.791 (data_loss: 0.791, reg_loss: 0.000), lr: 0.0009922012977992977\n",
      "step: 5, acc: 0.828, loss: 0.824 (data_loss: 0.824, reg_loss: 0.000), lr: 0.0009921914532628215\n",
      "step: 6, acc: 0.836, loss: 0.812 (data_loss: 0.812, reg_loss: 0.000), lr: 0.0009921816089216969\n",
      "step: 7, acc: 0.891, loss: 0.706 (data_loss: 0.706, reg_loss: 0.000), lr: 0.0009921717647759182\n",
      "step: 8, acc: 0.836, loss: 0.774 (data_loss: 0.774, reg_loss: 0.000), lr: 0.0009921619208254787\n",
      "step: 9, acc: 0.805, loss: 0.794 (data_loss: 0.794, reg_loss: 0.000), lr: 0.0009921520770703734\n",
      "step: 10, acc: 0.828, loss: 0.739 (data_loss: 0.739, reg_loss: 0.000), lr: 0.0009921422335105962\n",
      "step: 11, acc: 0.789, loss: 0.775 (data_loss: 0.775, reg_loss: 0.000), lr: 0.000992132390146141\n",
      "step: 12, acc: 0.812, loss: 0.741 (data_loss: 0.741, reg_loss: 0.000), lr: 0.0009921225469770025\n",
      "step: 13, acc: 0.758, loss: 0.841 (data_loss: 0.841, reg_loss: 0.000), lr: 0.0009921127040031748\n",
      "step: 14, acc: 0.781, loss: 0.767 (data_loss: 0.767, reg_loss: 0.000), lr: 0.0009921028612246518\n",
      "step: 15, acc: 0.828, loss: 0.753 (data_loss: 0.753, reg_loss: 0.000), lr: 0.0009920930186414277\n",
      "step: 16, acc: 0.797, loss: 0.778 (data_loss: 0.778, reg_loss: 0.000), lr: 0.000992083176253497\n",
      "step: 17, acc: 0.820, loss: 0.744 (data_loss: 0.744, reg_loss: 0.000), lr: 0.0009920733340608538\n",
      "step: 18, acc: 0.781, loss: 0.836 (data_loss: 0.836, reg_loss: 0.000), lr: 0.000992063492063492\n",
      "step: 19, acc: 0.781, loss: 0.797 (data_loss: 0.797, reg_loss: 0.000), lr: 0.000992053650261406\n",
      "step: 20, acc: 0.797, loss: 0.788 (data_loss: 0.788, reg_loss: 0.000), lr: 0.0009920438086545903\n",
      "step: 21, acc: 0.812, loss: 0.820 (data_loss: 0.820, reg_loss: 0.000), lr: 0.0009920339672430385\n",
      "step: 22, acc: 0.844, loss: 0.693 (data_loss: 0.693, reg_loss: 0.000), lr: 0.000992024126026745\n",
      "step: 23, acc: 0.789, loss: 0.779 (data_loss: 0.779, reg_loss: 0.000), lr: 0.0009920142850057042\n",
      "step: 24, acc: 0.828, loss: 0.720 (data_loss: 0.720, reg_loss: 0.000), lr: 0.00099200444417991\n",
      "step: 25, acc: 0.852, loss: 0.731 (data_loss: 0.731, reg_loss: 0.000), lr: 0.0009919946035493567\n",
      "step: 26, acc: 0.805, loss: 0.796 (data_loss: 0.796, reg_loss: 0.000), lr: 0.0009919847631140385\n",
      "step: 27, acc: 0.820, loss: 0.736 (data_loss: 0.736, reg_loss: 0.000), lr: 0.0009919749228739499\n",
      "step: 28, acc: 0.844, loss: 0.777 (data_loss: 0.777, reg_loss: 0.000), lr: 0.0009919650828290846\n",
      "step: 29, acc: 0.820, loss: 0.776 (data_loss: 0.776, reg_loss: 0.000), lr: 0.0009919552429794368\n",
      "step: 30, acc: 0.805, loss: 0.734 (data_loss: 0.734, reg_loss: 0.000), lr: 0.0009919454033250012\n",
      "step: 31, acc: 0.789, loss: 0.789 (data_loss: 0.789, reg_loss: 0.000), lr: 0.0009919355638657713\n",
      "step: 32, acc: 0.844, loss: 0.725 (data_loss: 0.725, reg_loss: 0.000), lr: 0.0009919257246017417\n",
      "step: 33, acc: 0.797, loss: 0.779 (data_loss: 0.779, reg_loss: 0.000), lr: 0.0009919158855329067\n",
      "step: 34, acc: 0.789, loss: 0.764 (data_loss: 0.764, reg_loss: 0.000), lr: 0.0009919060466592605\n",
      "step: 35, acc: 0.789, loss: 0.770 (data_loss: 0.770, reg_loss: 0.000), lr: 0.000991896207980797\n",
      "step: 36, acc: 0.859, loss: 0.745 (data_loss: 0.745, reg_loss: 0.000), lr: 0.0009918863694975103\n",
      "step: 37, acc: 0.797, loss: 0.710 (data_loss: 0.710, reg_loss: 0.000), lr: 0.000991876531209395\n",
      "step: 38, acc: 0.773, loss: 0.795 (data_loss: 0.795, reg_loss: 0.000), lr: 0.0009918666931164452\n",
      "step: 39, acc: 0.773, loss: 0.814 (data_loss: 0.814, reg_loss: 0.000), lr: 0.0009918568552186547\n",
      "step: 40, acc: 0.828, loss: 0.734 (data_loss: 0.734, reg_loss: 0.000), lr: 0.0009918470175160185\n",
      "step: 41, acc: 0.836, loss: 0.738 (data_loss: 0.738, reg_loss: 0.000), lr: 0.0009918371800085298\n",
      "step: 42, acc: 0.773, loss: 0.787 (data_loss: 0.787, reg_loss: 0.000), lr: 0.0009918273426961835\n",
      "step: 43, acc: 0.766, loss: 0.744 (data_loss: 0.744, reg_loss: 0.000), lr: 0.0009918175055789735\n",
      "step: 44, acc: 0.805, loss: 0.798 (data_loss: 0.798, reg_loss: 0.000), lr: 0.0009918076686568941\n",
      "step: 45, acc: 0.773, loss: 0.771 (data_loss: 0.771, reg_loss: 0.000), lr: 0.0009917978319299394\n",
      "step: 46, acc: 0.828, loss: 0.759 (data_loss: 0.759, reg_loss: 0.000), lr: 0.0009917879953981036\n",
      "step: 47, acc: 0.805, loss: 0.824 (data_loss: 0.824, reg_loss: 0.000), lr: 0.0009917781590613813\n",
      "step: 48, acc: 0.789, loss: 0.705 (data_loss: 0.705, reg_loss: 0.000), lr: 0.000991768322919766\n",
      "step: 49, acc: 0.828, loss: 0.716 (data_loss: 0.716, reg_loss: 0.000), lr: 0.0009917584869732522\n",
      "step: 50, acc: 0.844, loss: 0.738 (data_loss: 0.738, reg_loss: 0.000), lr: 0.0009917486512218342\n",
      "step: 51, acc: 0.875, loss: 0.745 (data_loss: 0.745, reg_loss: 0.000), lr: 0.0009917388156655063\n",
      "step: 52, acc: 0.820, loss: 0.760 (data_loss: 0.760, reg_loss: 0.000), lr: 0.0009917289803042626\n",
      "step: 53, acc: 0.703, loss: 0.905 (data_loss: 0.905, reg_loss: 0.000), lr: 0.0009917191451380967\n",
      "step: 54, acc: 0.836, loss: 0.713 (data_loss: 0.713, reg_loss: 0.000), lr: 0.000991709310167004\n",
      "step: 55, acc: 0.797, loss: 0.849 (data_loss: 0.849, reg_loss: 0.000), lr: 0.0009916994753909776\n",
      "step: 56, acc: 0.828, loss: 0.786 (data_loss: 0.786, reg_loss: 0.000), lr: 0.000991689640810012\n",
      "step: 57, acc: 0.844, loss: 0.681 (data_loss: 0.681, reg_loss: 0.000), lr: 0.0009916798064241018\n",
      "step: 58, acc: 0.812, loss: 0.726 (data_loss: 0.726, reg_loss: 0.000), lr: 0.0009916699722332409\n",
      "step: 59, acc: 0.812, loss: 0.771 (data_loss: 0.771, reg_loss: 0.000), lr: 0.0009916601382374234\n",
      "step: 60, acc: 0.836, loss: 0.777 (data_loss: 0.777, reg_loss: 0.000), lr: 0.0009916503044366434\n",
      "step: 61, acc: 0.820, loss: 0.729 (data_loss: 0.729, reg_loss: 0.000), lr: 0.0009916404708308956\n",
      "step: 62, acc: 0.836, loss: 0.729 (data_loss: 0.729, reg_loss: 0.000), lr: 0.0009916306374201738\n",
      "step: 63, acc: 0.828, loss: 0.779 (data_loss: 0.779, reg_loss: 0.000), lr: 0.0009916208042044722\n",
      "step: 64, acc: 0.781, loss: 0.794 (data_loss: 0.794, reg_loss: 0.000), lr: 0.0009916109711837853\n",
      "step: 65, acc: 0.766, loss: 0.884 (data_loss: 0.884, reg_loss: 0.000), lr: 0.0009916011383581068\n",
      "step: 66, acc: 0.844, loss: 0.708 (data_loss: 0.708, reg_loss: 0.000), lr: 0.0009915913057274314\n",
      "step: 67, acc: 0.812, loss: 0.840 (data_loss: 0.840, reg_loss: 0.000), lr: 0.000991581473291753\n",
      "step: 68, acc: 0.773, loss: 0.771 (data_loss: 0.771, reg_loss: 0.000), lr: 0.000991571641051066\n",
      "step: 69, acc: 0.805, loss: 0.750 (data_loss: 0.750, reg_loss: 0.000), lr: 0.0009915618090053644\n",
      "step: 70, acc: 0.867, loss: 0.669 (data_loss: 0.669, reg_loss: 0.000), lr: 0.0009915519771546424\n",
      "step: 71, acc: 0.828, loss: 0.697 (data_loss: 0.697, reg_loss: 0.000), lr: 0.0009915421454988946\n",
      "step: 72, acc: 0.820, loss: 0.720 (data_loss: 0.720, reg_loss: 0.000), lr: 0.0009915323140381146\n",
      "step: 73, acc: 0.867, loss: 0.663 (data_loss: 0.663, reg_loss: 0.000), lr: 0.0009915224827722969\n",
      "step: 74, acc: 0.789, loss: 0.841 (data_loss: 0.841, reg_loss: 0.000), lr: 0.0009915126517014358\n",
      "step: 75, acc: 0.797, loss: 0.797 (data_loss: 0.797, reg_loss: 0.000), lr: 0.0009915028208255254\n",
      "step: 76, acc: 0.812, loss: 0.693 (data_loss: 0.693, reg_loss: 0.000), lr: 0.0009914929901445597\n",
      "step: 77, acc: 0.883, loss: 0.640 (data_loss: 0.640, reg_loss: 0.000), lr: 0.0009914831596585332\n",
      "step: 78, acc: 0.805, loss: 0.790 (data_loss: 0.790, reg_loss: 0.000), lr: 0.00099147332936744\n",
      "step: 79, acc: 0.820, loss: 0.779 (data_loss: 0.779, reg_loss: 0.000), lr: 0.0009914634992712744\n",
      "step: 80, acc: 0.781, loss: 0.786 (data_loss: 0.786, reg_loss: 0.000), lr: 0.0009914536693700303\n",
      "step: 81, acc: 0.773, loss: 0.764 (data_loss: 0.764, reg_loss: 0.000), lr: 0.0009914438396637023\n",
      "step: 82, acc: 0.891, loss: 0.660 (data_loss: 0.660, reg_loss: 0.000), lr: 0.0009914340101522842\n",
      "step: 83, acc: 0.742, loss: 0.794 (data_loss: 0.794, reg_loss: 0.000), lr: 0.0009914241808357705\n",
      "step: 84, acc: 0.758, loss: 0.835 (data_loss: 0.835, reg_loss: 0.000), lr: 0.0009914143517141556\n",
      "step: 85, acc: 0.836, loss: 0.760 (data_loss: 0.760, reg_loss: 0.000), lr: 0.000991404522787433\n",
      "step: 86, acc: 0.797, loss: 0.810 (data_loss: 0.810, reg_loss: 0.000), lr: 0.0009913946940555975\n",
      "step: 87, acc: 0.820, loss: 0.767 (data_loss: 0.767, reg_loss: 0.000), lr: 0.000991384865518643\n",
      "step: 88, acc: 0.750, loss: 0.870 (data_loss: 0.870, reg_loss: 0.000), lr: 0.000991375037176564\n",
      "step: 89, acc: 0.844, loss: 0.691 (data_loss: 0.691, reg_loss: 0.000), lr: 0.0009913652090293543\n",
      "step: 90, acc: 0.820, loss: 0.687 (data_loss: 0.687, reg_loss: 0.000), lr: 0.0009913553810770085\n",
      "step: 91, acc: 0.852, loss: 0.690 (data_loss: 0.690, reg_loss: 0.000), lr: 0.0009913455533195207\n",
      "step: 92, acc: 0.867, loss: 0.735 (data_loss: 0.735, reg_loss: 0.000), lr: 0.000991335725756885\n",
      "step: 93, acc: 0.812, loss: 0.725 (data_loss: 0.725, reg_loss: 0.000), lr: 0.0009913258983890955\n",
      "step: 94, acc: 0.852, loss: 0.734 (data_loss: 0.734, reg_loss: 0.000), lr: 0.0009913160712161466\n",
      "step: 95, acc: 0.797, loss: 0.843 (data_loss: 0.843, reg_loss: 0.000), lr: 0.0009913062442380325\n",
      "step: 96, acc: 0.828, loss: 0.705 (data_loss: 0.705, reg_loss: 0.000), lr: 0.0009912964174547472\n",
      "step: 97, acc: 0.844, loss: 0.685 (data_loss: 0.685, reg_loss: 0.000), lr: 0.0009912865908662852\n",
      "step: 98, acc: 0.742, loss: 0.794 (data_loss: 0.794, reg_loss: 0.000), lr: 0.0009912767644726407\n",
      "step: 99, acc: 0.828, loss: 0.696 (data_loss: 0.696, reg_loss: 0.000), lr: 0.0009912669382738078\n",
      "step: 100, acc: 0.844, loss: 0.741 (data_loss: 0.741, reg_loss: 0.000), lr: 0.0009912571122697804\n",
      "step: 101, acc: 0.844, loss: 0.720 (data_loss: 0.720, reg_loss: 0.000), lr: 0.0009912472864605534\n",
      "step: 102, acc: 0.820, loss: 0.691 (data_loss: 0.691, reg_loss: 0.000), lr: 0.0009912374608461202\n",
      "step: 103, acc: 0.797, loss: 0.847 (data_loss: 0.847, reg_loss: 0.000), lr: 0.0009912276354264757\n",
      "step: 104, acc: 0.797, loss: 0.744 (data_loss: 0.744, reg_loss: 0.000), lr: 0.0009912178102016137\n",
      "step: 105, acc: 0.812, loss: 0.653 (data_loss: 0.653, reg_loss: 0.000), lr: 0.0009912079851715286\n",
      "step: 106, acc: 0.867, loss: 0.651 (data_loss: 0.651, reg_loss: 0.000), lr: 0.0009911981603362146\n",
      "step: 107, acc: 0.773, loss: 0.893 (data_loss: 0.893, reg_loss: 0.000), lr: 0.0009911883356956655\n",
      "step: 108, acc: 0.836, loss: 0.703 (data_loss: 0.703, reg_loss: 0.000), lr: 0.0009911785112498763\n",
      "step: 109, acc: 0.859, loss: 0.644 (data_loss: 0.644, reg_loss: 0.000), lr: 0.0009911686869988404\n",
      "step: 110, acc: 0.914, loss: 0.620 (data_loss: 0.620, reg_loss: 0.000), lr: 0.0009911588629425525\n",
      "step: 111, acc: 0.812, loss: 0.719 (data_loss: 0.719, reg_loss: 0.000), lr: 0.0009911490390810064\n",
      "step: 112, acc: 0.820, loss: 0.765 (data_loss: 0.765, reg_loss: 0.000), lr: 0.0009911392154141972\n",
      "step: 113, acc: 0.820, loss: 0.707 (data_loss: 0.707, reg_loss: 0.000), lr: 0.000991129391942118\n",
      "step: 114, acc: 0.828, loss: 0.731 (data_loss: 0.731, reg_loss: 0.000), lr: 0.0009911195686647637\n",
      "step: 115, acc: 0.852, loss: 0.676 (data_loss: 0.676, reg_loss: 0.000), lr: 0.0009911097455821284\n",
      "step: 116, acc: 0.766, loss: 0.790 (data_loss: 0.790, reg_loss: 0.000), lr: 0.000991099922694206\n",
      "step: 117, acc: 0.836, loss: 0.689 (data_loss: 0.689, reg_loss: 0.000), lr: 0.000991090100000991\n",
      "step: 118, acc: 0.836, loss: 0.697 (data_loss: 0.697, reg_loss: 0.000), lr: 0.000991080277502478\n",
      "step: 119, acc: 0.828, loss: 0.727 (data_loss: 0.727, reg_loss: 0.000), lr: 0.0009910704551986602\n",
      "step: 120, acc: 0.875, loss: 0.623 (data_loss: 0.623, reg_loss: 0.000), lr: 0.0009910606330895324\n",
      "step: 121, acc: 0.828, loss: 0.709 (data_loss: 0.709, reg_loss: 0.000), lr: 0.000991050811175089\n",
      "step: 122, acc: 0.812, loss: 0.737 (data_loss: 0.737, reg_loss: 0.000), lr: 0.000991040989455324\n",
      "step: 123, acc: 0.797, loss: 0.788 (data_loss: 0.788, reg_loss: 0.000), lr: 0.0009910311679302314\n",
      "step: 124, acc: 0.812, loss: 0.719 (data_loss: 0.719, reg_loss: 0.000), lr: 0.0009910213465998056\n",
      "step: 125, acc: 0.812, loss: 0.718 (data_loss: 0.718, reg_loss: 0.000), lr: 0.0009910115254640412\n",
      "step: 126, acc: 0.781, loss: 0.736 (data_loss: 0.736, reg_loss: 0.000), lr: 0.0009910017045229318\n",
      "step: 127, acc: 0.875, loss: 0.631 (data_loss: 0.631, reg_loss: 0.000), lr: 0.0009909918837764718\n",
      "step: 128, acc: 0.805, loss: 0.781 (data_loss: 0.781, reg_loss: 0.000), lr: 0.0009909820632246556\n",
      "step: 129, acc: 0.859, loss: 0.622 (data_loss: 0.622, reg_loss: 0.000), lr: 0.0009909722428674773\n",
      "step: 130, acc: 0.789, loss: 0.815 (data_loss: 0.815, reg_loss: 0.000), lr: 0.0009909624227049311\n",
      "step: 131, acc: 0.766, loss: 0.823 (data_loss: 0.823, reg_loss: 0.000), lr: 0.0009909526027370111\n",
      "step: 132, acc: 0.789, loss: 0.708 (data_loss: 0.708, reg_loss: 0.000), lr: 0.0009909427829637117\n",
      "step: 133, acc: 0.805, loss: 0.691 (data_loss: 0.691, reg_loss: 0.000), lr: 0.000990932963385027\n",
      "step: 134, acc: 0.883, loss: 0.663 (data_loss: 0.663, reg_loss: 0.000), lr: 0.0009909231440009512\n",
      "step: 135, acc: 0.867, loss: 0.638 (data_loss: 0.638, reg_loss: 0.000), lr: 0.0009909133248114789\n",
      "step: 136, acc: 0.797, loss: 0.673 (data_loss: 0.673, reg_loss: 0.000), lr: 0.0009909035058166037\n",
      "step: 137, acc: 0.891, loss: 0.608 (data_loss: 0.608, reg_loss: 0.000), lr: 0.00099089368701632\n",
      "step: 138, acc: 0.805, loss: 0.709 (data_loss: 0.709, reg_loss: 0.000), lr: 0.0009908838684106222\n",
      "step: 139, acc: 0.781, loss: 0.730 (data_loss: 0.730, reg_loss: 0.000), lr: 0.0009908740499995046\n",
      "step: 140, acc: 0.781, loss: 0.709 (data_loss: 0.709, reg_loss: 0.000), lr: 0.0009908642317829613\n",
      "step: 141, acc: 0.859, loss: 0.723 (data_loss: 0.723, reg_loss: 0.000), lr: 0.000990854413760986\n",
      "step: 142, acc: 0.875, loss: 0.606 (data_loss: 0.606, reg_loss: 0.000), lr: 0.0009908445959335738\n",
      "step: 143, acc: 0.859, loss: 0.694 (data_loss: 0.694, reg_loss: 0.000), lr: 0.0009908347783007185\n",
      "step: 144, acc: 0.805, loss: 0.728 (data_loss: 0.728, reg_loss: 0.000), lr: 0.0009908249608624141\n",
      "step: 145, acc: 0.828, loss: 0.674 (data_loss: 0.674, reg_loss: 0.000), lr: 0.0009908151436186553\n",
      "step: 146, acc: 0.836, loss: 0.818 (data_loss: 0.818, reg_loss: 0.000), lr: 0.0009908053265694358\n",
      "step: 147, acc: 0.734, loss: 0.779 (data_loss: 0.779, reg_loss: 0.000), lr: 0.00099079550971475\n",
      "step: 148, acc: 0.789, loss: 0.778 (data_loss: 0.778, reg_loss: 0.000), lr: 0.0009907856930545921\n",
      "step: 149, acc: 0.852, loss: 0.646 (data_loss: 0.646, reg_loss: 0.000), lr: 0.0009907758765889567\n",
      "step: 150, acc: 0.867, loss: 0.635 (data_loss: 0.635, reg_loss: 0.000), lr: 0.0009907660603178379\n",
      "step: 151, acc: 0.820, loss: 0.678 (data_loss: 0.678, reg_loss: 0.000), lr: 0.0009907562442412294\n",
      "step: 152, acc: 0.828, loss: 0.705 (data_loss: 0.705, reg_loss: 0.000), lr: 0.000990746428359126\n",
      "step: 153, acc: 0.789, loss: 0.759 (data_loss: 0.759, reg_loss: 0.000), lr: 0.0009907366126715215\n",
      "step: 154, acc: 0.844, loss: 0.611 (data_loss: 0.611, reg_loss: 0.000), lr: 0.00099072679717841\n",
      "step: 155, acc: 0.852, loss: 0.613 (data_loss: 0.613, reg_loss: 0.000), lr: 0.0009907169818797862\n",
      "step: 156, acc: 0.852, loss: 0.652 (data_loss: 0.652, reg_loss: 0.000), lr: 0.0009907071667756445\n",
      "step: 157, acc: 0.828, loss: 0.718 (data_loss: 0.718, reg_loss: 0.000), lr: 0.0009906973518659784\n",
      "step: 158, acc: 0.844, loss: 0.793 (data_loss: 0.793, reg_loss: 0.000), lr: 0.0009906875371507827\n",
      "step: 159, acc: 0.852, loss: 0.685 (data_loss: 0.685, reg_loss: 0.000), lr: 0.0009906777226300512\n",
      "step: 160, acc: 0.820, loss: 0.664 (data_loss: 0.664, reg_loss: 0.000), lr: 0.0009906679083037783\n",
      "step: 161, acc: 0.781, loss: 0.747 (data_loss: 0.747, reg_loss: 0.000), lr: 0.0009906580941719584\n",
      "step: 162, acc: 0.859, loss: 0.694 (data_loss: 0.694, reg_loss: 0.000), lr: 0.0009906482802345855\n",
      "step: 163, acc: 0.812, loss: 0.716 (data_loss: 0.716, reg_loss: 0.000), lr: 0.000990638466491654\n",
      "step: 164, acc: 0.891, loss: 0.591 (data_loss: 0.591, reg_loss: 0.000), lr: 0.0009906286529431578\n",
      "step: 165, acc: 0.828, loss: 0.641 (data_loss: 0.641, reg_loss: 0.000), lr: 0.0009906188395890914\n",
      "step: 166, acc: 0.773, loss: 0.759 (data_loss: 0.759, reg_loss: 0.000), lr: 0.0009906090264294488\n",
      "step: 167, acc: 0.750, loss: 0.761 (data_loss: 0.761, reg_loss: 0.000), lr: 0.0009905992134642246\n",
      "step: 168, acc: 0.781, loss: 0.800 (data_loss: 0.800, reg_loss: 0.000), lr: 0.0009905894006934125\n",
      "step: 169, acc: 0.828, loss: 0.660 (data_loss: 0.660, reg_loss: 0.000), lr: 0.0009905795881170072\n",
      "step: 170, acc: 0.820, loss: 0.753 (data_loss: 0.753, reg_loss: 0.000), lr: 0.0009905697757350029\n",
      "step: 171, acc: 0.852, loss: 0.699 (data_loss: 0.699, reg_loss: 0.000), lr: 0.0009905599635473934\n",
      "step: 172, acc: 0.781, loss: 0.713 (data_loss: 0.713, reg_loss: 0.000), lr: 0.000990550151554173\n",
      "step: 173, acc: 0.836, loss: 0.725 (data_loss: 0.725, reg_loss: 0.000), lr: 0.0009905403397553365\n",
      "step: 174, acc: 0.773, loss: 0.725 (data_loss: 0.725, reg_loss: 0.000), lr: 0.0009905305281508777\n",
      "step: 175, acc: 0.844, loss: 0.715 (data_loss: 0.715, reg_loss: 0.000), lr: 0.0009905207167407906\n",
      "step: 176, acc: 0.844, loss: 0.650 (data_loss: 0.650, reg_loss: 0.000), lr: 0.0009905109055250699\n",
      "step: 177, acc: 0.828, loss: 0.741 (data_loss: 0.741, reg_loss: 0.000), lr: 0.0009905010945037095\n",
      "step: 178, acc: 0.805, loss: 0.752 (data_loss: 0.752, reg_loss: 0.000), lr: 0.0009904912836767037\n",
      "step: 179, acc: 0.828, loss: 0.740 (data_loss: 0.740, reg_loss: 0.000), lr: 0.0009904814730440467\n",
      "step: 180, acc: 0.836, loss: 0.633 (data_loss: 0.633, reg_loss: 0.000), lr: 0.000990471662605733\n",
      "step: 181, acc: 0.883, loss: 0.592 (data_loss: 0.592, reg_loss: 0.000), lr: 0.0009904618523617563\n",
      "step: 182, acc: 0.844, loss: 0.690 (data_loss: 0.690, reg_loss: 0.000), lr: 0.0009904520423121112\n",
      "step: 183, acc: 0.797, loss: 0.708 (data_loss: 0.708, reg_loss: 0.000), lr: 0.000990442232456792\n",
      "step: 184, acc: 0.852, loss: 0.686 (data_loss: 0.686, reg_loss: 0.000), lr: 0.0009904324227957928\n",
      "step: 185, acc: 0.797, loss: 0.753 (data_loss: 0.753, reg_loss: 0.000), lr: 0.0009904226133291075\n",
      "step: 186, acc: 0.820, loss: 0.725 (data_loss: 0.725, reg_loss: 0.000), lr: 0.000990412804056731\n",
      "step: 187, acc: 0.836, loss: 0.665 (data_loss: 0.665, reg_loss: 0.000), lr: 0.0009904029949786568\n",
      "step: 188, acc: 0.867, loss: 0.611 (data_loss: 0.611, reg_loss: 0.000), lr: 0.0009903931860948795\n",
      "step: 189, acc: 0.828, loss: 0.637 (data_loss: 0.637, reg_loss: 0.000), lr: 0.0009903833774053935\n",
      "step: 190, acc: 0.789, loss: 0.726 (data_loss: 0.726, reg_loss: 0.000), lr: 0.000990373568910193\n",
      "step: 191, acc: 0.852, loss: 0.591 (data_loss: 0.591, reg_loss: 0.000), lr: 0.0009903637606092717\n",
      "step: 192, acc: 0.898, loss: 0.555 (data_loss: 0.555, reg_loss: 0.000), lr: 0.0009903539525026243\n",
      "step: 193, acc: 0.844, loss: 0.687 (data_loss: 0.687, reg_loss: 0.000), lr: 0.0009903441445902451\n",
      "step: 194, acc: 0.812, loss: 0.742 (data_loss: 0.742, reg_loss: 0.000), lr: 0.0009903343368721281\n",
      "step: 195, acc: 0.852, loss: 0.668 (data_loss: 0.668, reg_loss: 0.000), lr: 0.0009903245293482674\n",
      "step: 196, acc: 0.797, loss: 0.682 (data_loss: 0.682, reg_loss: 0.000), lr: 0.0009903147220186577\n",
      "step: 197, acc: 0.859, loss: 0.672 (data_loss: 0.672, reg_loss: 0.000), lr: 0.0009903049148832926\n",
      "step: 198, acc: 0.820, loss: 0.762 (data_loss: 0.762, reg_loss: 0.000), lr: 0.0009902951079421667\n",
      "step: 199, acc: 0.883, loss: 0.615 (data_loss: 0.615, reg_loss: 0.000), lr: 0.0009902853011952743\n",
      "step: 200, acc: 0.797, loss: 0.698 (data_loss: 0.698, reg_loss: 0.000), lr: 0.0009902754946426097\n",
      "step: 201, acc: 0.805, loss: 0.771 (data_loss: 0.771, reg_loss: 0.000), lr: 0.0009902656882841666\n",
      "step: 202, acc: 0.812, loss: 0.739 (data_loss: 0.739, reg_loss: 0.000), lr: 0.0009902558821199398\n",
      "step: 203, acc: 0.836, loss: 0.723 (data_loss: 0.723, reg_loss: 0.000), lr: 0.0009902460761499234\n",
      "step: 204, acc: 0.891, loss: 0.583 (data_loss: 0.583, reg_loss: 0.000), lr: 0.0009902362703741114\n",
      "step: 205, acc: 0.852, loss: 0.596 (data_loss: 0.596, reg_loss: 0.000), lr: 0.000990226464792498\n",
      "step: 206, acc: 0.797, loss: 0.713 (data_loss: 0.713, reg_loss: 0.000), lr: 0.0009902166594050778\n",
      "step: 207, acc: 0.812, loss: 0.665 (data_loss: 0.665, reg_loss: 0.000), lr: 0.000990206854211845\n",
      "step: 208, acc: 0.828, loss: 0.665 (data_loss: 0.665, reg_loss: 0.000), lr: 0.0009901970492127933\n",
      "step: 209, acc: 0.820, loss: 0.703 (data_loss: 0.703, reg_loss: 0.000), lr: 0.0009901872444079175\n",
      "step: 210, acc: 0.820, loss: 0.672 (data_loss: 0.672, reg_loss: 0.000), lr: 0.0009901774397972117\n",
      "step: 211, acc: 0.883, loss: 0.644 (data_loss: 0.644, reg_loss: 0.000), lr: 0.00099016763538067\n",
      "step: 212, acc: 0.867, loss: 0.636 (data_loss: 0.636, reg_loss: 0.000), lr: 0.0009901578311582867\n",
      "step: 213, acc: 0.859, loss: 0.674 (data_loss: 0.674, reg_loss: 0.000), lr: 0.000990148027130056\n",
      "step: 214, acc: 0.836, loss: 0.649 (data_loss: 0.649, reg_loss: 0.000), lr: 0.0009901382232959722\n",
      "step: 215, acc: 0.852, loss: 0.675 (data_loss: 0.675, reg_loss: 0.000), lr: 0.0009901284196560294\n",
      "step: 216, acc: 0.797, loss: 0.716 (data_loss: 0.716, reg_loss: 0.000), lr: 0.0009901186162102219\n",
      "step: 217, acc: 0.820, loss: 0.668 (data_loss: 0.668, reg_loss: 0.000), lr: 0.0009901088129585442\n",
      "step: 218, acc: 0.797, loss: 0.709 (data_loss: 0.709, reg_loss: 0.000), lr: 0.0009900990099009901\n",
      "step: 219, acc: 0.805, loss: 0.685 (data_loss: 0.685, reg_loss: 0.000), lr: 0.000990089207037554\n",
      "step: 220, acc: 0.867, loss: 0.646 (data_loss: 0.646, reg_loss: 0.000), lr: 0.0009900794043682304\n",
      "step: 221, acc: 0.836, loss: 0.667 (data_loss: 0.667, reg_loss: 0.000), lr: 0.0009900696018930132\n",
      "step: 222, acc: 0.750, loss: 0.741 (data_loss: 0.741, reg_loss: 0.000), lr: 0.0009900597996118966\n",
      "step: 223, acc: 0.812, loss: 0.697 (data_loss: 0.697, reg_loss: 0.000), lr: 0.0009900499975248752\n",
      "step: 224, acc: 0.789, loss: 0.672 (data_loss: 0.672, reg_loss: 0.000), lr: 0.0009900401956319427\n",
      "step: 225, acc: 0.750, loss: 0.831 (data_loss: 0.831, reg_loss: 0.000), lr: 0.0009900303939330939\n",
      "step: 226, acc: 0.852, loss: 0.665 (data_loss: 0.665, reg_loss: 0.000), lr: 0.0009900205924283224\n",
      "step: 227, acc: 0.836, loss: 0.709 (data_loss: 0.709, reg_loss: 0.000), lr: 0.0009900107911176232\n",
      "step: 228, acc: 0.805, loss: 0.714 (data_loss: 0.714, reg_loss: 0.000), lr: 0.00099000099000099\n",
      "step: 229, acc: 0.844, loss: 0.690 (data_loss: 0.690, reg_loss: 0.000), lr: 0.0009899911890784172\n",
      "step: 230, acc: 0.883, loss: 0.660 (data_loss: 0.660, reg_loss: 0.000), lr: 0.0009899813883498991\n",
      "step: 231, acc: 0.859, loss: 0.587 (data_loss: 0.587, reg_loss: 0.000), lr: 0.0009899715878154297\n",
      "step: 232, acc: 0.875, loss: 0.607 (data_loss: 0.607, reg_loss: 0.000), lr: 0.0009899617874750035\n",
      "step: 233, acc: 0.844, loss: 0.747 (data_loss: 0.747, reg_loss: 0.000), lr: 0.0009899519873286145\n",
      "step: 234, acc: 0.828, loss: 0.707 (data_loss: 0.707, reg_loss: 0.000), lr: 0.0009899421873762573\n",
      "step: 235, acc: 0.852, loss: 0.686 (data_loss: 0.686, reg_loss: 0.000), lr: 0.0009899323876179256\n",
      "step: 236, acc: 0.867, loss: 0.644 (data_loss: 0.644, reg_loss: 0.000), lr: 0.0009899225880536141\n",
      "step: 237, acc: 0.875, loss: 0.592 (data_loss: 0.592, reg_loss: 0.000), lr: 0.0009899127886833171\n",
      "step: 238, acc: 0.820, loss: 0.589 (data_loss: 0.589, reg_loss: 0.000), lr: 0.0009899029895070284\n",
      "step: 239, acc: 0.867, loss: 0.656 (data_loss: 0.656, reg_loss: 0.000), lr: 0.0009898931905247424\n",
      "step: 240, acc: 0.859, loss: 0.602 (data_loss: 0.602, reg_loss: 0.000), lr: 0.0009898833917364536\n",
      "step: 241, acc: 0.812, loss: 0.703 (data_loss: 0.703, reg_loss: 0.000), lr: 0.0009898735931421559\n",
      "step: 242, acc: 0.914, loss: 0.557 (data_loss: 0.557, reg_loss: 0.000), lr: 0.0009898637947418434\n",
      "step: 243, acc: 0.875, loss: 0.554 (data_loss: 0.554, reg_loss: 0.000), lr: 0.000989853996535511\n",
      "step: 244, acc: 0.836, loss: 0.631 (data_loss: 0.631, reg_loss: 0.000), lr: 0.0009898441985231525\n",
      "step: 245, acc: 0.820, loss: 0.709 (data_loss: 0.709, reg_loss: 0.000), lr: 0.000989834400704762\n",
      "step: 246, acc: 0.805, loss: 0.604 (data_loss: 0.604, reg_loss: 0.000), lr: 0.0009898246030803342\n",
      "step: 247, acc: 0.844, loss: 0.625 (data_loss: 0.625, reg_loss: 0.000), lr: 0.0009898148056498631\n",
      "step: 248, acc: 0.812, loss: 0.665 (data_loss: 0.665, reg_loss: 0.000), lr: 0.0009898050084133426\n",
      "step: 249, acc: 0.805, loss: 0.691 (data_loss: 0.691, reg_loss: 0.000), lr: 0.0009897952113707674\n",
      "step: 250, acc: 0.867, loss: 0.605 (data_loss: 0.605, reg_loss: 0.000), lr: 0.0009897854145221317\n",
      "step: 251, acc: 0.883, loss: 0.613 (data_loss: 0.613, reg_loss: 0.000), lr: 0.0009897756178674296\n",
      "step: 252, acc: 0.852, loss: 0.622 (data_loss: 0.622, reg_loss: 0.000), lr: 0.0009897658214066552\n",
      "step: 253, acc: 0.859, loss: 0.584 (data_loss: 0.584, reg_loss: 0.000), lr: 0.000989756025139803\n",
      "step: 254, acc: 0.844, loss: 0.706 (data_loss: 0.706, reg_loss: 0.000), lr: 0.0009897462290668674\n",
      "step: 255, acc: 0.852, loss: 0.663 (data_loss: 0.663, reg_loss: 0.000), lr: 0.0009897364331878421\n",
      "step: 256, acc: 0.805, loss: 0.654 (data_loss: 0.654, reg_loss: 0.000), lr: 0.0009897266375027216\n",
      "step: 257, acc: 0.773, loss: 0.712 (data_loss: 0.712, reg_loss: 0.000), lr: 0.0009897168420115005\n",
      "step: 258, acc: 0.859, loss: 0.626 (data_loss: 0.626, reg_loss: 0.000), lr: 0.0009897070467141727\n",
      "step: 259, acc: 0.820, loss: 0.623 (data_loss: 0.623, reg_loss: 0.000), lr: 0.0009896972516107324\n",
      "step: 260, acc: 0.812, loss: 0.710 (data_loss: 0.710, reg_loss: 0.000), lr: 0.0009896874567011736\n",
      "step: 261, acc: 0.852, loss: 0.593 (data_loss: 0.593, reg_loss: 0.000), lr: 0.0009896776619854914\n",
      "step: 262, acc: 0.859, loss: 0.642 (data_loss: 0.642, reg_loss: 0.000), lr: 0.0009896678674636793\n",
      "step: 263, acc: 0.789, loss: 0.647 (data_loss: 0.647, reg_loss: 0.000), lr: 0.0009896580731357314\n",
      "step: 264, acc: 0.766, loss: 0.684 (data_loss: 0.684, reg_loss: 0.000), lr: 0.0009896482790016428\n",
      "step: 265, acc: 0.836, loss: 0.659 (data_loss: 0.659, reg_loss: 0.000), lr: 0.000989638485061407\n",
      "step: 266, acc: 0.836, loss: 0.734 (data_loss: 0.734, reg_loss: 0.000), lr: 0.0009896286913150185\n",
      "step: 267, acc: 0.820, loss: 0.673 (data_loss: 0.673, reg_loss: 0.000), lr: 0.0009896188977624716\n",
      "step: 268, acc: 0.781, loss: 0.810 (data_loss: 0.810, reg_loss: 0.000), lr: 0.0009896091044037606\n",
      "step: 269, acc: 0.836, loss: 0.627 (data_loss: 0.627, reg_loss: 0.000), lr: 0.0009895993112388794\n",
      "step: 270, acc: 0.805, loss: 0.709 (data_loss: 0.709, reg_loss: 0.000), lr: 0.0009895895182678225\n",
      "step: 271, acc: 0.852, loss: 0.636 (data_loss: 0.636, reg_loss: 0.000), lr: 0.0009895797254905843\n",
      "step: 272, acc: 0.844, loss: 0.593 (data_loss: 0.593, reg_loss: 0.000), lr: 0.0009895699329071587\n",
      "step: 273, acc: 0.891, loss: 0.579 (data_loss: 0.579, reg_loss: 0.000), lr: 0.0009895601405175399\n",
      "step: 274, acc: 0.797, loss: 0.691 (data_loss: 0.691, reg_loss: 0.000), lr: 0.0009895503483217227\n",
      "step: 275, acc: 0.773, loss: 0.756 (data_loss: 0.756, reg_loss: 0.000), lr: 0.000989540556319701\n",
      "step: 276, acc: 0.852, loss: 0.667 (data_loss: 0.667, reg_loss: 0.000), lr: 0.0009895307645114686\n",
      "step: 277, acc: 0.805, loss: 0.657 (data_loss: 0.657, reg_loss: 0.000), lr: 0.0009895209728970206\n",
      "step: 278, acc: 0.836, loss: 0.607 (data_loss: 0.607, reg_loss: 0.000), lr: 0.0009895111814763509\n",
      "step: 279, acc: 0.828, loss: 0.708 (data_loss: 0.708, reg_loss: 0.000), lr: 0.0009895013902494532\n",
      "step: 280, acc: 0.859, loss: 0.638 (data_loss: 0.638, reg_loss: 0.000), lr: 0.0009894915992163225\n",
      "step: 281, acc: 0.844, loss: 0.667 (data_loss: 0.667, reg_loss: 0.000), lr: 0.0009894818083769532\n",
      "step: 282, acc: 0.836, loss: 0.666 (data_loss: 0.666, reg_loss: 0.000), lr: 0.0009894720177313385\n",
      "step: 283, acc: 0.781, loss: 0.693 (data_loss: 0.693, reg_loss: 0.000), lr: 0.0009894622272794737\n",
      "step: 284, acc: 0.828, loss: 0.611 (data_loss: 0.611, reg_loss: 0.000), lr: 0.0009894524370213525\n",
      "step: 285, acc: 0.914, loss: 0.488 (data_loss: 0.488, reg_loss: 0.000), lr: 0.0009894426469569692\n",
      "step: 286, acc: 0.875, loss: 0.540 (data_loss: 0.540, reg_loss: 0.000), lr: 0.000989432857086318\n",
      "step: 287, acc: 0.812, loss: 0.739 (data_loss: 0.739, reg_loss: 0.000), lr: 0.0009894230674093935\n",
      "step: 288, acc: 0.859, loss: 0.632 (data_loss: 0.632, reg_loss: 0.000), lr: 0.0009894132779261898\n",
      "step: 289, acc: 0.844, loss: 0.598 (data_loss: 0.598, reg_loss: 0.000), lr: 0.000989403488636701\n",
      "step: 290, acc: 0.852, loss: 0.582 (data_loss: 0.582, reg_loss: 0.000), lr: 0.0009893936995409214\n",
      "step: 291, acc: 0.797, loss: 0.687 (data_loss: 0.687, reg_loss: 0.000), lr: 0.0009893839106388453\n",
      "step: 292, acc: 0.797, loss: 0.651 (data_loss: 0.651, reg_loss: 0.000), lr: 0.000989374121930467\n",
      "step: 293, acc: 0.867, loss: 0.516 (data_loss: 0.516, reg_loss: 0.000), lr: 0.0009893643334157804\n",
      "step: 294, acc: 0.828, loss: 0.683 (data_loss: 0.683, reg_loss: 0.000), lr: 0.00098935454509478\n",
      "step: 295, acc: 0.852, loss: 0.679 (data_loss: 0.679, reg_loss: 0.000), lr: 0.0009893447569674606\n",
      "step: 296, acc: 0.836, loss: 0.591 (data_loss: 0.591, reg_loss: 0.000), lr: 0.0009893349690338156\n",
      "step: 297, acc: 0.844, loss: 0.672 (data_loss: 0.672, reg_loss: 0.000), lr: 0.0009893251812938394\n",
      "step: 298, acc: 0.836, loss: 0.627 (data_loss: 0.627, reg_loss: 0.000), lr: 0.0009893153937475267\n",
      "step: 299, acc: 0.898, loss: 0.584 (data_loss: 0.584, reg_loss: 0.000), lr: 0.0009893056063948714\n",
      "step: 300, acc: 0.852, loss: 0.605 (data_loss: 0.605, reg_loss: 0.000), lr: 0.0009892958192358678\n",
      "step: 301, acc: 0.805, loss: 0.644 (data_loss: 0.644, reg_loss: 0.000), lr: 0.0009892860322705105\n",
      "step: 302, acc: 0.844, loss: 0.677 (data_loss: 0.677, reg_loss: 0.000), lr: 0.000989276245498793\n",
      "step: 303, acc: 0.828, loss: 0.613 (data_loss: 0.613, reg_loss: 0.000), lr: 0.0009892664589207104\n",
      "step: 304, acc: 0.844, loss: 0.653 (data_loss: 0.653, reg_loss: 0.000), lr: 0.0009892566725362563\n",
      "step: 305, acc: 0.836, loss: 0.626 (data_loss: 0.626, reg_loss: 0.000), lr: 0.0009892468863454253\n",
      "step: 306, acc: 0.859, loss: 0.605 (data_loss: 0.605, reg_loss: 0.000), lr: 0.0009892371003482115\n",
      "step: 307, acc: 0.867, loss: 0.582 (data_loss: 0.582, reg_loss: 0.000), lr: 0.0009892273145446092\n",
      "step: 308, acc: 0.812, loss: 0.648 (data_loss: 0.648, reg_loss: 0.000), lr: 0.0009892175289346128\n",
      "step: 309, acc: 0.852, loss: 0.669 (data_loss: 0.669, reg_loss: 0.000), lr: 0.0009892077435182164\n",
      "step: 310, acc: 0.883, loss: 0.560 (data_loss: 0.560, reg_loss: 0.000), lr: 0.000989197958295414\n",
      "step: 311, acc: 0.844, loss: 0.641 (data_loss: 0.641, reg_loss: 0.000), lr: 0.0009891881732662004\n",
      "step: 312, acc: 0.805, loss: 0.662 (data_loss: 0.662, reg_loss: 0.000), lr: 0.0009891783884305697\n",
      "step: 313, acc: 0.844, loss: 0.620 (data_loss: 0.620, reg_loss: 0.000), lr: 0.0009891686037885158\n",
      "step: 314, acc: 0.875, loss: 0.553 (data_loss: 0.553, reg_loss: 0.000), lr: 0.000989158819340033\n",
      "step: 315, acc: 0.852, loss: 0.662 (data_loss: 0.662, reg_loss: 0.000), lr: 0.0009891490350851164\n",
      "step: 316, acc: 0.859, loss: 0.551 (data_loss: 0.551, reg_loss: 0.000), lr: 0.000989139251023759\n",
      "step: 317, acc: 0.828, loss: 0.563 (data_loss: 0.563, reg_loss: 0.000), lr: 0.000989129467155956\n",
      "step: 318, acc: 0.820, loss: 0.661 (data_loss: 0.661, reg_loss: 0.000), lr: 0.0009891196834817015\n",
      "step: 319, acc: 0.867, loss: 0.545 (data_loss: 0.545, reg_loss: 0.000), lr: 0.0009891099000009893\n",
      "step: 320, acc: 0.789, loss: 0.661 (data_loss: 0.661, reg_loss: 0.000), lr: 0.0009891001167138137\n",
      "step: 321, acc: 0.820, loss: 0.676 (data_loss: 0.676, reg_loss: 0.000), lr: 0.0009890903336201694\n",
      "step: 322, acc: 0.844, loss: 0.610 (data_loss: 0.610, reg_loss: 0.000), lr: 0.0009890805507200508\n",
      "step: 323, acc: 0.883, loss: 0.593 (data_loss: 0.593, reg_loss: 0.000), lr: 0.0009890707680134513\n",
      "step: 324, acc: 0.828, loss: 0.656 (data_loss: 0.656, reg_loss: 0.000), lr: 0.000989060985500366\n",
      "step: 325, acc: 0.875, loss: 0.660 (data_loss: 0.660, reg_loss: 0.000), lr: 0.0009890512031807887\n",
      "step: 326, acc: 0.836, loss: 0.614 (data_loss: 0.614, reg_loss: 0.000), lr: 0.0009890414210547138\n",
      "step: 327, acc: 0.867, loss: 0.637 (data_loss: 0.637, reg_loss: 0.000), lr: 0.0009890316391221354\n",
      "step: 328, acc: 0.820, loss: 0.637 (data_loss: 0.637, reg_loss: 0.000), lr: 0.000989021857383048\n",
      "step: 329, acc: 0.883, loss: 0.559 (data_loss: 0.559, reg_loss: 0.000), lr: 0.000989012075837446\n",
      "step: 330, acc: 0.836, loss: 0.600 (data_loss: 0.600, reg_loss: 0.000), lr: 0.0009890022944853232\n",
      "step: 331, acc: 0.828, loss: 0.643 (data_loss: 0.643, reg_loss: 0.000), lr: 0.000988992513326674\n",
      "step: 332, acc: 0.859, loss: 0.645 (data_loss: 0.645, reg_loss: 0.000), lr: 0.000988982732361493\n",
      "step: 333, acc: 0.844, loss: 0.646 (data_loss: 0.646, reg_loss: 0.000), lr: 0.000988972951589774\n",
      "step: 334, acc: 0.812, loss: 0.722 (data_loss: 0.722, reg_loss: 0.000), lr: 0.0009889631710115114\n",
      "step: 335, acc: 0.844, loss: 0.570 (data_loss: 0.570, reg_loss: 0.000), lr: 0.0009889533906267\n",
      "step: 336, acc: 0.859, loss: 0.576 (data_loss: 0.576, reg_loss: 0.000), lr: 0.000988943610435333\n",
      "step: 337, acc: 0.836, loss: 0.613 (data_loss: 0.613, reg_loss: 0.000), lr: 0.0009889338304374055\n",
      "step: 338, acc: 0.891, loss: 0.491 (data_loss: 0.491, reg_loss: 0.000), lr: 0.0009889240506329115\n",
      "step: 339, acc: 0.820, loss: 0.635 (data_loss: 0.635, reg_loss: 0.000), lr: 0.0009889142710218452\n",
      "step: 340, acc: 0.906, loss: 0.521 (data_loss: 0.521, reg_loss: 0.000), lr: 0.000988904491604201\n",
      "step: 341, acc: 0.773, loss: 0.680 (data_loss: 0.680, reg_loss: 0.000), lr: 0.0009888947123799729\n",
      "step: 342, acc: 0.773, loss: 0.667 (data_loss: 0.667, reg_loss: 0.000), lr: 0.0009888849333491555\n",
      "step: 343, acc: 0.820, loss: 0.637 (data_loss: 0.637, reg_loss: 0.000), lr: 0.000988875154511743\n",
      "step: 344, acc: 0.859, loss: 0.608 (data_loss: 0.608, reg_loss: 0.000), lr: 0.0009888653758677293\n",
      "step: 345, acc: 0.867, loss: 0.593 (data_loss: 0.593, reg_loss: 0.000), lr: 0.0009888555974171093\n",
      "step: 346, acc: 0.805, loss: 0.654 (data_loss: 0.654, reg_loss: 0.000), lr: 0.0009888458191598768\n",
      "step: 347, acc: 0.867, loss: 0.537 (data_loss: 0.537, reg_loss: 0.000), lr: 0.0009888360410960258\n",
      "step: 348, acc: 0.820, loss: 0.637 (data_loss: 0.637, reg_loss: 0.000), lr: 0.0009888262632255513\n",
      "step: 349, acc: 0.797, loss: 0.643 (data_loss: 0.643, reg_loss: 0.000), lr: 0.0009888164855484472\n",
      "step: 350, acc: 0.820, loss: 0.653 (data_loss: 0.653, reg_loss: 0.000), lr: 0.0009888067080647076\n",
      "step: 351, acc: 0.859, loss: 0.563 (data_loss: 0.563, reg_loss: 0.000), lr: 0.0009887969307743269\n",
      "step: 352, acc: 0.828, loss: 0.620 (data_loss: 0.620, reg_loss: 0.000), lr: 0.0009887871536772995\n",
      "step: 353, acc: 0.805, loss: 0.688 (data_loss: 0.688, reg_loss: 0.000), lr: 0.0009887773767736194\n",
      "step: 354, acc: 0.805, loss: 0.680 (data_loss: 0.680, reg_loss: 0.000), lr: 0.0009887676000632812\n",
      "step: 355, acc: 0.898, loss: 0.565 (data_loss: 0.565, reg_loss: 0.000), lr: 0.0009887578235462787\n",
      "step: 356, acc: 0.828, loss: 0.697 (data_loss: 0.697, reg_loss: 0.000), lr: 0.0009887480472226067\n",
      "step: 357, acc: 0.891, loss: 0.526 (data_loss: 0.526, reg_loss: 0.000), lr: 0.0009887382710922592\n",
      "step: 358, acc: 0.875, loss: 0.539 (data_loss: 0.539, reg_loss: 0.000), lr: 0.0009887284951552303\n",
      "step: 359, acc: 0.852, loss: 0.547 (data_loss: 0.547, reg_loss: 0.000), lr: 0.0009887187194115147\n",
      "step: 360, acc: 0.781, loss: 0.642 (data_loss: 0.642, reg_loss: 0.000), lr: 0.0009887089438611063\n",
      "step: 361, acc: 0.867, loss: 0.588 (data_loss: 0.588, reg_loss: 0.000), lr: 0.0009886991685039992\n",
      "step: 362, acc: 0.836, loss: 0.538 (data_loss: 0.538, reg_loss: 0.000), lr: 0.0009886893933401884\n",
      "step: 363, acc: 0.805, loss: 0.664 (data_loss: 0.664, reg_loss: 0.000), lr: 0.0009886796183696674\n",
      "step: 364, acc: 0.820, loss: 0.612 (data_loss: 0.612, reg_loss: 0.000), lr: 0.0009886698435924307\n",
      "step: 365, acc: 0.836, loss: 0.597 (data_loss: 0.597, reg_loss: 0.000), lr: 0.0009886600690084727\n",
      "step: 366, acc: 0.789, loss: 0.648 (data_loss: 0.648, reg_loss: 0.000), lr: 0.0009886502946177878\n",
      "step: 367, acc: 0.883, loss: 0.486 (data_loss: 0.486, reg_loss: 0.000), lr: 0.00098864052042037\n",
      "step: 368, acc: 0.867, loss: 0.594 (data_loss: 0.594, reg_loss: 0.000), lr: 0.0009886307464162135\n",
      "step: 369, acc: 0.836, loss: 0.610 (data_loss: 0.610, reg_loss: 0.000), lr: 0.0009886209726053129\n",
      "step: 370, acc: 0.812, loss: 0.619 (data_loss: 0.619, reg_loss: 0.000), lr: 0.0009886111989876622\n",
      "step: 371, acc: 0.867, loss: 0.548 (data_loss: 0.548, reg_loss: 0.000), lr: 0.0009886014255632556\n",
      "step: 372, acc: 0.844, loss: 0.554 (data_loss: 0.554, reg_loss: 0.000), lr: 0.0009885916523320877\n",
      "step: 373, acc: 0.914, loss: 0.536 (data_loss: 0.536, reg_loss: 0.000), lr: 0.0009885818792941526\n",
      "step: 374, acc: 0.852, loss: 0.533 (data_loss: 0.533, reg_loss: 0.000), lr: 0.0009885721064494444\n",
      "step: 375, acc: 0.859, loss: 0.604 (data_loss: 0.604, reg_loss: 0.000), lr: 0.0009885623337979575\n",
      "step: 376, acc: 0.867, loss: 0.602 (data_loss: 0.602, reg_loss: 0.000), lr: 0.0009885525613396865\n",
      "step: 377, acc: 0.891, loss: 0.533 (data_loss: 0.533, reg_loss: 0.000), lr: 0.000988542789074625\n",
      "step: 378, acc: 0.812, loss: 0.598 (data_loss: 0.598, reg_loss: 0.000), lr: 0.0009885330170027679\n",
      "step: 379, acc: 0.820, loss: 0.626 (data_loss: 0.626, reg_loss: 0.000), lr: 0.0009885232451241092\n",
      "step: 380, acc: 0.844, loss: 0.629 (data_loss: 0.629, reg_loss: 0.000), lr: 0.000988513473438643\n",
      "step: 381, acc: 0.859, loss: 0.577 (data_loss: 0.577, reg_loss: 0.000), lr: 0.0009885037019463638\n",
      "step: 382, acc: 0.891, loss: 0.562 (data_loss: 0.562, reg_loss: 0.000), lr: 0.0009884939306472659\n",
      "step: 383, acc: 0.812, loss: 0.603 (data_loss: 0.603, reg_loss: 0.000), lr: 0.0009884841595413434\n",
      "step: 384, acc: 0.797, loss: 0.672 (data_loss: 0.672, reg_loss: 0.000), lr: 0.0009884743886285907\n",
      "step: 385, acc: 0.891, loss: 0.521 (data_loss: 0.521, reg_loss: 0.000), lr: 0.0009884646179090018\n",
      "step: 386, acc: 0.820, loss: 0.633 (data_loss: 0.633, reg_loss: 0.000), lr: 0.0009884548473825716\n",
      "step: 387, acc: 0.891, loss: 0.501 (data_loss: 0.501, reg_loss: 0.000), lr: 0.0009884450770492937\n",
      "step: 388, acc: 0.875, loss: 0.539 (data_loss: 0.539, reg_loss: 0.000), lr: 0.0009884353069091628\n",
      "step: 389, acc: 0.867, loss: 0.539 (data_loss: 0.539, reg_loss: 0.000), lr: 0.0009884255369621729\n",
      "step: 390, acc: 0.875, loss: 0.475 (data_loss: 0.475, reg_loss: 0.000), lr: 0.0009884157672083187\n",
      "training, acc: 0.829, loss: 0.684 (data_loss: 0.684, reg_loss: 0.000), lr: 0.0009884157672083187\n",
      "validation, acc: 0.850, loss: 0.584\n",
      "epoch: 4\n",
      "step: 0, acc: 0.820, loss: 0.683 (data_loss: 0.683, reg_loss: 0.000), lr: 0.0009884059976475938\n",
      "step: 1, acc: 0.836, loss: 0.692 (data_loss: 0.692, reg_loss: 0.000), lr: 0.000988396228279993\n",
      "step: 2, acc: 0.828, loss: 0.600 (data_loss: 0.600, reg_loss: 0.000), lr: 0.0009883864591055103\n",
      "step: 3, acc: 0.859, loss: 0.537 (data_loss: 0.537, reg_loss: 0.000), lr: 0.0009883766901241401\n",
      "step: 4, acc: 0.883, loss: 0.574 (data_loss: 0.574, reg_loss: 0.000), lr: 0.0009883669213358766\n",
      "step: 5, acc: 0.859, loss: 0.629 (data_loss: 0.629, reg_loss: 0.000), lr: 0.0009883571527407144\n",
      "step: 6, acc: 0.875, loss: 0.611 (data_loss: 0.611, reg_loss: 0.000), lr: 0.0009883473843386474\n",
      "step: 7, acc: 0.914, loss: 0.499 (data_loss: 0.499, reg_loss: 0.000), lr: 0.0009883376161296698\n",
      "step: 8, acc: 0.859, loss: 0.608 (data_loss: 0.608, reg_loss: 0.000), lr: 0.0009883278481137763\n",
      "step: 9, acc: 0.883, loss: 0.579 (data_loss: 0.579, reg_loss: 0.000), lr: 0.000988318080290961\n",
      "step: 10, acc: 0.883, loss: 0.537 (data_loss: 0.537, reg_loss: 0.000), lr: 0.0009883083126612177\n",
      "step: 11, acc: 0.828, loss: 0.586 (data_loss: 0.586, reg_loss: 0.000), lr: 0.0009882985452245414\n",
      "step: 12, acc: 0.852, loss: 0.548 (data_loss: 0.548, reg_loss: 0.000), lr: 0.0009882887779809261\n",
      "step: 13, acc: 0.812, loss: 0.659 (data_loss: 0.659, reg_loss: 0.000), lr: 0.0009882790109303659\n",
      "step: 14, acc: 0.828, loss: 0.580 (data_loss: 0.580, reg_loss: 0.000), lr: 0.0009882692440728552\n",
      "step: 15, acc: 0.836, loss: 0.541 (data_loss: 0.541, reg_loss: 0.000), lr: 0.0009882594774083882\n",
      "step: 16, acc: 0.852, loss: 0.600 (data_loss: 0.600, reg_loss: 0.000), lr: 0.0009882497109369595\n",
      "step: 17, acc: 0.844, loss: 0.552 (data_loss: 0.552, reg_loss: 0.000), lr: 0.000988239944658563\n",
      "step: 18, acc: 0.852, loss: 0.612 (data_loss: 0.612, reg_loss: 0.000), lr: 0.0009882301785731932\n",
      "step: 19, acc: 0.820, loss: 0.590 (data_loss: 0.590, reg_loss: 0.000), lr: 0.0009882204126808443\n",
      "step: 20, acc: 0.820, loss: 0.596 (data_loss: 0.596, reg_loss: 0.000), lr: 0.0009882106469815107\n",
      "step: 21, acc: 0.805, loss: 0.647 (data_loss: 0.647, reg_loss: 0.000), lr: 0.0009882008814751863\n",
      "step: 22, acc: 0.898, loss: 0.483 (data_loss: 0.483, reg_loss: 0.000), lr: 0.000988191116161866\n",
      "step: 23, acc: 0.828, loss: 0.610 (data_loss: 0.610, reg_loss: 0.000), lr: 0.0009881813510415431\n",
      "step: 24, acc: 0.875, loss: 0.532 (data_loss: 0.532, reg_loss: 0.000), lr: 0.0009881715861142129\n",
      "step: 25, acc: 0.875, loss: 0.520 (data_loss: 0.520, reg_loss: 0.000), lr: 0.000988161821379869\n",
      "step: 26, acc: 0.844, loss: 0.609 (data_loss: 0.609, reg_loss: 0.000), lr: 0.0009881520568385063\n",
      "step: 27, acc: 0.852, loss: 0.545 (data_loss: 0.545, reg_loss: 0.000), lr: 0.0009881422924901185\n",
      "step: 28, acc: 0.867, loss: 0.570 (data_loss: 0.570, reg_loss: 0.000), lr: 0.0009881325283347003\n",
      "step: 29, acc: 0.875, loss: 0.588 (data_loss: 0.588, reg_loss: 0.000), lr: 0.0009881227643722458\n",
      "step: 30, acc: 0.836, loss: 0.557 (data_loss: 0.557, reg_loss: 0.000), lr: 0.000988113000602749\n",
      "step: 31, acc: 0.883, loss: 0.601 (data_loss: 0.601, reg_loss: 0.000), lr: 0.0009881032370262044\n",
      "step: 32, acc: 0.859, loss: 0.534 (data_loss: 0.534, reg_loss: 0.000), lr: 0.0009880934736426067\n",
      "step: 33, acc: 0.836, loss: 0.588 (data_loss: 0.588, reg_loss: 0.000), lr: 0.0009880837104519495\n",
      "step: 34, acc: 0.828, loss: 0.572 (data_loss: 0.572, reg_loss: 0.000), lr: 0.0009880739474542276\n",
      "step: 35, acc: 0.828, loss: 0.589 (data_loss: 0.589, reg_loss: 0.000), lr: 0.0009880641846494347\n",
      "step: 36, acc: 0.875, loss: 0.548 (data_loss: 0.548, reg_loss: 0.000), lr: 0.0009880544220375658\n",
      "step: 37, acc: 0.836, loss: 0.537 (data_loss: 0.537, reg_loss: 0.000), lr: 0.0009880446596186147\n",
      "step: 38, acc: 0.812, loss: 0.595 (data_loss: 0.595, reg_loss: 0.000), lr: 0.0009880348973925759\n",
      "step: 39, acc: 0.812, loss: 0.660 (data_loss: 0.660, reg_loss: 0.000), lr: 0.0009880251353594435\n",
      "step: 40, acc: 0.883, loss: 0.537 (data_loss: 0.537, reg_loss: 0.000), lr: 0.000988015373519212\n",
      "step: 41, acc: 0.875, loss: 0.542 (data_loss: 0.542, reg_loss: 0.000), lr: 0.0009880056118718753\n",
      "step: 42, acc: 0.820, loss: 0.609 (data_loss: 0.609, reg_loss: 0.000), lr: 0.000987995850417428\n",
      "step: 43, acc: 0.844, loss: 0.552 (data_loss: 0.552, reg_loss: 0.000), lr: 0.0009879860891558647\n",
      "step: 44, acc: 0.867, loss: 0.620 (data_loss: 0.620, reg_loss: 0.000), lr: 0.0009879763280871792\n",
      "step: 45, acc: 0.844, loss: 0.595 (data_loss: 0.595, reg_loss: 0.000), lr: 0.0009879665672113654\n",
      "step: 46, acc: 0.859, loss: 0.590 (data_loss: 0.590, reg_loss: 0.000), lr: 0.0009879568065284186\n",
      "step: 47, acc: 0.828, loss: 0.633 (data_loss: 0.633, reg_loss: 0.000), lr: 0.0009879470460383323\n",
      "step: 48, acc: 0.852, loss: 0.525 (data_loss: 0.525, reg_loss: 0.000), lr: 0.000987937285741101\n",
      "step: 49, acc: 0.859, loss: 0.528 (data_loss: 0.528, reg_loss: 0.000), lr: 0.0009879275256367195\n",
      "step: 50, acc: 0.891, loss: 0.564 (data_loss: 0.564, reg_loss: 0.000), lr: 0.000987917765725181\n",
      "step: 51, acc: 0.883, loss: 0.546 (data_loss: 0.546, reg_loss: 0.000), lr: 0.0009879080060064807\n",
      "step: 52, acc: 0.867, loss: 0.598 (data_loss: 0.598, reg_loss: 0.000), lr: 0.0009878982464806125\n",
      "step: 53, acc: 0.758, loss: 0.726 (data_loss: 0.726, reg_loss: 0.000), lr: 0.000987888487147571\n",
      "step: 54, acc: 0.844, loss: 0.529 (data_loss: 0.529, reg_loss: 0.000), lr: 0.0009878787280073497\n",
      "step: 55, acc: 0.859, loss: 0.670 (data_loss: 0.670, reg_loss: 0.000), lr: 0.0009878689690599439\n",
      "step: 56, acc: 0.859, loss: 0.590 (data_loss: 0.590, reg_loss: 0.000), lr: 0.0009878592103053474\n",
      "step: 57, acc: 0.883, loss: 0.499 (data_loss: 0.499, reg_loss: 0.000), lr: 0.0009878494517435543\n",
      "step: 58, acc: 0.828, loss: 0.559 (data_loss: 0.559, reg_loss: 0.000), lr: 0.000987839693374559\n",
      "step: 59, acc: 0.836, loss: 0.587 (data_loss: 0.587, reg_loss: 0.000), lr: 0.0009878299351983562\n",
      "step: 60, acc: 0.867, loss: 0.601 (data_loss: 0.601, reg_loss: 0.000), lr: 0.00098782017721494\n",
      "step: 61, acc: 0.867, loss: 0.550 (data_loss: 0.550, reg_loss: 0.000), lr: 0.000987810419424304\n",
      "step: 62, acc: 0.883, loss: 0.525 (data_loss: 0.525, reg_loss: 0.000), lr: 0.0009878006618264433\n",
      "step: 63, acc: 0.844, loss: 0.611 (data_loss: 0.611, reg_loss: 0.000), lr: 0.0009877909044213522\n",
      "step: 64, acc: 0.828, loss: 0.637 (data_loss: 0.637, reg_loss: 0.000), lr: 0.0009877811472090243\n",
      "step: 65, acc: 0.805, loss: 0.721 (data_loss: 0.721, reg_loss: 0.000), lr: 0.0009877713901894544\n",
      "step: 66, acc: 0.883, loss: 0.544 (data_loss: 0.544, reg_loss: 0.000), lr: 0.000987761633362637\n",
      "step: 67, acc: 0.828, loss: 0.663 (data_loss: 0.663, reg_loss: 0.000), lr: 0.0009877518767285659\n",
      "step: 68, acc: 0.828, loss: 0.602 (data_loss: 0.602, reg_loss: 0.000), lr: 0.0009877421202872355\n",
      "step: 69, acc: 0.828, loss: 0.583 (data_loss: 0.583, reg_loss: 0.000), lr: 0.00098773236403864\n",
      "step: 70, acc: 0.875, loss: 0.498 (data_loss: 0.498, reg_loss: 0.000), lr: 0.0009877226079827743\n",
      "step: 71, acc: 0.875, loss: 0.520 (data_loss: 0.520, reg_loss: 0.000), lr: 0.0009877128521196318\n",
      "step: 72, acc: 0.867, loss: 0.539 (data_loss: 0.539, reg_loss: 0.000), lr: 0.0009877030964492073\n",
      "step: 73, acc: 0.922, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.0009876933409714954\n",
      "step: 74, acc: 0.820, loss: 0.651 (data_loss: 0.651, reg_loss: 0.000), lr: 0.0009876835856864896\n",
      "step: 75, acc: 0.852, loss: 0.619 (data_loss: 0.619, reg_loss: 0.000), lr: 0.0009876738305941847\n",
      "step: 76, acc: 0.875, loss: 0.518 (data_loss: 0.518, reg_loss: 0.000), lr: 0.0009876640756945748\n",
      "step: 77, acc: 0.898, loss: 0.471 (data_loss: 0.471, reg_loss: 0.000), lr: 0.0009876543209876543\n",
      "step: 78, acc: 0.859, loss: 0.615 (data_loss: 0.615, reg_loss: 0.000), lr: 0.0009876445664734174\n",
      "step: 79, acc: 0.844, loss: 0.607 (data_loss: 0.607, reg_loss: 0.000), lr: 0.0009876348121518586\n",
      "step: 80, acc: 0.797, loss: 0.625 (data_loss: 0.625, reg_loss: 0.000), lr: 0.0009876250580229723\n",
      "step: 81, acc: 0.820, loss: 0.589 (data_loss: 0.589, reg_loss: 0.000), lr: 0.0009876153040867522\n",
      "step: 82, acc: 0.914, loss: 0.486 (data_loss: 0.486, reg_loss: 0.000), lr: 0.0009876055503431928\n",
      "step: 83, acc: 0.789, loss: 0.638 (data_loss: 0.638, reg_loss: 0.000), lr: 0.000987595796792289\n",
      "step: 84, acc: 0.812, loss: 0.672 (data_loss: 0.672, reg_loss: 0.000), lr: 0.0009875860434340343\n",
      "step: 85, acc: 0.836, loss: 0.601 (data_loss: 0.601, reg_loss: 0.000), lr: 0.0009875762902684232\n",
      "step: 86, acc: 0.820, loss: 0.663 (data_loss: 0.663, reg_loss: 0.000), lr: 0.0009875665372954502\n",
      "step: 87, acc: 0.875, loss: 0.590 (data_loss: 0.590, reg_loss: 0.000), lr: 0.0009875567845151097\n",
      "step: 88, acc: 0.789, loss: 0.728 (data_loss: 0.728, reg_loss: 0.000), lr: 0.0009875470319273955\n",
      "step: 89, acc: 0.883, loss: 0.526 (data_loss: 0.526, reg_loss: 0.000), lr: 0.0009875372795323024\n",
      "step: 90, acc: 0.836, loss: 0.514 (data_loss: 0.514, reg_loss: 0.000), lr: 0.0009875275273298245\n",
      "step: 91, acc: 0.867, loss: 0.535 (data_loss: 0.535, reg_loss: 0.000), lr: 0.0009875177753199558\n",
      "step: 92, acc: 0.875, loss: 0.548 (data_loss: 0.548, reg_loss: 0.000), lr: 0.000987508023502691\n",
      "step: 93, acc: 0.852, loss: 0.577 (data_loss: 0.577, reg_loss: 0.000), lr: 0.0009874982718780243\n",
      "step: 94, acc: 0.883, loss: 0.558 (data_loss: 0.558, reg_loss: 0.000), lr: 0.00098748852044595\n",
      "step: 95, acc: 0.812, loss: 0.706 (data_loss: 0.706, reg_loss: 0.000), lr: 0.0009874787692064622\n",
      "step: 96, acc: 0.852, loss: 0.529 (data_loss: 0.529, reg_loss: 0.000), lr: 0.0009874690181595552\n",
      "step: 97, acc: 0.852, loss: 0.516 (data_loss: 0.516, reg_loss: 0.000), lr: 0.0009874592673052237\n",
      "step: 98, acc: 0.789, loss: 0.638 (data_loss: 0.638, reg_loss: 0.000), lr: 0.0009874495166434616\n",
      "step: 99, acc: 0.875, loss: 0.534 (data_loss: 0.534, reg_loss: 0.000), lr: 0.0009874397661742633\n",
      "step: 100, acc: 0.867, loss: 0.558 (data_loss: 0.558, reg_loss: 0.000), lr: 0.0009874300158976234\n",
      "step: 101, acc: 0.859, loss: 0.588 (data_loss: 0.588, reg_loss: 0.000), lr: 0.0009874202658135356\n",
      "step: 102, acc: 0.852, loss: 0.531 (data_loss: 0.531, reg_loss: 0.000), lr: 0.0009874105159219946\n",
      "step: 103, acc: 0.820, loss: 0.689 (data_loss: 0.689, reg_loss: 0.000), lr: 0.0009874007662229944\n",
      "step: 104, acc: 0.828, loss: 0.583 (data_loss: 0.583, reg_loss: 0.000), lr: 0.00098739101671653\n",
      "step: 105, acc: 0.844, loss: 0.489 (data_loss: 0.489, reg_loss: 0.000), lr: 0.000987381267402595\n",
      "step: 106, acc: 0.867, loss: 0.491 (data_loss: 0.491, reg_loss: 0.000), lr: 0.0009873715182811837\n",
      "step: 107, acc: 0.812, loss: 0.715 (data_loss: 0.715, reg_loss: 0.000), lr: 0.0009873617693522908\n",
      "step: 108, acc: 0.852, loss: 0.536 (data_loss: 0.536, reg_loss: 0.000), lr: 0.0009873520206159102\n",
      "step: 109, acc: 0.883, loss: 0.496 (data_loss: 0.496, reg_loss: 0.000), lr: 0.0009873422720720363\n",
      "step: 110, acc: 0.930, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.000987332523720664\n",
      "step: 111, acc: 0.812, loss: 0.572 (data_loss: 0.572, reg_loss: 0.000), lr: 0.0009873227755617868\n",
      "step: 112, acc: 0.844, loss: 0.596 (data_loss: 0.596, reg_loss: 0.000), lr: 0.0009873130275953991\n",
      "step: 113, acc: 0.875, loss: 0.533 (data_loss: 0.533, reg_loss: 0.000), lr: 0.0009873032798214955\n",
      "step: 114, acc: 0.867, loss: 0.565 (data_loss: 0.565, reg_loss: 0.000), lr: 0.0009872935322400704\n",
      "step: 115, acc: 0.875, loss: 0.506 (data_loss: 0.506, reg_loss: 0.000), lr: 0.0009872837848511175\n",
      "step: 116, acc: 0.812, loss: 0.644 (data_loss: 0.644, reg_loss: 0.000), lr: 0.0009872740376546318\n",
      "step: 117, acc: 0.875, loss: 0.528 (data_loss: 0.528, reg_loss: 0.000), lr: 0.0009872642906506074\n",
      "step: 118, acc: 0.859, loss: 0.533 (data_loss: 0.533, reg_loss: 0.000), lr: 0.000987254543839038\n",
      "step: 119, acc: 0.859, loss: 0.565 (data_loss: 0.565, reg_loss: 0.000), lr: 0.0009872447972199187\n",
      "step: 120, acc: 0.906, loss: 0.455 (data_loss: 0.455, reg_loss: 0.000), lr: 0.0009872350507932432\n",
      "step: 121, acc: 0.859, loss: 0.558 (data_loss: 0.558, reg_loss: 0.000), lr: 0.0009872253045590065\n",
      "step: 122, acc: 0.852, loss: 0.604 (data_loss: 0.604, reg_loss: 0.000), lr: 0.0009872155585172022\n",
      "step: 123, acc: 0.836, loss: 0.657 (data_loss: 0.657, reg_loss: 0.000), lr: 0.0009872058126678249\n",
      "step: 124, acc: 0.836, loss: 0.581 (data_loss: 0.581, reg_loss: 0.000), lr: 0.0009871960670108692\n",
      "step: 125, acc: 0.852, loss: 0.555 (data_loss: 0.555, reg_loss: 0.000), lr: 0.0009871863215463288\n",
      "step: 126, acc: 0.844, loss: 0.563 (data_loss: 0.563, reg_loss: 0.000), lr: 0.000987176576274198\n",
      "step: 127, acc: 0.898, loss: 0.481 (data_loss: 0.481, reg_loss: 0.000), lr: 0.000987166831194472\n",
      "step: 128, acc: 0.828, loss: 0.629 (data_loss: 0.629, reg_loss: 0.000), lr: 0.0009871570863071442\n",
      "step: 129, acc: 0.867, loss: 0.464 (data_loss: 0.464, reg_loss: 0.000), lr: 0.000987147341612209\n",
      "step: 130, acc: 0.812, loss: 0.678 (data_loss: 0.678, reg_loss: 0.000), lr: 0.000987137597109661\n",
      "step: 131, acc: 0.797, loss: 0.681 (data_loss: 0.681, reg_loss: 0.000), lr: 0.0009871278527994946\n",
      "step: 132, acc: 0.820, loss: 0.549 (data_loss: 0.549, reg_loss: 0.000), lr: 0.0009871181086817038\n",
      "step: 133, acc: 0.867, loss: 0.528 (data_loss: 0.528, reg_loss: 0.000), lr: 0.000987108364756283\n",
      "step: 134, acc: 0.898, loss: 0.493 (data_loss: 0.493, reg_loss: 0.000), lr: 0.0009870986210232266\n",
      "step: 135, acc: 0.875, loss: 0.477 (data_loss: 0.477, reg_loss: 0.000), lr: 0.0009870888774825286\n",
      "step: 136, acc: 0.844, loss: 0.523 (data_loss: 0.523, reg_loss: 0.000), lr: 0.0009870791341341834\n",
      "step: 137, acc: 0.930, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.0009870693909781857\n",
      "step: 138, acc: 0.844, loss: 0.557 (data_loss: 0.557, reg_loss: 0.000), lr: 0.0009870596480145296\n",
      "step: 139, acc: 0.859, loss: 0.582 (data_loss: 0.582, reg_loss: 0.000), lr: 0.0009870499052432092\n",
      "step: 140, acc: 0.852, loss: 0.552 (data_loss: 0.552, reg_loss: 0.000), lr: 0.0009870401626642187\n",
      "step: 141, acc: 0.867, loss: 0.582 (data_loss: 0.582, reg_loss: 0.000), lr: 0.000987030420277553\n",
      "step: 142, acc: 0.922, loss: 0.445 (data_loss: 0.445, reg_loss: 0.000), lr: 0.0009870206780832058\n",
      "step: 143, acc: 0.883, loss: 0.516 (data_loss: 0.516, reg_loss: 0.000), lr: 0.0009870109360811717\n",
      "step: 144, acc: 0.844, loss: 0.592 (data_loss: 0.592, reg_loss: 0.000), lr: 0.0009870011942714452\n",
      "step: 145, acc: 0.852, loss: 0.521 (data_loss: 0.521, reg_loss: 0.000), lr: 0.00098699145265402\n",
      "step: 146, acc: 0.883, loss: 0.668 (data_loss: 0.668, reg_loss: 0.000), lr: 0.000986981711228891\n",
      "step: 147, acc: 0.805, loss: 0.648 (data_loss: 0.648, reg_loss: 0.000), lr: 0.000986971969996052\n",
      "step: 148, acc: 0.836, loss: 0.618 (data_loss: 0.618, reg_loss: 0.000), lr: 0.0009869622289554979\n",
      "step: 149, acc: 0.883, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.0009869524881072225\n",
      "step: 150, acc: 0.875, loss: 0.493 (data_loss: 0.493, reg_loss: 0.000), lr: 0.0009869427474512203\n",
      "step: 151, acc: 0.875, loss: 0.516 (data_loss: 0.516, reg_loss: 0.000), lr: 0.0009869330069874858\n",
      "step: 152, acc: 0.883, loss: 0.558 (data_loss: 0.558, reg_loss: 0.000), lr: 0.0009869232667160128\n",
      "step: 153, acc: 0.805, loss: 0.620 (data_loss: 0.620, reg_loss: 0.000), lr: 0.000986913526636796\n",
      "step: 154, acc: 0.859, loss: 0.474 (data_loss: 0.474, reg_loss: 0.000), lr: 0.00098690378674983\n",
      "step: 155, acc: 0.867, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.0009868940470551082\n",
      "step: 156, acc: 0.844, loss: 0.511 (data_loss: 0.511, reg_loss: 0.000), lr: 0.0009868843075526257\n",
      "step: 157, acc: 0.844, loss: 0.572 (data_loss: 0.572, reg_loss: 0.000), lr: 0.0009868745682423763\n",
      "step: 158, acc: 0.852, loss: 0.646 (data_loss: 0.646, reg_loss: 0.000), lr: 0.000986864829124355\n",
      "step: 159, acc: 0.859, loss: 0.538 (data_loss: 0.538, reg_loss: 0.000), lr: 0.0009868550901985552\n",
      "step: 160, acc: 0.867, loss: 0.506 (data_loss: 0.506, reg_loss: 0.000), lr: 0.0009868453514649718\n",
      "step: 161, acc: 0.820, loss: 0.604 (data_loss: 0.604, reg_loss: 0.000), lr: 0.0009868356129235992\n",
      "step: 162, acc: 0.891, loss: 0.563 (data_loss: 0.563, reg_loss: 0.000), lr: 0.0009868258745744313\n",
      "step: 163, acc: 0.836, loss: 0.573 (data_loss: 0.573, reg_loss: 0.000), lr: 0.0009868161364174628\n",
      "step: 164, acc: 0.898, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0009868063984526875\n",
      "step: 165, acc: 0.859, loss: 0.487 (data_loss: 0.487, reg_loss: 0.000), lr: 0.0009867966606801003\n",
      "step: 166, acc: 0.812, loss: 0.628 (data_loss: 0.628, reg_loss: 0.000), lr: 0.0009867869230996951\n",
      "step: 167, acc: 0.789, loss: 0.612 (data_loss: 0.612, reg_loss: 0.000), lr: 0.0009867771857114663\n",
      "step: 168, acc: 0.828, loss: 0.674 (data_loss: 0.674, reg_loss: 0.000), lr: 0.0009867674485154083\n",
      "step: 169, acc: 0.859, loss: 0.508 (data_loss: 0.508, reg_loss: 0.000), lr: 0.0009867577115115155\n",
      "step: 170, acc: 0.844, loss: 0.610 (data_loss: 0.610, reg_loss: 0.000), lr: 0.0009867479746997819\n",
      "step: 171, acc: 0.875, loss: 0.546 (data_loss: 0.546, reg_loss: 0.000), lr: 0.0009867382380802023\n",
      "step: 172, acc: 0.781, loss: 0.600 (data_loss: 0.600, reg_loss: 0.000), lr: 0.0009867285016527702\n",
      "step: 173, acc: 0.844, loss: 0.592 (data_loss: 0.592, reg_loss: 0.000), lr: 0.0009867187654174808\n",
      "step: 174, acc: 0.797, loss: 0.591 (data_loss: 0.591, reg_loss: 0.000), lr: 0.0009867090293743277\n",
      "step: 175, acc: 0.867, loss: 0.566 (data_loss: 0.566, reg_loss: 0.000), lr: 0.0009866992935233059\n",
      "step: 176, acc: 0.891, loss: 0.510 (data_loss: 0.510, reg_loss: 0.000), lr: 0.0009866895578644092\n",
      "step: 177, acc: 0.836, loss: 0.599 (data_loss: 0.599, reg_loss: 0.000), lr: 0.0009866798223976318\n",
      "step: 178, acc: 0.828, loss: 0.629 (data_loss: 0.629, reg_loss: 0.000), lr: 0.0009866700871229688\n",
      "step: 179, acc: 0.859, loss: 0.602 (data_loss: 0.602, reg_loss: 0.000), lr: 0.0009866603520404136\n",
      "step: 180, acc: 0.875, loss: 0.497 (data_loss: 0.497, reg_loss: 0.000), lr: 0.000986650617149961\n",
      "step: 181, acc: 0.891, loss: 0.453 (data_loss: 0.453, reg_loss: 0.000), lr: 0.0009866408824516053\n",
      "step: 182, acc: 0.859, loss: 0.539 (data_loss: 0.539, reg_loss: 0.000), lr: 0.0009866311479453406\n",
      "step: 183, acc: 0.805, loss: 0.569 (data_loss: 0.569, reg_loss: 0.000), lr: 0.0009866214136311615\n",
      "step: 184, acc: 0.852, loss: 0.553 (data_loss: 0.553, reg_loss: 0.000), lr: 0.000986611679509062\n",
      "step: 185, acc: 0.852, loss: 0.612 (data_loss: 0.612, reg_loss: 0.000), lr: 0.0009866019455790369\n",
      "step: 186, acc: 0.828, loss: 0.594 (data_loss: 0.594, reg_loss: 0.000), lr: 0.0009865922118410797\n",
      "step: 187, acc: 0.828, loss: 0.540 (data_loss: 0.540, reg_loss: 0.000), lr: 0.0009865824782951855\n",
      "step: 188, acc: 0.898, loss: 0.470 (data_loss: 0.470, reg_loss: 0.000), lr: 0.0009865727449413484\n",
      "step: 189, acc: 0.867, loss: 0.491 (data_loss: 0.491, reg_loss: 0.000), lr: 0.0009865630117795623\n",
      "step: 190, acc: 0.805, loss: 0.597 (data_loss: 0.597, reg_loss: 0.000), lr: 0.000986553278809822\n",
      "step: 191, acc: 0.852, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.0009865435460321217\n",
      "step: 192, acc: 0.922, loss: 0.393 (data_loss: 0.393, reg_loss: 0.000), lr: 0.000986533813446456\n",
      "step: 193, acc: 0.875, loss: 0.553 (data_loss: 0.553, reg_loss: 0.000), lr: 0.0009865240810528184\n",
      "step: 194, acc: 0.844, loss: 0.630 (data_loss: 0.630, reg_loss: 0.000), lr: 0.000986514348851204\n",
      "step: 195, acc: 0.891, loss: 0.527 (data_loss: 0.527, reg_loss: 0.000), lr: 0.000986504616841607\n",
      "step: 196, acc: 0.836, loss: 0.547 (data_loss: 0.547, reg_loss: 0.000), lr: 0.0009864948850240212\n",
      "step: 197, acc: 0.891, loss: 0.516 (data_loss: 0.516, reg_loss: 0.000), lr: 0.0009864851533984414\n",
      "step: 198, acc: 0.836, loss: 0.635 (data_loss: 0.635, reg_loss: 0.000), lr: 0.0009864754219648616\n",
      "step: 199, acc: 0.883, loss: 0.474 (data_loss: 0.474, reg_loss: 0.000), lr: 0.0009864656907232767\n",
      "step: 200, acc: 0.844, loss: 0.549 (data_loss: 0.549, reg_loss: 0.000), lr: 0.0009864559596736804\n",
      "step: 201, acc: 0.805, loss: 0.655 (data_loss: 0.655, reg_loss: 0.000), lr: 0.0009864462288160672\n",
      "step: 202, acc: 0.852, loss: 0.599 (data_loss: 0.599, reg_loss: 0.000), lr: 0.0009864364981504318\n",
      "step: 203, acc: 0.852, loss: 0.593 (data_loss: 0.593, reg_loss: 0.000), lr: 0.0009864267676767677\n",
      "step: 204, acc: 0.922, loss: 0.418 (data_loss: 0.418, reg_loss: 0.000), lr: 0.0009864170373950697\n",
      "step: 205, acc: 0.859, loss: 0.465 (data_loss: 0.465, reg_loss: 0.000), lr: 0.0009864073073053328\n",
      "step: 206, acc: 0.836, loss: 0.584 (data_loss: 0.584, reg_loss: 0.000), lr: 0.00098639757740755\n",
      "step: 207, acc: 0.828, loss: 0.530 (data_loss: 0.530, reg_loss: 0.000), lr: 0.0009863878477017164\n",
      "step: 208, acc: 0.852, loss: 0.542 (data_loss: 0.542, reg_loss: 0.000), lr: 0.000986378118187826\n",
      "step: 209, acc: 0.828, loss: 0.593 (data_loss: 0.593, reg_loss: 0.000), lr: 0.0009863683888658736\n",
      "step: 210, acc: 0.852, loss: 0.547 (data_loss: 0.547, reg_loss: 0.000), lr: 0.000986358659735853\n",
      "step: 211, acc: 0.891, loss: 0.506 (data_loss: 0.506, reg_loss: 0.000), lr: 0.000986348930797759\n",
      "step: 212, acc: 0.891, loss: 0.514 (data_loss: 0.514, reg_loss: 0.000), lr: 0.0009863392020515857\n",
      "step: 213, acc: 0.867, loss: 0.538 (data_loss: 0.538, reg_loss: 0.000), lr: 0.000986329473497327\n",
      "step: 214, acc: 0.844, loss: 0.529 (data_loss: 0.529, reg_loss: 0.000), lr: 0.0009863197451349778\n",
      "step: 215, acc: 0.875, loss: 0.530 (data_loss: 0.530, reg_loss: 0.000), lr: 0.0009863100169645324\n",
      "step: 216, acc: 0.820, loss: 0.576 (data_loss: 0.576, reg_loss: 0.000), lr: 0.0009863002889859847\n",
      "step: 217, acc: 0.828, loss: 0.534 (data_loss: 0.534, reg_loss: 0.000), lr: 0.0009862905611993293\n",
      "step: 218, acc: 0.812, loss: 0.582 (data_loss: 0.582, reg_loss: 0.000), lr: 0.0009862808336045603\n",
      "step: 219, acc: 0.844, loss: 0.565 (data_loss: 0.565, reg_loss: 0.000), lr: 0.0009862711062016728\n",
      "step: 220, acc: 0.891, loss: 0.508 (data_loss: 0.508, reg_loss: 0.000), lr: 0.0009862613789906602\n",
      "step: 221, acc: 0.875, loss: 0.519 (data_loss: 0.519, reg_loss: 0.000), lr: 0.000986251651971517\n",
      "step: 222, acc: 0.797, loss: 0.611 (data_loss: 0.611, reg_loss: 0.000), lr: 0.000986241925144238\n",
      "step: 223, acc: 0.844, loss: 0.560 (data_loss: 0.560, reg_loss: 0.000), lr: 0.0009862321985088169\n",
      "step: 224, acc: 0.836, loss: 0.538 (data_loss: 0.538, reg_loss: 0.000), lr: 0.0009862224720652486\n",
      "step: 225, acc: 0.773, loss: 0.715 (data_loss: 0.715, reg_loss: 0.000), lr: 0.0009862127458135268\n",
      "step: 226, acc: 0.844, loss: 0.544 (data_loss: 0.544, reg_loss: 0.000), lr: 0.0009862030197536466\n",
      "step: 227, acc: 0.852, loss: 0.573 (data_loss: 0.573, reg_loss: 0.000), lr: 0.0009861932938856016\n",
      "step: 228, acc: 0.805, loss: 0.613 (data_loss: 0.613, reg_loss: 0.000), lr: 0.0009861835682093865\n",
      "step: 229, acc: 0.852, loss: 0.564 (data_loss: 0.564, reg_loss: 0.000), lr: 0.0009861738427249956\n",
      "step: 230, acc: 0.875, loss: 0.530 (data_loss: 0.530, reg_loss: 0.000), lr: 0.0009861641174324233\n",
      "step: 231, acc: 0.891, loss: 0.465 (data_loss: 0.465, reg_loss: 0.000), lr: 0.0009861543923316634\n",
      "step: 232, acc: 0.914, loss: 0.476 (data_loss: 0.476, reg_loss: 0.000), lr: 0.000986144667422711\n",
      "step: 233, acc: 0.867, loss: 0.614 (data_loss: 0.614, reg_loss: 0.000), lr: 0.00098613494270556\n",
      "step: 234, acc: 0.859, loss: 0.576 (data_loss: 0.576, reg_loss: 0.000), lr: 0.0009861252181802046\n",
      "step: 235, acc: 0.852, loss: 0.580 (data_loss: 0.580, reg_loss: 0.000), lr: 0.0009861154938466392\n",
      "step: 236, acc: 0.875, loss: 0.530 (data_loss: 0.530, reg_loss: 0.000), lr: 0.0009861057697048586\n",
      "step: 237, acc: 0.883, loss: 0.457 (data_loss: 0.457, reg_loss: 0.000), lr: 0.0009860960457548566\n",
      "step: 238, acc: 0.867, loss: 0.458 (data_loss: 0.458, reg_loss: 0.000), lr: 0.0009860863219966274\n",
      "step: 239, acc: 0.898, loss: 0.546 (data_loss: 0.546, reg_loss: 0.000), lr: 0.000986076598430166\n",
      "step: 240, acc: 0.867, loss: 0.474 (data_loss: 0.474, reg_loss: 0.000), lr: 0.0009860668750554663\n",
      "step: 241, acc: 0.852, loss: 0.589 (data_loss: 0.589, reg_loss: 0.000), lr: 0.0009860571518725226\n",
      "step: 242, acc: 0.922, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009860474288813292\n",
      "step: 243, acc: 0.906, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0009860377060818806\n",
      "step: 244, acc: 0.859, loss: 0.511 (data_loss: 0.511, reg_loss: 0.000), lr: 0.000986027983474171\n",
      "step: 245, acc: 0.852, loss: 0.597 (data_loss: 0.597, reg_loss: 0.000), lr: 0.0009860182610581948\n",
      "step: 246, acc: 0.875, loss: 0.476 (data_loss: 0.476, reg_loss: 0.000), lr: 0.0009860085388339465\n",
      "step: 247, acc: 0.867, loss: 0.499 (data_loss: 0.499, reg_loss: 0.000), lr: 0.00098599881680142\n",
      "step: 248, acc: 0.875, loss: 0.547 (data_loss: 0.547, reg_loss: 0.000), lr: 0.0009859890949606097\n",
      "step: 249, acc: 0.836, loss: 0.557 (data_loss: 0.557, reg_loss: 0.000), lr: 0.0009859793733115105\n",
      "step: 250, acc: 0.867, loss: 0.479 (data_loss: 0.479, reg_loss: 0.000), lr: 0.000985969651854116\n",
      "step: 251, acc: 0.898, loss: 0.468 (data_loss: 0.468, reg_loss: 0.000), lr: 0.000985959930588421\n",
      "step: 252, acc: 0.898, loss: 0.484 (data_loss: 0.484, reg_loss: 0.000), lr: 0.0009859502095144195\n",
      "step: 253, acc: 0.898, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.0009859404886321064\n",
      "step: 254, acc: 0.867, loss: 0.582 (data_loss: 0.582, reg_loss: 0.000), lr: 0.0009859307679414753\n",
      "step: 255, acc: 0.867, loss: 0.543 (data_loss: 0.543, reg_loss: 0.000), lr: 0.0009859210474425207\n",
      "step: 256, acc: 0.812, loss: 0.528 (data_loss: 0.528, reg_loss: 0.000), lr: 0.0009859113271352376\n",
      "step: 257, acc: 0.844, loss: 0.592 (data_loss: 0.592, reg_loss: 0.000), lr: 0.0009859016070196194\n",
      "step: 258, acc: 0.914, loss: 0.495 (data_loss: 0.495, reg_loss: 0.000), lr: 0.000985891887095661\n",
      "step: 259, acc: 0.859, loss: 0.493 (data_loss: 0.493, reg_loss: 0.000), lr: 0.0009858821673633567\n",
      "step: 260, acc: 0.820, loss: 0.603 (data_loss: 0.603, reg_loss: 0.000), lr: 0.0009858724478227008\n",
      "step: 261, acc: 0.906, loss: 0.466 (data_loss: 0.466, reg_loss: 0.000), lr: 0.0009858627284736873\n",
      "step: 262, acc: 0.906, loss: 0.519 (data_loss: 0.519, reg_loss: 0.000), lr: 0.0009858530093163108\n",
      "step: 263, acc: 0.844, loss: 0.534 (data_loss: 0.534, reg_loss: 0.000), lr: 0.000985843290350566\n",
      "step: 264, acc: 0.836, loss: 0.572 (data_loss: 0.572, reg_loss: 0.000), lr: 0.0009858335715764465\n",
      "step: 265, acc: 0.883, loss: 0.541 (data_loss: 0.541, reg_loss: 0.000), lr: 0.000985823852993947\n",
      "step: 266, acc: 0.852, loss: 0.639 (data_loss: 0.639, reg_loss: 0.000), lr: 0.000985814134603062\n",
      "step: 267, acc: 0.859, loss: 0.550 (data_loss: 0.550, reg_loss: 0.000), lr: 0.0009858044164037854\n",
      "step: 268, acc: 0.789, loss: 0.708 (data_loss: 0.708, reg_loss: 0.000), lr: 0.0009857946983961121\n",
      "step: 269, acc: 0.836, loss: 0.518 (data_loss: 0.518, reg_loss: 0.000), lr: 0.0009857849805800358\n",
      "step: 270, acc: 0.852, loss: 0.573 (data_loss: 0.573, reg_loss: 0.000), lr: 0.0009857752629555514\n",
      "step: 271, acc: 0.883, loss: 0.514 (data_loss: 0.514, reg_loss: 0.000), lr: 0.0009857655455226529\n",
      "step: 272, acc: 0.852, loss: 0.497 (data_loss: 0.497, reg_loss: 0.000), lr: 0.0009857558282813346\n",
      "step: 273, acc: 0.898, loss: 0.460 (data_loss: 0.460, reg_loss: 0.000), lr: 0.0009857461112315912\n",
      "step: 274, acc: 0.820, loss: 0.560 (data_loss: 0.560, reg_loss: 0.000), lr: 0.0009857363943734166\n",
      "step: 275, acc: 0.781, loss: 0.649 (data_loss: 0.649, reg_loss: 0.000), lr: 0.0009857266777068055\n",
      "step: 276, acc: 0.852, loss: 0.547 (data_loss: 0.547, reg_loss: 0.000), lr: 0.000985716961231752\n",
      "step: 277, acc: 0.844, loss: 0.542 (data_loss: 0.542, reg_loss: 0.000), lr: 0.0009857072449482504\n",
      "step: 278, acc: 0.883, loss: 0.486 (data_loss: 0.486, reg_loss: 0.000), lr: 0.0009856975288562951\n",
      "step: 279, acc: 0.836, loss: 0.583 (data_loss: 0.583, reg_loss: 0.000), lr: 0.0009856878129558804\n",
      "step: 280, acc: 0.875, loss: 0.535 (data_loss: 0.535, reg_loss: 0.000), lr: 0.0009856780972470013\n",
      "step: 281, acc: 0.883, loss: 0.556 (data_loss: 0.556, reg_loss: 0.000), lr: 0.0009856683817296508\n",
      "step: 282, acc: 0.867, loss: 0.533 (data_loss: 0.533, reg_loss: 0.000), lr: 0.0009856586664038242\n",
      "step: 283, acc: 0.828, loss: 0.589 (data_loss: 0.589, reg_loss: 0.000), lr: 0.0009856489512695158\n",
      "step: 284, acc: 0.859, loss: 0.489 (data_loss: 0.489, reg_loss: 0.000), lr: 0.0009856392363267197\n",
      "step: 285, acc: 0.930, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0009856295215754302\n",
      "step: 286, acc: 0.883, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009856198070156417\n",
      "step: 287, acc: 0.836, loss: 0.634 (data_loss: 0.634, reg_loss: 0.000), lr: 0.0009856100926473488\n",
      "step: 288, acc: 0.891, loss: 0.505 (data_loss: 0.505, reg_loss: 0.000), lr: 0.0009856003784705454\n",
      "step: 289, acc: 0.883, loss: 0.479 (data_loss: 0.479, reg_loss: 0.000), lr: 0.000985590664485226\n",
      "step: 290, acc: 0.875, loss: 0.470 (data_loss: 0.470, reg_loss: 0.000), lr: 0.000985580950691385\n",
      "step: 291, acc: 0.820, loss: 0.571 (data_loss: 0.571, reg_loss: 0.000), lr: 0.0009855712370890168\n",
      "step: 292, acc: 0.828, loss: 0.531 (data_loss: 0.531, reg_loss: 0.000), lr: 0.0009855615236781157\n",
      "step: 293, acc: 0.867, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.000985551810458676\n",
      "step: 294, acc: 0.828, loss: 0.581 (data_loss: 0.581, reg_loss: 0.000), lr: 0.0009855420974306918\n",
      "step: 295, acc: 0.898, loss: 0.568 (data_loss: 0.568, reg_loss: 0.000), lr: 0.0009855323845941576\n",
      "step: 296, acc: 0.867, loss: 0.485 (data_loss: 0.485, reg_loss: 0.000), lr: 0.0009855226719490682\n",
      "step: 297, acc: 0.859, loss: 0.570 (data_loss: 0.570, reg_loss: 0.000), lr: 0.0009855129594954174\n",
      "step: 298, acc: 0.875, loss: 0.501 (data_loss: 0.501, reg_loss: 0.000), lr: 0.0009855032472331996\n",
      "step: 299, acc: 0.930, loss: 0.450 (data_loss: 0.450, reg_loss: 0.000), lr: 0.0009854935351624092\n",
      "step: 300, acc: 0.883, loss: 0.496 (data_loss: 0.496, reg_loss: 0.000), lr: 0.0009854838232830408\n",
      "step: 301, acc: 0.852, loss: 0.519 (data_loss: 0.519, reg_loss: 0.000), lr: 0.0009854741115950885\n",
      "step: 302, acc: 0.875, loss: 0.549 (data_loss: 0.549, reg_loss: 0.000), lr: 0.0009854644000985464\n",
      "step: 303, acc: 0.852, loss: 0.504 (data_loss: 0.504, reg_loss: 0.000), lr: 0.0009854546887934092\n",
      "step: 304, acc: 0.875, loss: 0.523 (data_loss: 0.523, reg_loss: 0.000), lr: 0.0009854449776796714\n",
      "step: 305, acc: 0.852, loss: 0.511 (data_loss: 0.511, reg_loss: 0.000), lr: 0.0009854352667573267\n",
      "step: 306, acc: 0.883, loss: 0.502 (data_loss: 0.502, reg_loss: 0.000), lr: 0.00098542555602637\n",
      "step: 307, acc: 0.898, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.0009854158454867955\n",
      "step: 308, acc: 0.836, loss: 0.533 (data_loss: 0.533, reg_loss: 0.000), lr: 0.0009854061351385974\n",
      "step: 309, acc: 0.859, loss: 0.561 (data_loss: 0.561, reg_loss: 0.000), lr: 0.0009853964249817702\n",
      "step: 310, acc: 0.891, loss: 0.453 (data_loss: 0.453, reg_loss: 0.000), lr: 0.0009853867150163083\n",
      "step: 311, acc: 0.852, loss: 0.537 (data_loss: 0.537, reg_loss: 0.000), lr: 0.0009853770052422057\n",
      "step: 312, acc: 0.820, loss: 0.551 (data_loss: 0.551, reg_loss: 0.000), lr: 0.000985367295659457\n",
      "step: 313, acc: 0.859, loss: 0.513 (data_loss: 0.513, reg_loss: 0.000), lr: 0.0009853575862680565\n",
      "step: 314, acc: 0.906, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0009853478770679989\n",
      "step: 315, acc: 0.883, loss: 0.536 (data_loss: 0.536, reg_loss: 0.000), lr: 0.000985338168059278\n",
      "step: 316, acc: 0.906, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.0009853284592418882\n",
      "step: 317, acc: 0.859, loss: 0.445 (data_loss: 0.445, reg_loss: 0.000), lr: 0.0009853187506158243\n",
      "step: 318, acc: 0.852, loss: 0.538 (data_loss: 0.538, reg_loss: 0.000), lr: 0.00098530904218108\n",
      "step: 319, acc: 0.898, loss: 0.443 (data_loss: 0.443, reg_loss: 0.000), lr: 0.0009852993339376503\n",
      "step: 320, acc: 0.852, loss: 0.560 (data_loss: 0.560, reg_loss: 0.000), lr: 0.000985289625885529\n",
      "step: 321, acc: 0.836, loss: 0.567 (data_loss: 0.567, reg_loss: 0.000), lr: 0.0009852799180247109\n",
      "step: 322, acc: 0.867, loss: 0.505 (data_loss: 0.505, reg_loss: 0.000), lr: 0.00098527021035519\n",
      "step: 323, acc: 0.891, loss: 0.484 (data_loss: 0.484, reg_loss: 0.000), lr: 0.0009852605028769605\n",
      "step: 324, acc: 0.867, loss: 0.558 (data_loss: 0.558, reg_loss: 0.000), lr: 0.0009852507955900175\n",
      "step: 325, acc: 0.883, loss: 0.563 (data_loss: 0.563, reg_loss: 0.000), lr: 0.0009852410884943546\n",
      "step: 326, acc: 0.852, loss: 0.496 (data_loss: 0.496, reg_loss: 0.000), lr: 0.0009852313815899665\n",
      "step: 327, acc: 0.883, loss: 0.534 (data_loss: 0.534, reg_loss: 0.000), lr: 0.0009852216748768474\n",
      "step: 328, acc: 0.852, loss: 0.537 (data_loss: 0.537, reg_loss: 0.000), lr: 0.0009852119683549916\n",
      "step: 329, acc: 0.898, loss: 0.445 (data_loss: 0.445, reg_loss: 0.000), lr: 0.0009852022620243936\n",
      "step: 330, acc: 0.875, loss: 0.487 (data_loss: 0.487, reg_loss: 0.000), lr: 0.0009851925558850476\n",
      "step: 331, acc: 0.836, loss: 0.547 (data_loss: 0.547, reg_loss: 0.000), lr: 0.0009851828499369483\n",
      "step: 332, acc: 0.875, loss: 0.544 (data_loss: 0.544, reg_loss: 0.000), lr: 0.0009851731441800897\n",
      "step: 333, acc: 0.875, loss: 0.536 (data_loss: 0.536, reg_loss: 0.000), lr: 0.0009851634386144662\n",
      "step: 334, acc: 0.852, loss: 0.610 (data_loss: 0.610, reg_loss: 0.000), lr: 0.0009851537332400723\n",
      "step: 335, acc: 0.875, loss: 0.455 (data_loss: 0.455, reg_loss: 0.000), lr: 0.000985144028056902\n",
      "step: 336, acc: 0.891, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.00098513432306495\n",
      "step: 337, acc: 0.844, loss: 0.500 (data_loss: 0.500, reg_loss: 0.000), lr: 0.0009851246182642104\n",
      "step: 338, acc: 0.922, loss: 0.375 (data_loss: 0.375, reg_loss: 0.000), lr: 0.0009851149136546778\n",
      "step: 339, acc: 0.828, loss: 0.539 (data_loss: 0.539, reg_loss: 0.000), lr: 0.0009851052092363464\n",
      "step: 340, acc: 0.922, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009850955050092105\n",
      "step: 341, acc: 0.812, loss: 0.580 (data_loss: 0.580, reg_loss: 0.000), lr: 0.0009850858009732648\n",
      "step: 342, acc: 0.797, loss: 0.553 (data_loss: 0.553, reg_loss: 0.000), lr: 0.0009850760971285033\n",
      "step: 343, acc: 0.867, loss: 0.533 (data_loss: 0.533, reg_loss: 0.000), lr: 0.0009850663934749201\n",
      "step: 344, acc: 0.875, loss: 0.517 (data_loss: 0.517, reg_loss: 0.000), lr: 0.0009850566900125102\n",
      "step: 345, acc: 0.883, loss: 0.492 (data_loss: 0.492, reg_loss: 0.000), lr: 0.0009850469867412675\n",
      "step: 346, acc: 0.812, loss: 0.551 (data_loss: 0.551, reg_loss: 0.000), lr: 0.0009850372836611866\n",
      "step: 347, acc: 0.898, loss: 0.420 (data_loss: 0.420, reg_loss: 0.000), lr: 0.0009850275807722615\n",
      "step: 348, acc: 0.820, loss: 0.553 (data_loss: 0.553, reg_loss: 0.000), lr: 0.0009850178780744872\n",
      "step: 349, acc: 0.812, loss: 0.545 (data_loss: 0.545, reg_loss: 0.000), lr: 0.0009850081755678572\n",
      "step: 350, acc: 0.836, loss: 0.552 (data_loss: 0.552, reg_loss: 0.000), lr: 0.0009849984732523663\n",
      "step: 351, acc: 0.898, loss: 0.453 (data_loss: 0.453, reg_loss: 0.000), lr: 0.0009849887711280091\n",
      "step: 352, acc: 0.852, loss: 0.506 (data_loss: 0.506, reg_loss: 0.000), lr: 0.0009849790691947797\n",
      "step: 353, acc: 0.828, loss: 0.585 (data_loss: 0.585, reg_loss: 0.000), lr: 0.0009849693674526723\n",
      "step: 354, acc: 0.867, loss: 0.583 (data_loss: 0.583, reg_loss: 0.000), lr: 0.0009849596659016813\n",
      "step: 355, acc: 0.906, loss: 0.455 (data_loss: 0.455, reg_loss: 0.000), lr: 0.0009849499645418014\n",
      "step: 356, acc: 0.844, loss: 0.594 (data_loss: 0.594, reg_loss: 0.000), lr: 0.0009849402633730264\n",
      "step: 357, acc: 0.867, loss: 0.429 (data_loss: 0.429, reg_loss: 0.000), lr: 0.000984930562395351\n",
      "step: 358, acc: 0.883, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.0009849208616087698\n",
      "step: 359, acc: 0.883, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0009849111610132767\n",
      "step: 360, acc: 0.820, loss: 0.542 (data_loss: 0.542, reg_loss: 0.000), lr: 0.000984901460608866\n",
      "step: 361, acc: 0.906, loss: 0.487 (data_loss: 0.487, reg_loss: 0.000), lr: 0.0009848917603955327\n",
      "step: 362, acc: 0.875, loss: 0.427 (data_loss: 0.427, reg_loss: 0.000), lr: 0.0009848820603732703\n",
      "step: 363, acc: 0.820, loss: 0.573 (data_loss: 0.573, reg_loss: 0.000), lr: 0.0009848723605420738\n",
      "step: 364, acc: 0.852, loss: 0.534 (data_loss: 0.534, reg_loss: 0.000), lr: 0.000984862660901937\n",
      "step: 365, acc: 0.852, loss: 0.504 (data_loss: 0.504, reg_loss: 0.000), lr: 0.000984852961452855\n",
      "step: 366, acc: 0.820, loss: 0.547 (data_loss: 0.547, reg_loss: 0.000), lr: 0.0009848432621948216\n",
      "step: 367, acc: 0.898, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.0009848335631278313\n",
      "step: 368, acc: 0.875, loss: 0.497 (data_loss: 0.497, reg_loss: 0.000), lr: 0.0009848238642518787\n",
      "step: 369, acc: 0.867, loss: 0.514 (data_loss: 0.514, reg_loss: 0.000), lr: 0.0009848141655669576\n",
      "step: 370, acc: 0.812, loss: 0.525 (data_loss: 0.525, reg_loss: 0.000), lr: 0.0009848044670730627\n",
      "step: 371, acc: 0.898, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.0009847947687701883\n",
      "step: 372, acc: 0.883, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.000984785070658329\n",
      "step: 373, acc: 0.906, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0009847753727374785\n",
      "step: 374, acc: 0.875, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.000984765675007632\n",
      "step: 375, acc: 0.875, loss: 0.504 (data_loss: 0.504, reg_loss: 0.000), lr: 0.0009847559774687834\n",
      "step: 376, acc: 0.859, loss: 0.501 (data_loss: 0.501, reg_loss: 0.000), lr: 0.0009847462801209268\n",
      "step: 377, acc: 0.914, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009847365829640572\n",
      "step: 378, acc: 0.836, loss: 0.491 (data_loss: 0.491, reg_loss: 0.000), lr: 0.0009847268859981685\n",
      "step: 379, acc: 0.852, loss: 0.522 (data_loss: 0.522, reg_loss: 0.000), lr: 0.000984717189223255\n",
      "step: 380, acc: 0.875, loss: 0.530 (data_loss: 0.530, reg_loss: 0.000), lr: 0.0009847074926393115\n",
      "step: 381, acc: 0.883, loss: 0.477 (data_loss: 0.477, reg_loss: 0.000), lr: 0.000984697796246332\n",
      "step: 382, acc: 0.906, loss: 0.455 (data_loss: 0.455, reg_loss: 0.000), lr: 0.000984688100044311\n",
      "step: 383, acc: 0.859, loss: 0.508 (data_loss: 0.508, reg_loss: 0.000), lr: 0.0009846784040332427\n",
      "step: 384, acc: 0.812, loss: 0.560 (data_loss: 0.560, reg_loss: 0.000), lr: 0.0009846687082131216\n",
      "step: 385, acc: 0.891, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009846590125839423\n",
      "step: 386, acc: 0.836, loss: 0.537 (data_loss: 0.537, reg_loss: 0.000), lr: 0.0009846493171456986\n",
      "step: 387, acc: 0.922, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009846396218983853\n",
      "step: 388, acc: 0.875, loss: 0.452 (data_loss: 0.452, reg_loss: 0.000), lr: 0.0009846299268419967\n",
      "step: 389, acc: 0.875, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.0009846202319765268\n",
      "step: 390, acc: 0.887, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009846105373019702\n",
      "training, acc: 0.857, loss: 0.544 (data_loss: 0.544, reg_loss: 0.000), lr: 0.0009846105373019702\n",
      "validation, acc: 0.871, loss: 0.486\n",
      "epoch: 5\n",
      "step: 0, acc: 0.859, loss: 0.595 (data_loss: 0.595, reg_loss: 0.000), lr: 0.0009846008428183214\n",
      "step: 1, acc: 0.828, loss: 0.598 (data_loss: 0.598, reg_loss: 0.000), lr: 0.0009845911485255748\n",
      "step: 2, acc: 0.875, loss: 0.500 (data_loss: 0.500, reg_loss: 0.000), lr: 0.0009845814544237246\n",
      "step: 3, acc: 0.883, loss: 0.436 (data_loss: 0.436, reg_loss: 0.000), lr: 0.0009845717605127648\n",
      "step: 4, acc: 0.898, loss: 0.466 (data_loss: 0.466, reg_loss: 0.000), lr: 0.0009845620667926908\n",
      "step: 5, acc: 0.875, loss: 0.539 (data_loss: 0.539, reg_loss: 0.000), lr: 0.0009845523732634957\n",
      "step: 6, acc: 0.883, loss: 0.518 (data_loss: 0.518, reg_loss: 0.000), lr: 0.0009845426799251747\n",
      "step: 7, acc: 0.914, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.000984532986777722\n",
      "step: 8, acc: 0.875, loss: 0.529 (data_loss: 0.529, reg_loss: 0.000), lr: 0.0009845232938211319\n",
      "step: 9, acc: 0.906, loss: 0.465 (data_loss: 0.465, reg_loss: 0.000), lr: 0.0009845136010553986\n",
      "step: 10, acc: 0.906, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009845039084805166\n",
      "step: 11, acc: 0.844, loss: 0.493 (data_loss: 0.493, reg_loss: 0.000), lr: 0.0009844942160964806\n",
      "step: 12, acc: 0.875, loss: 0.460 (data_loss: 0.460, reg_loss: 0.000), lr: 0.0009844845239032844\n",
      "step: 13, acc: 0.859, loss: 0.562 (data_loss: 0.562, reg_loss: 0.000), lr: 0.0009844748319009224\n",
      "step: 14, acc: 0.883, loss: 0.488 (data_loss: 0.488, reg_loss: 0.000), lr: 0.0009844651400893896\n",
      "step: 15, acc: 0.867, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0009844554484686797\n",
      "step: 16, acc: 0.883, loss: 0.504 (data_loss: 0.504, reg_loss: 0.000), lr: 0.0009844457570387872\n",
      "step: 17, acc: 0.859, loss: 0.457 (data_loss: 0.457, reg_loss: 0.000), lr: 0.0009844360657997066\n",
      "step: 18, acc: 0.898, loss: 0.495 (data_loss: 0.495, reg_loss: 0.000), lr: 0.0009844263747514324\n",
      "step: 19, acc: 0.836, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.0009844166838939587\n",
      "step: 20, acc: 0.836, loss: 0.503 (data_loss: 0.503, reg_loss: 0.000), lr: 0.0009844069932272797\n",
      "step: 21, acc: 0.820, loss: 0.565 (data_loss: 0.565, reg_loss: 0.000), lr: 0.0009843973027513907\n",
      "step: 22, acc: 0.906, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009843876124662847\n",
      "step: 23, acc: 0.852, loss: 0.531 (data_loss: 0.531, reg_loss: 0.000), lr: 0.000984377922371957\n",
      "step: 24, acc: 0.883, loss: 0.449 (data_loss: 0.449, reg_loss: 0.000), lr: 0.000984368232468402\n",
      "step: 25, acc: 0.906, loss: 0.414 (data_loss: 0.414, reg_loss: 0.000), lr: 0.0009843585427556133\n",
      "step: 26, acc: 0.891, loss: 0.516 (data_loss: 0.516, reg_loss: 0.000), lr: 0.0009843488532335861\n",
      "step: 27, acc: 0.883, loss: 0.449 (data_loss: 0.449, reg_loss: 0.000), lr: 0.0009843391639023141\n",
      "step: 28, acc: 0.898, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.0009843294747617923\n",
      "step: 29, acc: 0.883, loss: 0.490 (data_loss: 0.490, reg_loss: 0.000), lr: 0.0009843197858120146\n",
      "step: 30, acc: 0.875, loss: 0.475 (data_loss: 0.475, reg_loss: 0.000), lr: 0.0009843100970529754\n",
      "step: 31, acc: 0.891, loss: 0.516 (data_loss: 0.516, reg_loss: 0.000), lr: 0.0009843004084846697\n",
      "step: 32, acc: 0.891, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0009842907201070908\n",
      "step: 33, acc: 0.852, loss: 0.493 (data_loss: 0.493, reg_loss: 0.000), lr: 0.0009842810319202339\n",
      "step: 34, acc: 0.875, loss: 0.478 (data_loss: 0.478, reg_loss: 0.000), lr: 0.0009842713439240929\n",
      "step: 35, acc: 0.859, loss: 0.498 (data_loss: 0.498, reg_loss: 0.000), lr: 0.0009842616561186626\n",
      "step: 36, acc: 0.898, loss: 0.450 (data_loss: 0.450, reg_loss: 0.000), lr: 0.000984251968503937\n",
      "step: 37, acc: 0.859, loss: 0.458 (data_loss: 0.458, reg_loss: 0.000), lr: 0.0009842422810799106\n",
      "step: 38, acc: 0.852, loss: 0.499 (data_loss: 0.499, reg_loss: 0.000), lr: 0.0009842325938465778\n",
      "step: 39, acc: 0.859, loss: 0.579 (data_loss: 0.579, reg_loss: 0.000), lr: 0.000984222906803933\n",
      "step: 40, acc: 0.891, loss: 0.442 (data_loss: 0.442, reg_loss: 0.000), lr: 0.0009842132199519703\n",
      "step: 41, acc: 0.891, loss: 0.447 (data_loss: 0.447, reg_loss: 0.000), lr: 0.0009842035332906847\n",
      "step: 42, acc: 0.836, loss: 0.527 (data_loss: 0.527, reg_loss: 0.000), lr: 0.0009841938468200698\n",
      "step: 43, acc: 0.852, loss: 0.460 (data_loss: 0.460, reg_loss: 0.000), lr: 0.0009841841605401202\n",
      "step: 44, acc: 0.875, loss: 0.530 (data_loss: 0.530, reg_loss: 0.000), lr: 0.0009841744744508306\n",
      "step: 45, acc: 0.883, loss: 0.503 (data_loss: 0.503, reg_loss: 0.000), lr: 0.0009841647885521954\n",
      "step: 46, acc: 0.867, loss: 0.509 (data_loss: 0.509, reg_loss: 0.000), lr: 0.0009841551028442082\n",
      "step: 47, acc: 0.844, loss: 0.528 (data_loss: 0.528, reg_loss: 0.000), lr: 0.0009841454173268641\n",
      "step: 48, acc: 0.875, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009841357320001577\n",
      "step: 49, acc: 0.875, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009841260468640824\n",
      "step: 50, acc: 0.906, loss: 0.484 (data_loss: 0.484, reg_loss: 0.000), lr: 0.0009841163619186332\n",
      "step: 51, acc: 0.883, loss: 0.451 (data_loss: 0.451, reg_loss: 0.000), lr: 0.0009841066771638044\n",
      "step: 52, acc: 0.867, loss: 0.524 (data_loss: 0.524, reg_loss: 0.000), lr: 0.0009840969925995907\n",
      "step: 53, acc: 0.789, loss: 0.622 (data_loss: 0.622, reg_loss: 0.000), lr: 0.0009840873082259858\n",
      "step: 54, acc: 0.867, loss: 0.440 (data_loss: 0.440, reg_loss: 0.000), lr: 0.0009840776240429845\n",
      "step: 55, acc: 0.867, loss: 0.576 (data_loss: 0.576, reg_loss: 0.000), lr: 0.0009840679400505811\n",
      "step: 56, acc: 0.875, loss: 0.490 (data_loss: 0.490, reg_loss: 0.000), lr: 0.00098405825624877\n",
      "step: 57, acc: 0.898, loss: 0.412 (data_loss: 0.412, reg_loss: 0.000), lr: 0.0009840485726375454\n",
      "step: 58, acc: 0.875, loss: 0.474 (data_loss: 0.474, reg_loss: 0.000), lr: 0.000984038889216902\n",
      "step: 59, acc: 0.852, loss: 0.489 (data_loss: 0.489, reg_loss: 0.000), lr: 0.0009840292059868337\n",
      "step: 60, acc: 0.883, loss: 0.512 (data_loss: 0.512, reg_loss: 0.000), lr: 0.0009840195229473352\n",
      "step: 61, acc: 0.883, loss: 0.458 (data_loss: 0.458, reg_loss: 0.000), lr: 0.0009840098400984009\n",
      "step: 62, acc: 0.883, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009840001574400253\n",
      "step: 63, acc: 0.852, loss: 0.528 (data_loss: 0.528, reg_loss: 0.000), lr: 0.0009839904749722023\n",
      "step: 64, acc: 0.844, loss: 0.557 (data_loss: 0.557, reg_loss: 0.000), lr: 0.0009839807926949266\n",
      "step: 65, acc: 0.812, loss: 0.627 (data_loss: 0.627, reg_loss: 0.000), lr: 0.0009839711106081927\n",
      "step: 66, acc: 0.898, loss: 0.467 (data_loss: 0.467, reg_loss: 0.000), lr: 0.0009839614287119945\n",
      "step: 67, acc: 0.836, loss: 0.571 (data_loss: 0.571, reg_loss: 0.000), lr: 0.0009839517470063269\n",
      "step: 68, acc: 0.859, loss: 0.511 (data_loss: 0.511, reg_loss: 0.000), lr: 0.0009839420654911841\n",
      "step: 69, acc: 0.852, loss: 0.496 (data_loss: 0.496, reg_loss: 0.000), lr: 0.0009839323841665602\n",
      "step: 70, acc: 0.891, loss: 0.411 (data_loss: 0.411, reg_loss: 0.000), lr: 0.0009839227030324499\n",
      "step: 71, acc: 0.898, loss: 0.430 (data_loss: 0.430, reg_loss: 0.000), lr: 0.0009839130220888473\n",
      "step: 72, acc: 0.891, loss: 0.445 (data_loss: 0.445, reg_loss: 0.000), lr: 0.0009839033413357472\n",
      "step: 73, acc: 0.953, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009838936607731437\n",
      "step: 74, acc: 0.875, loss: 0.547 (data_loss: 0.547, reg_loss: 0.000), lr: 0.000983883980401031\n",
      "step: 75, acc: 0.859, loss: 0.526 (data_loss: 0.526, reg_loss: 0.000), lr: 0.000983874300219404\n",
      "step: 76, acc: 0.906, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0009838646202282567\n",
      "step: 77, acc: 0.922, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009838549404275834\n",
      "step: 78, acc: 0.867, loss: 0.530 (data_loss: 0.530, reg_loss: 0.000), lr: 0.0009838452608173787\n",
      "step: 79, acc: 0.859, loss: 0.520 (data_loss: 0.520, reg_loss: 0.000), lr: 0.0009838355813976368\n",
      "step: 80, acc: 0.852, loss: 0.536 (data_loss: 0.536, reg_loss: 0.000), lr: 0.0009838259021683524\n",
      "step: 81, acc: 0.836, loss: 0.499 (data_loss: 0.499, reg_loss: 0.000), lr: 0.0009838162231295194\n",
      "step: 82, acc: 0.914, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009838065442811328\n",
      "step: 83, acc: 0.812, loss: 0.554 (data_loss: 0.554, reg_loss: 0.000), lr: 0.000983796865623186\n",
      "step: 84, acc: 0.844, loss: 0.583 (data_loss: 0.583, reg_loss: 0.000), lr: 0.0009837871871556745\n",
      "step: 85, acc: 0.852, loss: 0.515 (data_loss: 0.515, reg_loss: 0.000), lr: 0.0009837775088785922\n",
      "step: 86, acc: 0.844, loss: 0.582 (data_loss: 0.582, reg_loss: 0.000), lr: 0.0009837678307919333\n",
      "step: 87, acc: 0.891, loss: 0.494 (data_loss: 0.494, reg_loss: 0.000), lr: 0.0009837581528956921\n",
      "step: 88, acc: 0.828, loss: 0.651 (data_loss: 0.651, reg_loss: 0.000), lr: 0.0009837484751898634\n",
      "step: 89, acc: 0.891, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0009837387976744415\n",
      "step: 90, acc: 0.867, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009837291203494206\n",
      "step: 91, acc: 0.883, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.000983719443214795\n",
      "step: 92, acc: 0.883, loss: 0.448 (data_loss: 0.448, reg_loss: 0.000), lr: 0.0009837097662705597\n",
      "step: 93, acc: 0.859, loss: 0.500 (data_loss: 0.500, reg_loss: 0.000), lr: 0.0009837000895167082\n",
      "step: 94, acc: 0.898, loss: 0.466 (data_loss: 0.466, reg_loss: 0.000), lr: 0.0009836904129532354\n",
      "step: 95, acc: 0.844, loss: 0.631 (data_loss: 0.631, reg_loss: 0.000), lr: 0.0009836807365801354\n",
      "step: 96, acc: 0.867, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0009836710603974032\n",
      "step: 97, acc: 0.859, loss: 0.427 (data_loss: 0.427, reg_loss: 0.000), lr: 0.0009836613844050324\n",
      "step: 98, acc: 0.805, loss: 0.560 (data_loss: 0.560, reg_loss: 0.000), lr: 0.0009836517086030177\n",
      "step: 99, acc: 0.891, loss: 0.449 (data_loss: 0.449, reg_loss: 0.000), lr: 0.0009836420329913539\n",
      "step: 100, acc: 0.883, loss: 0.459 (data_loss: 0.459, reg_loss: 0.000), lr: 0.0009836323575700347\n",
      "step: 101, acc: 0.883, loss: 0.533 (data_loss: 0.533, reg_loss: 0.000), lr: 0.0009836226823390548\n",
      "step: 102, acc: 0.883, loss: 0.447 (data_loss: 0.447, reg_loss: 0.000), lr: 0.0009836130072984086\n",
      "step: 103, acc: 0.867, loss: 0.599 (data_loss: 0.599, reg_loss: 0.000), lr: 0.0009836033324480903\n",
      "step: 104, acc: 0.852, loss: 0.500 (data_loss: 0.500, reg_loss: 0.000), lr: 0.0009835936577880947\n",
      "step: 105, acc: 0.875, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009835839833184155\n",
      "step: 106, acc: 0.891, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.000983574309039048\n",
      "step: 107, acc: 0.828, loss: 0.612 (data_loss: 0.612, reg_loss: 0.000), lr: 0.0009835646349499857\n",
      "step: 108, acc: 0.883, loss: 0.450 (data_loss: 0.450, reg_loss: 0.000), lr: 0.0009835549610512236\n",
      "step: 109, acc: 0.906, loss: 0.423 (data_loss: 0.423, reg_loss: 0.000), lr: 0.0009835452873427559\n",
      "step: 110, acc: 0.961, loss: 0.354 (data_loss: 0.354, reg_loss: 0.000), lr: 0.0009835356138245767\n",
      "step: 111, acc: 0.852, loss: 0.501 (data_loss: 0.501, reg_loss: 0.000), lr: 0.0009835259404966806\n",
      "step: 112, acc: 0.875, loss: 0.508 (data_loss: 0.508, reg_loss: 0.000), lr: 0.000983516267359062\n",
      "step: 113, acc: 0.883, loss: 0.442 (data_loss: 0.442, reg_loss: 0.000), lr: 0.0009835065944117157\n",
      "step: 114, acc: 0.859, loss: 0.476 (data_loss: 0.476, reg_loss: 0.000), lr: 0.0009834969216546351\n",
      "step: 115, acc: 0.875, loss: 0.416 (data_loss: 0.416, reg_loss: 0.000), lr: 0.0009834872490878156\n",
      "step: 116, acc: 0.820, loss: 0.567 (data_loss: 0.567, reg_loss: 0.000), lr: 0.000983477576711251\n",
      "step: 117, acc: 0.883, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009834679045249359\n",
      "step: 118, acc: 0.867, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009834582325288644\n",
      "step: 119, acc: 0.898, loss: 0.475 (data_loss: 0.475, reg_loss: 0.000), lr: 0.0009834485607230314\n",
      "step: 120, acc: 0.906, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.000983438889107431\n",
      "step: 121, acc: 0.875, loss: 0.483 (data_loss: 0.483, reg_loss: 0.000), lr: 0.0009834292176820573\n",
      "step: 122, acc: 0.875, loss: 0.540 (data_loss: 0.540, reg_loss: 0.000), lr: 0.0009834195464469052\n",
      "step: 123, acc: 0.836, loss: 0.589 (data_loss: 0.589, reg_loss: 0.000), lr: 0.000983409875401969\n",
      "step: 124, acc: 0.844, loss: 0.513 (data_loss: 0.513, reg_loss: 0.000), lr: 0.0009834002045472426\n",
      "step: 125, acc: 0.859, loss: 0.465 (data_loss: 0.465, reg_loss: 0.000), lr: 0.0009833905338827208\n",
      "step: 126, acc: 0.891, loss: 0.465 (data_loss: 0.465, reg_loss: 0.000), lr: 0.0009833808634083982\n",
      "step: 127, acc: 0.898, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009833711931242688\n",
      "step: 128, acc: 0.836, loss: 0.549 (data_loss: 0.549, reg_loss: 0.000), lr: 0.0009833615230303268\n",
      "step: 129, acc: 0.891, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000), lr: 0.0009833518531265674\n",
      "step: 130, acc: 0.812, loss: 0.604 (data_loss: 0.604, reg_loss: 0.000), lr: 0.0009833421834129841\n",
      "step: 131, acc: 0.812, loss: 0.609 (data_loss: 0.609, reg_loss: 0.000), lr: 0.0009833325138895717\n",
      "step: 132, acc: 0.859, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.0009833228445563246\n",
      "step: 133, acc: 0.875, loss: 0.443 (data_loss: 0.443, reg_loss: 0.000), lr: 0.0009833131754132375\n",
      "step: 134, acc: 0.914, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.000983303506460304\n",
      "step: 135, acc: 0.883, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.000983293837697519\n",
      "step: 136, acc: 0.852, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.0009832841691248771\n",
      "step: 137, acc: 0.930, loss: 0.350 (data_loss: 0.350, reg_loss: 0.000), lr: 0.0009832745007423724\n",
      "step: 138, acc: 0.859, loss: 0.476 (data_loss: 0.476, reg_loss: 0.000), lr: 0.000983264832549999\n",
      "step: 139, acc: 0.867, loss: 0.502 (data_loss: 0.502, reg_loss: 0.000), lr: 0.0009832551645477517\n",
      "step: 140, acc: 0.891, loss: 0.466 (data_loss: 0.466, reg_loss: 0.000), lr: 0.000983245496735625\n",
      "step: 141, acc: 0.875, loss: 0.511 (data_loss: 0.511, reg_loss: 0.000), lr: 0.0009832358291136129\n",
      "step: 142, acc: 0.953, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.00098322616168171\n",
      "step: 143, acc: 0.906, loss: 0.422 (data_loss: 0.422, reg_loss: 0.000), lr: 0.0009832164944399108\n",
      "step: 144, acc: 0.859, loss: 0.519 (data_loss: 0.519, reg_loss: 0.000), lr: 0.0009832068273882095\n",
      "step: 145, acc: 0.844, loss: 0.442 (data_loss: 0.442, reg_loss: 0.000), lr: 0.0009831971605266004\n",
      "step: 146, acc: 0.891, loss: 0.591 (data_loss: 0.591, reg_loss: 0.000), lr: 0.0009831874938550783\n",
      "step: 147, acc: 0.812, loss: 0.578 (data_loss: 0.578, reg_loss: 0.000), lr: 0.000983177827373637\n",
      "step: 148, acc: 0.859, loss: 0.532 (data_loss: 0.532, reg_loss: 0.000), lr: 0.0009831681610822714\n",
      "step: 149, acc: 0.898, loss: 0.393 (data_loss: 0.393, reg_loss: 0.000), lr: 0.000983158494980976\n",
      "step: 150, acc: 0.875, loss: 0.423 (data_loss: 0.423, reg_loss: 0.000), lr: 0.0009831488290697446\n",
      "step: 151, acc: 0.906, loss: 0.427 (data_loss: 0.427, reg_loss: 0.000), lr: 0.000983139163348572\n",
      "step: 152, acc: 0.883, loss: 0.481 (data_loss: 0.481, reg_loss: 0.000), lr: 0.0009831294978174525\n",
      "step: 153, acc: 0.844, loss: 0.545 (data_loss: 0.545, reg_loss: 0.000), lr: 0.0009831198324763808\n",
      "step: 154, acc: 0.883, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.0009831101673253506\n",
      "step: 155, acc: 0.906, loss: 0.409 (data_loss: 0.409, reg_loss: 0.000), lr: 0.0009831005023643567\n",
      "step: 156, acc: 0.859, loss: 0.430 (data_loss: 0.430, reg_loss: 0.000), lr: 0.0009830908375933936\n",
      "step: 157, acc: 0.859, loss: 0.494 (data_loss: 0.494, reg_loss: 0.000), lr: 0.0009830811730124557\n",
      "step: 158, acc: 0.867, loss: 0.566 (data_loss: 0.566, reg_loss: 0.000), lr: 0.000983071508621537\n",
      "step: 159, acc: 0.875, loss: 0.466 (data_loss: 0.466, reg_loss: 0.000), lr: 0.0009830618444206323\n",
      "step: 160, acc: 0.875, loss: 0.423 (data_loss: 0.423, reg_loss: 0.000), lr: 0.0009830521804097363\n",
      "step: 161, acc: 0.844, loss: 0.522 (data_loss: 0.522, reg_loss: 0.000), lr: 0.0009830425165888424\n",
      "step: 162, acc: 0.875, loss: 0.497 (data_loss: 0.497, reg_loss: 0.000), lr: 0.0009830328529579458\n",
      "step: 163, acc: 0.859, loss: 0.492 (data_loss: 0.492, reg_loss: 0.000), lr: 0.000983023189517041\n",
      "step: 164, acc: 0.906, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009830135262661214\n",
      "step: 165, acc: 0.859, loss: 0.408 (data_loss: 0.408, reg_loss: 0.000), lr: 0.0009830038632051823\n",
      "step: 166, acc: 0.812, loss: 0.551 (data_loss: 0.551, reg_loss: 0.000), lr: 0.000982994200334218\n",
      "step: 167, acc: 0.805, loss: 0.522 (data_loss: 0.522, reg_loss: 0.000), lr: 0.0009829845376532228\n",
      "step: 168, acc: 0.852, loss: 0.603 (data_loss: 0.603, reg_loss: 0.000), lr: 0.000982974875162191\n",
      "step: 169, acc: 0.891, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.000982965212861117\n",
      "step: 170, acc: 0.875, loss: 0.534 (data_loss: 0.534, reg_loss: 0.000), lr: 0.0009829555507499953\n",
      "step: 171, acc: 0.891, loss: 0.464 (data_loss: 0.464, reg_loss: 0.000), lr: 0.00098294588882882\n",
      "step: 172, acc: 0.828, loss: 0.541 (data_loss: 0.541, reg_loss: 0.000), lr: 0.000982936227097586\n",
      "step: 173, acc: 0.859, loss: 0.517 (data_loss: 0.517, reg_loss: 0.000), lr: 0.0009829265655562872\n",
      "step: 174, acc: 0.812, loss: 0.521 (data_loss: 0.521, reg_loss: 0.000), lr: 0.0009829169042049185\n",
      "step: 175, acc: 0.898, loss: 0.489 (data_loss: 0.489, reg_loss: 0.000), lr: 0.0009829072430434741\n",
      "step: 176, acc: 0.898, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.000982897582071948\n",
      "step: 177, acc: 0.844, loss: 0.517 (data_loss: 0.517, reg_loss: 0.000), lr: 0.0009828879212903353\n",
      "step: 178, acc: 0.859, loss: 0.562 (data_loss: 0.562, reg_loss: 0.000), lr: 0.0009828782606986297\n",
      "step: 179, acc: 0.875, loss: 0.525 (data_loss: 0.525, reg_loss: 0.000), lr: 0.0009828686002968262\n",
      "step: 180, acc: 0.891, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.000982858940084919\n",
      "step: 181, acc: 0.922, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009828492800629024\n",
      "step: 182, acc: 0.875, loss: 0.455 (data_loss: 0.455, reg_loss: 0.000), lr: 0.0009828396202307707\n",
      "step: 183, acc: 0.836, loss: 0.498 (data_loss: 0.498, reg_loss: 0.000), lr: 0.0009828299605885184\n",
      "step: 184, acc: 0.867, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.0009828203011361402\n",
      "step: 185, acc: 0.852, loss: 0.529 (data_loss: 0.529, reg_loss: 0.000), lr: 0.0009828106418736302\n",
      "step: 186, acc: 0.836, loss: 0.518 (data_loss: 0.518, reg_loss: 0.000), lr: 0.0009828009828009828\n",
      "step: 187, acc: 0.852, loss: 0.473 (data_loss: 0.473, reg_loss: 0.000), lr: 0.0009827913239181926\n",
      "step: 188, acc: 0.922, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009827816652252536\n",
      "step: 189, acc: 0.883, loss: 0.414 (data_loss: 0.414, reg_loss: 0.000), lr: 0.0009827720067221604\n",
      "step: 190, acc: 0.844, loss: 0.529 (data_loss: 0.529, reg_loss: 0.000), lr: 0.000982762348408908\n",
      "step: 191, acc: 0.875, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009827526902854897\n",
      "step: 192, acc: 0.930, loss: 0.306 (data_loss: 0.306, reg_loss: 0.000), lr: 0.0009827430323519006\n",
      "step: 193, acc: 0.883, loss: 0.485 (data_loss: 0.485, reg_loss: 0.000), lr: 0.000982733374608135\n",
      "step: 194, acc: 0.867, loss: 0.567 (data_loss: 0.567, reg_loss: 0.000), lr: 0.0009827237170541875\n",
      "step: 195, acc: 0.930, loss: 0.453 (data_loss: 0.453, reg_loss: 0.000), lr: 0.000982714059690052\n",
      "step: 196, acc: 0.859, loss: 0.475 (data_loss: 0.475, reg_loss: 0.000), lr: 0.0009827044025157233\n",
      "step: 197, acc: 0.898, loss: 0.429 (data_loss: 0.429, reg_loss: 0.000), lr: 0.0009826947455311957\n",
      "step: 198, acc: 0.859, loss: 0.569 (data_loss: 0.569, reg_loss: 0.000), lr: 0.0009826850887364636\n",
      "step: 199, acc: 0.898, loss: 0.399 (data_loss: 0.399, reg_loss: 0.000), lr: 0.0009826754321315212\n",
      "step: 200, acc: 0.867, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.0009826657757163633\n",
      "step: 201, acc: 0.820, loss: 0.592 (data_loss: 0.592, reg_loss: 0.000), lr: 0.0009826561194909843\n",
      "step: 202, acc: 0.859, loss: 0.518 (data_loss: 0.518, reg_loss: 0.000), lr: 0.000982646463455378\n",
      "step: 203, acc: 0.852, loss: 0.521 (data_loss: 0.521, reg_loss: 0.000), lr: 0.0009826368076095394\n",
      "step: 204, acc: 0.945, loss: 0.326 (data_loss: 0.326, reg_loss: 0.000), lr: 0.0009826271519534629\n",
      "step: 205, acc: 0.883, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009826174964871425\n",
      "step: 206, acc: 0.844, loss: 0.512 (data_loss: 0.512, reg_loss: 0.000), lr: 0.0009826078412105727\n",
      "step: 207, acc: 0.844, loss: 0.450 (data_loss: 0.450, reg_loss: 0.000), lr: 0.0009825981861237485\n",
      "step: 208, acc: 0.875, loss: 0.476 (data_loss: 0.476, reg_loss: 0.000), lr: 0.0009825885312266635\n",
      "step: 209, acc: 0.852, loss: 0.540 (data_loss: 0.540, reg_loss: 0.000), lr: 0.0009825788765193127\n",
      "step: 210, acc: 0.859, loss: 0.483 (data_loss: 0.483, reg_loss: 0.000), lr: 0.00098256922200169\n",
      "step: 211, acc: 0.898, loss: 0.427 (data_loss: 0.427, reg_loss: 0.000), lr: 0.0009825595676737904\n",
      "step: 212, acc: 0.906, loss: 0.449 (data_loss: 0.449, reg_loss: 0.000), lr: 0.0009825499135356077\n",
      "step: 213, acc: 0.883, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.0009825402595871366\n",
      "step: 214, acc: 0.852, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.0009825306058283715\n",
      "step: 215, acc: 0.906, loss: 0.447 (data_loss: 0.447, reg_loss: 0.000), lr: 0.000982520952259307\n",
      "step: 216, acc: 0.828, loss: 0.495 (data_loss: 0.495, reg_loss: 0.000), lr: 0.000982511298879937\n",
      "step: 217, acc: 0.883, loss: 0.460 (data_loss: 0.460, reg_loss: 0.000), lr: 0.0009825016456902565\n",
      "step: 218, acc: 0.820, loss: 0.514 (data_loss: 0.514, reg_loss: 0.000), lr: 0.0009824919926902597\n",
      "step: 219, acc: 0.867, loss: 0.499 (data_loss: 0.499, reg_loss: 0.000), lr: 0.0009824823398799406\n",
      "step: 220, acc: 0.898, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.0009824726872592943\n",
      "step: 221, acc: 0.906, loss: 0.437 (data_loss: 0.437, reg_loss: 0.000), lr: 0.0009824630348283148\n",
      "step: 222, acc: 0.805, loss: 0.536 (data_loss: 0.536, reg_loss: 0.000), lr: 0.0009824533825869963\n",
      "step: 223, acc: 0.875, loss: 0.484 (data_loss: 0.484, reg_loss: 0.000), lr: 0.0009824437305353336\n",
      "step: 224, acc: 0.844, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.000982434078673321\n",
      "step: 225, acc: 0.797, loss: 0.650 (data_loss: 0.650, reg_loss: 0.000), lr: 0.000982424427000953\n",
      "step: 226, acc: 0.844, loss: 0.483 (data_loss: 0.483, reg_loss: 0.000), lr: 0.0009824147755182239\n",
      "step: 227, acc: 0.859, loss: 0.492 (data_loss: 0.492, reg_loss: 0.000), lr: 0.0009824051242251278\n",
      "step: 228, acc: 0.812, loss: 0.562 (data_loss: 0.562, reg_loss: 0.000), lr: 0.00098239547312166\n",
      "step: 229, acc: 0.875, loss: 0.496 (data_loss: 0.496, reg_loss: 0.000), lr: 0.0009823858222078139\n",
      "step: 230, acc: 0.867, loss: 0.458 (data_loss: 0.458, reg_loss: 0.000), lr: 0.0009823761714835846\n",
      "step: 231, acc: 0.883, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.0009823665209489662\n",
      "step: 232, acc: 0.930, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.000982356870603953\n",
      "step: 233, acc: 0.875, loss: 0.538 (data_loss: 0.538, reg_loss: 0.000), lr: 0.0009823472204485398\n",
      "step: 234, acc: 0.891, loss: 0.502 (data_loss: 0.502, reg_loss: 0.000), lr: 0.0009823375704827205\n",
      "step: 235, acc: 0.859, loss: 0.524 (data_loss: 0.524, reg_loss: 0.000), lr: 0.0009823279207064903\n",
      "step: 236, acc: 0.891, loss: 0.468 (data_loss: 0.468, reg_loss: 0.000), lr: 0.0009823182711198428\n",
      "step: 237, acc: 0.914, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009823086217227728\n",
      "step: 238, acc: 0.898, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009822989725152748\n",
      "step: 239, acc: 0.906, loss: 0.492 (data_loss: 0.492, reg_loss: 0.000), lr: 0.000982289323497343\n",
      "step: 240, acc: 0.891, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.0009822796746689717\n",
      "step: 241, acc: 0.867, loss: 0.525 (data_loss: 0.525, reg_loss: 0.000), lr: 0.0009822700260301558\n",
      "step: 242, acc: 0.930, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.000982260377580889\n",
      "step: 243, acc: 0.922, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.0009822507293211664\n",
      "step: 244, acc: 0.867, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.0009822410812509823\n",
      "step: 245, acc: 0.867, loss: 0.533 (data_loss: 0.533, reg_loss: 0.000), lr: 0.0009822314333703308\n",
      "step: 246, acc: 0.914, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.0009822217856792063\n",
      "step: 247, acc: 0.867, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0009822121381776036\n",
      "step: 248, acc: 0.891, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.000982202490865517\n",
      "step: 249, acc: 0.844, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.0009821928437429405\n",
      "step: 250, acc: 0.875, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.000982183196809869\n",
      "step: 251, acc: 0.906, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009821735500662966\n",
      "step: 252, acc: 0.914, loss: 0.408 (data_loss: 0.408, reg_loss: 0.000), lr: 0.0009821639035122183\n",
      "step: 253, acc: 0.930, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009821542571476277\n",
      "step: 254, acc: 0.867, loss: 0.516 (data_loss: 0.516, reg_loss: 0.000), lr: 0.0009821446109725194\n",
      "step: 255, acc: 0.875, loss: 0.476 (data_loss: 0.476, reg_loss: 0.000), lr: 0.0009821349649868885\n",
      "step: 256, acc: 0.852, loss: 0.454 (data_loss: 0.454, reg_loss: 0.000), lr: 0.0009821253191907287\n",
      "step: 257, acc: 0.852, loss: 0.525 (data_loss: 0.525, reg_loss: 0.000), lr: 0.0009821156735840347\n",
      "step: 258, acc: 0.922, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009821060281668009\n",
      "step: 259, acc: 0.891, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009820963829390216\n",
      "step: 260, acc: 0.852, loss: 0.541 (data_loss: 0.541, reg_loss: 0.000), lr: 0.0009820867379006914\n",
      "step: 261, acc: 0.914, loss: 0.393 (data_loss: 0.393, reg_loss: 0.000), lr: 0.0009820770930518046\n",
      "step: 262, acc: 0.914, loss: 0.451 (data_loss: 0.451, reg_loss: 0.000), lr: 0.0009820674483923557\n",
      "step: 263, acc: 0.852, loss: 0.473 (data_loss: 0.473, reg_loss: 0.000), lr: 0.0009820578039223388\n",
      "step: 264, acc: 0.852, loss: 0.508 (data_loss: 0.508, reg_loss: 0.000), lr: 0.0009820481596417487\n",
      "step: 265, acc: 0.891, loss: 0.472 (data_loss: 0.472, reg_loss: 0.000), lr: 0.00098203851555058\n",
      "step: 266, acc: 0.875, loss: 0.588 (data_loss: 0.588, reg_loss: 0.000), lr: 0.0009820288716488265\n",
      "step: 267, acc: 0.875, loss: 0.474 (data_loss: 0.474, reg_loss: 0.000), lr: 0.000982019227936483\n",
      "step: 268, acc: 0.820, loss: 0.649 (data_loss: 0.649, reg_loss: 0.000), lr: 0.0009820095844135439\n",
      "step: 269, acc: 0.875, loss: 0.458 (data_loss: 0.458, reg_loss: 0.000), lr: 0.0009819999410800035\n",
      "step: 270, acc: 0.875, loss: 0.492 (data_loss: 0.492, reg_loss: 0.000), lr: 0.0009819902979358564\n",
      "step: 271, acc: 0.875, loss: 0.449 (data_loss: 0.449, reg_loss: 0.000), lr: 0.0009819806549810968\n",
      "step: 272, acc: 0.875, loss: 0.447 (data_loss: 0.447, reg_loss: 0.000), lr: 0.0009819710122157194\n",
      "step: 273, acc: 0.898, loss: 0.393 (data_loss: 0.393, reg_loss: 0.000), lr: 0.0009819613696397183\n",
      "step: 274, acc: 0.852, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.0009819517272530883\n",
      "step: 275, acc: 0.805, loss: 0.591 (data_loss: 0.591, reg_loss: 0.000), lr: 0.0009819420850558235\n",
      "step: 276, acc: 0.867, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.0009819324430479185\n",
      "step: 277, acc: 0.859, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.0009819228012293672\n",
      "step: 278, acc: 0.898, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.000981913159600165\n",
      "step: 279, acc: 0.875, loss: 0.507 (data_loss: 0.507, reg_loss: 0.000), lr: 0.0009819035181603056\n",
      "step: 280, acc: 0.891, loss: 0.476 (data_loss: 0.476, reg_loss: 0.000), lr: 0.0009818938769097837\n",
      "step: 281, acc: 0.891, loss: 0.494 (data_loss: 0.494, reg_loss: 0.000), lr: 0.0009818842358485934\n",
      "step: 282, acc: 0.883, loss: 0.452 (data_loss: 0.452, reg_loss: 0.000), lr: 0.0009818745949767298\n",
      "step: 283, acc: 0.844, loss: 0.528 (data_loss: 0.528, reg_loss: 0.000), lr: 0.0009818649542941865\n",
      "step: 284, acc: 0.883, loss: 0.419 (data_loss: 0.419, reg_loss: 0.000), lr: 0.0009818553138009583\n",
      "step: 285, acc: 0.930, loss: 0.312 (data_loss: 0.312, reg_loss: 0.000), lr: 0.00098184567349704\n",
      "step: 286, acc: 0.898, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009818360333824251\n",
      "step: 287, acc: 0.859, loss: 0.573 (data_loss: 0.573, reg_loss: 0.000), lr: 0.0009818263934571088\n",
      "step: 288, acc: 0.922, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009818167537210855\n",
      "step: 289, acc: 0.906, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009818071141743494\n",
      "step: 290, acc: 0.906, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009817974748168948\n",
      "step: 291, acc: 0.836, loss: 0.503 (data_loss: 0.503, reg_loss: 0.000), lr: 0.0009817878356487163\n",
      "step: 292, acc: 0.875, loss: 0.459 (data_loss: 0.459, reg_loss: 0.000), lr: 0.0009817781966698085\n",
      "step: 293, acc: 0.898, loss: 0.341 (data_loss: 0.341, reg_loss: 0.000), lr: 0.0009817685578801653\n",
      "step: 294, acc: 0.836, loss: 0.525 (data_loss: 0.525, reg_loss: 0.000), lr: 0.0009817589192797817\n",
      "step: 295, acc: 0.906, loss: 0.504 (data_loss: 0.504, reg_loss: 0.000), lr: 0.0009817492808686518\n",
      "step: 296, acc: 0.875, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009817396426467701\n",
      "step: 297, acc: 0.867, loss: 0.514 (data_loss: 0.514, reg_loss: 0.000), lr: 0.000981730004614131\n",
      "step: 298, acc: 0.906, loss: 0.425 (data_loss: 0.425, reg_loss: 0.000), lr: 0.000981720366770729\n",
      "step: 299, acc: 0.945, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009817107291165586\n",
      "step: 300, acc: 0.898, loss: 0.436 (data_loss: 0.436, reg_loss: 0.000), lr: 0.000981701091651614\n",
      "step: 301, acc: 0.859, loss: 0.445 (data_loss: 0.445, reg_loss: 0.000), lr: 0.0009816914543758896\n",
      "step: 302, acc: 0.883, loss: 0.474 (data_loss: 0.474, reg_loss: 0.000), lr: 0.0009816818172893804\n",
      "step: 303, acc: 0.875, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.00098167218039208\n",
      "step: 304, acc: 0.891, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.0009816625436839831\n",
      "step: 305, acc: 0.883, loss: 0.448 (data_loss: 0.448, reg_loss: 0.000), lr: 0.0009816529071650845\n",
      "step: 306, acc: 0.891, loss: 0.445 (data_loss: 0.445, reg_loss: 0.000), lr: 0.0009816432708353786\n",
      "step: 307, acc: 0.914, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009816336346948592\n",
      "step: 308, acc: 0.852, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.0009816239987435213\n",
      "step: 309, acc: 0.859, loss: 0.501 (data_loss: 0.501, reg_loss: 0.000), lr: 0.0009816143629813592\n",
      "step: 310, acc: 0.898, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009816047274083673\n",
      "step: 311, acc: 0.875, loss: 0.479 (data_loss: 0.479, reg_loss: 0.000), lr: 0.00098159509202454\n",
      "step: 312, acc: 0.836, loss: 0.486 (data_loss: 0.486, reg_loss: 0.000), lr: 0.0009815854568298716\n",
      "step: 313, acc: 0.859, loss: 0.454 (data_loss: 0.454, reg_loss: 0.000), lr: 0.000981575821824357\n",
      "step: 314, acc: 0.914, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.00098156618700799\n",
      "step: 315, acc: 0.891, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.0009815565523807654\n",
      "step: 316, acc: 0.906, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.0009815469179426776\n",
      "step: 317, acc: 0.883, loss: 0.376 (data_loss: 0.376, reg_loss: 0.000), lr: 0.000981537283693721\n",
      "step: 318, acc: 0.875, loss: 0.459 (data_loss: 0.459, reg_loss: 0.000), lr: 0.0009815276496338901\n",
      "step: 319, acc: 0.930, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.0009815180157631794\n",
      "step: 320, acc: 0.875, loss: 0.501 (data_loss: 0.501, reg_loss: 0.000), lr: 0.000981508382081583\n",
      "step: 321, acc: 0.836, loss: 0.502 (data_loss: 0.502, reg_loss: 0.000), lr: 0.0009814987485890956\n",
      "step: 322, acc: 0.875, loss: 0.447 (data_loss: 0.447, reg_loss: 0.000), lr: 0.0009814891152857114\n",
      "step: 323, acc: 0.891, loss: 0.423 (data_loss: 0.423, reg_loss: 0.000), lr: 0.0009814794821714253\n",
      "step: 324, acc: 0.867, loss: 0.505 (data_loss: 0.505, reg_loss: 0.000), lr: 0.000981469849246231\n",
      "step: 325, acc: 0.883, loss: 0.511 (data_loss: 0.511, reg_loss: 0.000), lr: 0.0009814602165101238\n",
      "step: 326, acc: 0.867, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0009814505839630975\n",
      "step: 327, acc: 0.883, loss: 0.479 (data_loss: 0.479, reg_loss: 0.000), lr: 0.0009814409516051468\n",
      "step: 328, acc: 0.859, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.000981431319436266\n",
      "step: 329, acc: 0.898, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.0009814216874564493\n",
      "step: 330, acc: 0.883, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009814120556656918\n",
      "step: 331, acc: 0.844, loss: 0.492 (data_loss: 0.492, reg_loss: 0.000), lr: 0.0009814024240639874\n",
      "step: 332, acc: 0.891, loss: 0.484 (data_loss: 0.484, reg_loss: 0.000), lr: 0.0009813927926513308\n",
      "step: 333, acc: 0.875, loss: 0.468 (data_loss: 0.468, reg_loss: 0.000), lr: 0.0009813831614277164\n",
      "step: 334, acc: 0.859, loss: 0.543 (data_loss: 0.543, reg_loss: 0.000), lr: 0.0009813735303931383\n",
      "step: 335, acc: 0.906, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.0009813638995475912\n",
      "step: 336, acc: 0.914, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009813542688910698\n",
      "step: 337, acc: 0.867, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.000981344638423568\n",
      "step: 338, acc: 0.930, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.0009813350081450806\n",
      "step: 339, acc: 0.844, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.000981325378055602\n",
      "step: 340, acc: 0.930, loss: 0.349 (data_loss: 0.349, reg_loss: 0.000), lr: 0.0009813157481551266\n",
      "step: 341, acc: 0.812, loss: 0.520 (data_loss: 0.520, reg_loss: 0.000), lr: 0.0009813061184436485\n",
      "step: 342, acc: 0.836, loss: 0.479 (data_loss: 0.479, reg_loss: 0.000), lr: 0.0009812964889211627\n",
      "step: 343, acc: 0.883, loss: 0.470 (data_loss: 0.470, reg_loss: 0.000), lr: 0.0009812868595876635\n",
      "step: 344, acc: 0.875, loss: 0.465 (data_loss: 0.465, reg_loss: 0.000), lr: 0.0009812772304431448\n",
      "step: 345, acc: 0.883, loss: 0.437 (data_loss: 0.437, reg_loss: 0.000), lr: 0.0009812676014876016\n",
      "step: 346, acc: 0.828, loss: 0.491 (data_loss: 0.491, reg_loss: 0.000), lr: 0.0009812579727210284\n",
      "step: 347, acc: 0.906, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009812483441434194\n",
      "step: 348, acc: 0.828, loss: 0.508 (data_loss: 0.508, reg_loss: 0.000), lr: 0.0009812387157547688\n",
      "step: 349, acc: 0.844, loss: 0.485 (data_loss: 0.485, reg_loss: 0.000), lr: 0.0009812290875550714\n",
      "step: 350, acc: 0.859, loss: 0.494 (data_loss: 0.494, reg_loss: 0.000), lr: 0.0009812194595443218\n",
      "step: 351, acc: 0.914, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009812098317225138\n",
      "step: 352, acc: 0.867, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0009812002040896423\n",
      "step: 353, acc: 0.828, loss: 0.519 (data_loss: 0.519, reg_loss: 0.000), lr: 0.000981190576645702\n",
      "step: 354, acc: 0.883, loss: 0.524 (data_loss: 0.524, reg_loss: 0.000), lr: 0.0009811809493906866\n",
      "step: 355, acc: 0.914, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009811713223245911\n",
      "step: 356, acc: 0.875, loss: 0.530 (data_loss: 0.530, reg_loss: 0.000), lr: 0.0009811616954474097\n",
      "step: 357, acc: 0.883, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009811520687591372\n",
      "step: 358, acc: 0.906, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009811424422597672\n",
      "step: 359, acc: 0.898, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0009811328159492951\n",
      "step: 360, acc: 0.844, loss: 0.481 (data_loss: 0.481, reg_loss: 0.000), lr: 0.000981123189827715\n",
      "step: 361, acc: 0.906, loss: 0.425 (data_loss: 0.425, reg_loss: 0.000), lr: 0.000981113563895021\n",
      "step: 362, acc: 0.898, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009811039381512076\n",
      "step: 363, acc: 0.828, loss: 0.518 (data_loss: 0.518, reg_loss: 0.000), lr: 0.0009810943125962701\n",
      "step: 364, acc: 0.859, loss: 0.492 (data_loss: 0.492, reg_loss: 0.000), lr: 0.0009810846872302017\n",
      "step: 365, acc: 0.859, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.0009810750620529976\n",
      "step: 366, acc: 0.852, loss: 0.485 (data_loss: 0.485, reg_loss: 0.000), lr: 0.0009810654370646522\n",
      "step: 367, acc: 0.906, loss: 0.321 (data_loss: 0.321, reg_loss: 0.000), lr: 0.0009810558122651599\n",
      "step: 368, acc: 0.906, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0009810461876545147\n",
      "step: 369, acc: 0.875, loss: 0.460 (data_loss: 0.460, reg_loss: 0.000), lr: 0.0009810365632327116\n",
      "step: 370, acc: 0.836, loss: 0.471 (data_loss: 0.471, reg_loss: 0.000), lr: 0.000981026938999745\n",
      "step: 371, acc: 0.906, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.000981017314955609\n",
      "step: 372, acc: 0.898, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.0009810076911002982\n",
      "step: 373, acc: 0.914, loss: 0.364 (data_loss: 0.364, reg_loss: 0.000), lr: 0.000980998067433807\n",
      "step: 374, acc: 0.914, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.0009809884439561302\n",
      "step: 375, acc: 0.898, loss: 0.447 (data_loss: 0.447, reg_loss: 0.000), lr: 0.0009809788206672618\n",
      "step: 376, acc: 0.875, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0009809691975671965\n",
      "step: 377, acc: 0.914, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.0009809595746559285\n",
      "step: 378, acc: 0.859, loss: 0.423 (data_loss: 0.423, reg_loss: 0.000), lr: 0.0009809499519334525\n",
      "step: 379, acc: 0.867, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.0009809403293997627\n",
      "step: 380, acc: 0.891, loss: 0.474 (data_loss: 0.474, reg_loss: 0.000), lr: 0.0009809307070548538\n",
      "step: 381, acc: 0.898, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009809210848987198\n",
      "step: 382, acc: 0.914, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.000980911462931356\n",
      "step: 383, acc: 0.898, loss: 0.452 (data_loss: 0.452, reg_loss: 0.000), lr: 0.000980901841152756\n",
      "step: 384, acc: 0.836, loss: 0.487 (data_loss: 0.487, reg_loss: 0.000), lr: 0.0009808922195629144\n",
      "step: 385, acc: 0.891, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.000980882598161826\n",
      "step: 386, acc: 0.859, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.0009808729769494849\n",
      "step: 387, acc: 0.922, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.000980863355925886\n",
      "step: 388, acc: 0.891, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.0009808537350910233\n",
      "step: 389, acc: 0.883, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009808441144448913\n",
      "step: 390, acc: 0.900, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.0009808344939874845\n",
      "training, acc: 0.875, loss: 0.468 (data_loss: 0.468, reg_loss: 0.000), lr: 0.0009808344939874845\n",
      "validation, acc: 0.883, loss: 0.429\n",
      "epoch: 6\n",
      "step: 0, acc: 0.859, loss: 0.545 (data_loss: 0.545, reg_loss: 0.000), lr: 0.0009808248737187975\n",
      "step: 1, acc: 0.844, loss: 0.540 (data_loss: 0.540, reg_loss: 0.000), lr: 0.0009808152536388247\n",
      "step: 2, acc: 0.875, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.0009808056337475602\n",
      "step: 3, acc: 0.898, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.000980796014044999\n",
      "step: 4, acc: 0.914, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.000980786394531135\n",
      "step: 5, acc: 0.883, loss: 0.491 (data_loss: 0.491, reg_loss: 0.000), lr: 0.000980776775205963\n",
      "step: 6, acc: 0.898, loss: 0.468 (data_loss: 0.468, reg_loss: 0.000), lr: 0.0009807671560694777\n",
      "step: 7, acc: 0.922, loss: 0.346 (data_loss: 0.346, reg_loss: 0.000), lr: 0.0009807575371216727\n",
      "step: 8, acc: 0.891, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.0009807479183625433\n",
      "step: 9, acc: 0.938, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009807382997920834\n",
      "step: 10, acc: 0.914, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.000980728681410288\n",
      "step: 11, acc: 0.867, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0009807190632171508\n",
      "step: 12, acc: 0.891, loss: 0.411 (data_loss: 0.411, reg_loss: 0.000), lr: 0.0009807094452126668\n",
      "step: 13, acc: 0.867, loss: 0.500 (data_loss: 0.500, reg_loss: 0.000), lr: 0.0009806998273968305\n",
      "step: 14, acc: 0.891, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.000980690209769636\n",
      "step: 15, acc: 0.906, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.0009806805923310777\n",
      "step: 16, acc: 0.906, loss: 0.442 (data_loss: 0.442, reg_loss: 0.000), lr: 0.0009806709750811507\n",
      "step: 17, acc: 0.875, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.0009806613580198487\n",
      "step: 18, acc: 0.906, loss: 0.423 (data_loss: 0.423, reg_loss: 0.000), lr: 0.0009806517411471663\n",
      "step: 19, acc: 0.859, loss: 0.419 (data_loss: 0.419, reg_loss: 0.000), lr: 0.0009806421244630984\n",
      "step: 20, acc: 0.844, loss: 0.448 (data_loss: 0.448, reg_loss: 0.000), lr: 0.0009806325079676393\n",
      "step: 21, acc: 0.844, loss: 0.514 (data_loss: 0.514, reg_loss: 0.000), lr: 0.000980622891660783\n",
      "step: 22, acc: 0.922, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009806132755425243\n",
      "step: 23, acc: 0.844, loss: 0.485 (data_loss: 0.485, reg_loss: 0.000), lr: 0.0009806036596128579\n",
      "step: 24, acc: 0.891, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0009805940438717775\n",
      "step: 25, acc: 0.914, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009805844283192783\n",
      "step: 26, acc: 0.898, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.0009805748129553544\n",
      "step: 27, acc: 0.898, loss: 0.390 (data_loss: 0.390, reg_loss: 0.000), lr: 0.0009805651977800004\n",
      "step: 28, acc: 0.906, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009805555827932108\n",
      "step: 29, acc: 0.891, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.0009805459679949795\n",
      "step: 30, acc: 0.891, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0009805363533853019\n",
      "step: 31, acc: 0.891, loss: 0.470 (data_loss: 0.470, reg_loss: 0.000), lr: 0.0009805267389641715\n",
      "step: 32, acc: 0.906, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000), lr: 0.0009805171247315833\n",
      "step: 33, acc: 0.867, loss: 0.437 (data_loss: 0.437, reg_loss: 0.000), lr: 0.000980507510687532\n",
      "step: 34, acc: 0.891, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009804978968320113\n",
      "step: 35, acc: 0.875, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009804882831650162\n",
      "step: 36, acc: 0.914, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.000980478669686541\n",
      "step: 37, acc: 0.883, loss: 0.415 (data_loss: 0.415, reg_loss: 0.000), lr: 0.0009804690563965802\n",
      "step: 38, acc: 0.844, loss: 0.445 (data_loss: 0.445, reg_loss: 0.000), lr: 0.0009804594432951282\n",
      "step: 39, acc: 0.875, loss: 0.527 (data_loss: 0.527, reg_loss: 0.000), lr: 0.0009804498303821792\n",
      "step: 40, acc: 0.898, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009804402176577284\n",
      "step: 41, acc: 0.891, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009804306051217695\n",
      "step: 42, acc: 0.852, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.0009804209927742973\n",
      "step: 43, acc: 0.875, loss: 0.408 (data_loss: 0.408, reg_loss: 0.000), lr: 0.000980411380615306\n",
      "step: 44, acc: 0.891, loss: 0.476 (data_loss: 0.476, reg_loss: 0.000), lr: 0.0009804017686447907\n",
      "step: 45, acc: 0.906, loss: 0.447 (data_loss: 0.447, reg_loss: 0.000), lr: 0.000980392156862745\n",
      "step: 46, acc: 0.898, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.000980382545269164\n",
      "step: 47, acc: 0.867, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.000980372933864042\n",
      "step: 48, acc: 0.898, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009803633226473732\n",
      "step: 49, acc: 0.914, loss: 0.361 (data_loss: 0.361, reg_loss: 0.000), lr: 0.000980353711619152\n",
      "step: 50, acc: 0.914, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009803441007793737\n",
      "step: 51, acc: 0.898, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009803344901280317\n",
      "step: 52, acc: 0.891, loss: 0.483 (data_loss: 0.483, reg_loss: 0.000), lr: 0.000980324879665121\n",
      "step: 53, acc: 0.789, loss: 0.554 (data_loss: 0.554, reg_loss: 0.000), lr: 0.000980315269390636\n",
      "step: 54, acc: 0.883, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009803056593045713\n",
      "step: 55, acc: 0.859, loss: 0.517 (data_loss: 0.517, reg_loss: 0.000), lr: 0.000980296049406921\n",
      "step: 56, acc: 0.898, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0009802864396976797\n",
      "step: 57, acc: 0.922, loss: 0.363 (data_loss: 0.363, reg_loss: 0.000), lr: 0.000980276830176842\n",
      "step: 58, acc: 0.883, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009802672208444022\n",
      "step: 59, acc: 0.859, loss: 0.429 (data_loss: 0.429, reg_loss: 0.000), lr: 0.0009802576117003549\n",
      "step: 60, acc: 0.898, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.0009802480027446942\n",
      "step: 61, acc: 0.906, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.0009802383939774154\n",
      "step: 62, acc: 0.891, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.000980228785398512\n",
      "step: 63, acc: 0.859, loss: 0.481 (data_loss: 0.481, reg_loss: 0.000), lr: 0.0009802191770079789\n",
      "step: 64, acc: 0.867, loss: 0.510 (data_loss: 0.510, reg_loss: 0.000), lr: 0.0009802095688058107\n",
      "step: 65, acc: 0.828, loss: 0.563 (data_loss: 0.563, reg_loss: 0.000), lr: 0.0009801999607920015\n",
      "step: 66, acc: 0.922, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.000980190352966546\n",
      "step: 67, acc: 0.844, loss: 0.513 (data_loss: 0.513, reg_loss: 0.000), lr: 0.000980180745329439\n",
      "step: 68, acc: 0.852, loss: 0.453 (data_loss: 0.453, reg_loss: 0.000), lr: 0.000980171137880674\n",
      "step: 69, acc: 0.852, loss: 0.443 (data_loss: 0.443, reg_loss: 0.000), lr: 0.000980161530620246\n",
      "step: 70, acc: 0.891, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.00098015192354815\n",
      "step: 71, acc: 0.914, loss: 0.375 (data_loss: 0.375, reg_loss: 0.000), lr: 0.0009801423166643796\n",
      "step: 72, acc: 0.930, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009801327099689299\n",
      "step: 73, acc: 0.953, loss: 0.298 (data_loss: 0.298, reg_loss: 0.000), lr: 0.0009801231034617947\n",
      "step: 74, acc: 0.891, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.0009801134971429693\n",
      "step: 75, acc: 0.875, loss: 0.468 (data_loss: 0.468, reg_loss: 0.000), lr: 0.0009801038910124474\n",
      "step: 76, acc: 0.922, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0009800942850702237\n",
      "step: 77, acc: 0.922, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000), lr: 0.000980084679316293\n",
      "step: 78, acc: 0.875, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.0009800750737506492\n",
      "step: 79, acc: 0.875, loss: 0.467 (data_loss: 0.467, reg_loss: 0.000), lr: 0.0009800654683732874\n",
      "step: 80, acc: 0.867, loss: 0.478 (data_loss: 0.478, reg_loss: 0.000), lr: 0.0009800558631842015\n",
      "step: 81, acc: 0.844, loss: 0.445 (data_loss: 0.445, reg_loss: 0.000), lr: 0.0009800462581833864\n",
      "step: 82, acc: 0.930, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000), lr: 0.000980036653370836\n",
      "step: 83, acc: 0.812, loss: 0.503 (data_loss: 0.503, reg_loss: 0.000), lr: 0.0009800270487465453\n",
      "step: 84, acc: 0.844, loss: 0.527 (data_loss: 0.527, reg_loss: 0.000), lr: 0.0009800174443105089\n",
      "step: 85, acc: 0.883, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.0009800078400627205\n",
      "step: 86, acc: 0.891, loss: 0.529 (data_loss: 0.529, reg_loss: 0.000), lr: 0.0009799982360031753\n",
      "step: 87, acc: 0.898, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009799886321318672\n",
      "step: 88, acc: 0.852, loss: 0.603 (data_loss: 0.603, reg_loss: 0.000), lr: 0.0009799790284487912\n",
      "step: 89, acc: 0.906, loss: 0.382 (data_loss: 0.382, reg_loss: 0.000), lr: 0.0009799694249539414\n",
      "step: 90, acc: 0.883, loss: 0.369 (data_loss: 0.369, reg_loss: 0.000), lr: 0.0009799598216473126\n",
      "step: 91, acc: 0.898, loss: 0.416 (data_loss: 0.416, reg_loss: 0.000), lr: 0.0009799502185288988\n",
      "step: 92, acc: 0.898, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009799406155986947\n",
      "step: 93, acc: 0.867, loss: 0.455 (data_loss: 0.455, reg_loss: 0.000), lr: 0.0009799310128566947\n",
      "step: 94, acc: 0.906, loss: 0.411 (data_loss: 0.411, reg_loss: 0.000), lr: 0.0009799214103028938\n",
      "step: 95, acc: 0.859, loss: 0.582 (data_loss: 0.582, reg_loss: 0.000), lr: 0.0009799118079372858\n",
      "step: 96, acc: 0.891, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.000979902205759865\n",
      "step: 97, acc: 0.891, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.0009798926037706268\n",
      "step: 98, acc: 0.828, loss: 0.515 (data_loss: 0.515, reg_loss: 0.000), lr: 0.0009798830019695649\n",
      "step: 99, acc: 0.906, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009798734003566738\n",
      "step: 100, acc: 0.898, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009798637989319485\n",
      "step: 101, acc: 0.891, loss: 0.508 (data_loss: 0.508, reg_loss: 0.000), lr: 0.0009798541976953831\n",
      "step: 102, acc: 0.891, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009798445966469717\n",
      "step: 103, acc: 0.875, loss: 0.539 (data_loss: 0.539, reg_loss: 0.000), lr: 0.0009798349957867096\n",
      "step: 104, acc: 0.867, loss: 0.450 (data_loss: 0.450, reg_loss: 0.000), lr: 0.0009798253951145905\n",
      "step: 105, acc: 0.875, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009798157946306096\n",
      "step: 106, acc: 0.867, loss: 0.366 (data_loss: 0.366, reg_loss: 0.000), lr: 0.0009798061943347607\n",
      "step: 107, acc: 0.852, loss: 0.545 (data_loss: 0.545, reg_loss: 0.000), lr: 0.0009797965942270385\n",
      "step: 108, acc: 0.898, loss: 0.398 (data_loss: 0.398, reg_loss: 0.000), lr: 0.0009797869943074377\n",
      "step: 109, acc: 0.914, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.0009797773945759525\n",
      "step: 110, acc: 0.961, loss: 0.296 (data_loss: 0.296, reg_loss: 0.000), lr: 0.0009797677950325772\n",
      "step: 111, acc: 0.859, loss: 0.460 (data_loss: 0.460, reg_loss: 0.000), lr: 0.0009797581956773069\n",
      "step: 112, acc: 0.914, loss: 0.453 (data_loss: 0.453, reg_loss: 0.000), lr: 0.0009797485965101357\n",
      "step: 113, acc: 0.883, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009797389975310577\n",
      "step: 114, acc: 0.867, loss: 0.422 (data_loss: 0.422, reg_loss: 0.000), lr: 0.000979729398740068\n",
      "step: 115, acc: 0.914, loss: 0.361 (data_loss: 0.361, reg_loss: 0.000), lr: 0.000979719800137161\n",
      "step: 116, acc: 0.836, loss: 0.520 (data_loss: 0.520, reg_loss: 0.000), lr: 0.0009797102017223304\n",
      "step: 117, acc: 0.891, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.0009797006034955717\n",
      "step: 118, acc: 0.891, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009796910054568789\n",
      "step: 119, acc: 0.891, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.0009796814076062465\n",
      "step: 120, acc: 0.906, loss: 0.320 (data_loss: 0.320, reg_loss: 0.000), lr: 0.0009796718099436689\n",
      "step: 121, acc: 0.883, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0009796622124691407\n",
      "step: 122, acc: 0.891, loss: 0.503 (data_loss: 0.503, reg_loss: 0.000), lr: 0.0009796526151826562\n",
      "step: 123, acc: 0.844, loss: 0.548 (data_loss: 0.548, reg_loss: 0.000), lr: 0.00097964301808421\n",
      "step: 124, acc: 0.844, loss: 0.473 (data_loss: 0.473, reg_loss: 0.000), lr: 0.0009796334211737967\n",
      "step: 125, acc: 0.867, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.0009796238244514108\n",
      "step: 126, acc: 0.891, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009796142279170463\n",
      "step: 127, acc: 0.906, loss: 0.369 (data_loss: 0.369, reg_loss: 0.000), lr: 0.000979604631570698\n",
      "step: 128, acc: 0.836, loss: 0.498 (data_loss: 0.498, reg_loss: 0.000), lr: 0.0009795950354123605\n",
      "step: 129, acc: 0.906, loss: 0.328 (data_loss: 0.328, reg_loss: 0.000), lr: 0.0009795854394420282\n",
      "step: 130, acc: 0.812, loss: 0.556 (data_loss: 0.556, reg_loss: 0.000), lr: 0.0009795758436596954\n",
      "step: 131, acc: 0.828, loss: 0.565 (data_loss: 0.565, reg_loss: 0.000), lr: 0.0009795662480653565\n",
      "step: 132, acc: 0.883, loss: 0.408 (data_loss: 0.408, reg_loss: 0.000), lr: 0.0009795566526590066\n",
      "step: 133, acc: 0.875, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009795470574406394\n",
      "step: 134, acc: 0.922, loss: 0.349 (data_loss: 0.349, reg_loss: 0.000), lr: 0.0009795374624102498\n",
      "step: 135, acc: 0.898, loss: 0.345 (data_loss: 0.345, reg_loss: 0.000), lr: 0.0009795278675678325\n",
      "step: 136, acc: 0.883, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009795182729133813\n",
      "step: 137, acc: 0.930, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.0009795086784468911\n",
      "step: 138, acc: 0.867, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009794990841683565\n",
      "step: 139, acc: 0.859, loss: 0.453 (data_loss: 0.453, reg_loss: 0.000), lr: 0.0009794894900777716\n",
      "step: 140, acc: 0.906, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.000979479896175131\n",
      "step: 141, acc: 0.875, loss: 0.470 (data_loss: 0.470, reg_loss: 0.000), lr: 0.0009794703024604294\n",
      "step: 142, acc: 0.953, loss: 0.309 (data_loss: 0.309, reg_loss: 0.000), lr: 0.0009794607089336613\n",
      "step: 143, acc: 0.914, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.0009794511155948207\n",
      "step: 144, acc: 0.891, loss: 0.473 (data_loss: 0.473, reg_loss: 0.000), lr: 0.0009794415224439025\n",
      "step: 145, acc: 0.852, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009794319294809011\n",
      "step: 146, acc: 0.898, loss: 0.545 (data_loss: 0.545, reg_loss: 0.000), lr: 0.000979422336705811\n",
      "step: 147, acc: 0.812, loss: 0.534 (data_loss: 0.534, reg_loss: 0.000), lr: 0.0009794127441186266\n",
      "step: 148, acc: 0.875, loss: 0.477 (data_loss: 0.477, reg_loss: 0.000), lr: 0.0009794031517193422\n",
      "step: 149, acc: 0.906, loss: 0.341 (data_loss: 0.341, reg_loss: 0.000), lr: 0.0009793935595079528\n",
      "step: 150, acc: 0.875, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.0009793839674844523\n",
      "step: 151, acc: 0.906, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009793743756488355\n",
      "step: 152, acc: 0.891, loss: 0.436 (data_loss: 0.436, reg_loss: 0.000), lr: 0.000979364784001097\n",
      "step: 153, acc: 0.859, loss: 0.495 (data_loss: 0.495, reg_loss: 0.000), lr: 0.000979355192541231\n",
      "step: 154, acc: 0.898, loss: 0.356 (data_loss: 0.356, reg_loss: 0.000), lr: 0.0009793456012692318\n",
      "step: 155, acc: 0.906, loss: 0.363 (data_loss: 0.363, reg_loss: 0.000), lr: 0.0009793360101850947\n",
      "step: 156, acc: 0.898, loss: 0.376 (data_loss: 0.376, reg_loss: 0.000), lr: 0.000979326419288813\n",
      "step: 157, acc: 0.883, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009793168285803823\n",
      "step: 158, acc: 0.883, loss: 0.517 (data_loss: 0.517, reg_loss: 0.000), lr: 0.0009793072380597963\n",
      "step: 159, acc: 0.883, loss: 0.425 (data_loss: 0.425, reg_loss: 0.000), lr: 0.0009792976477270502\n",
      "step: 160, acc: 0.891, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009792880575821379\n",
      "step: 161, acc: 0.883, loss: 0.468 (data_loss: 0.468, reg_loss: 0.000), lr: 0.0009792784676250538\n",
      "step: 162, acc: 0.891, loss: 0.457 (data_loss: 0.457, reg_loss: 0.000), lr: 0.000979268877855793\n",
      "step: 163, acc: 0.867, loss: 0.440 (data_loss: 0.440, reg_loss: 0.000), lr: 0.0009792592882743494\n",
      "step: 164, acc: 0.906, loss: 0.312 (data_loss: 0.312, reg_loss: 0.000), lr: 0.0009792496988807176\n",
      "step: 165, acc: 0.867, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009792401096748921\n",
      "step: 166, acc: 0.836, loss: 0.499 (data_loss: 0.499, reg_loss: 0.000), lr: 0.0009792305206568679\n",
      "step: 167, acc: 0.844, loss: 0.460 (data_loss: 0.460, reg_loss: 0.000), lr: 0.0009792209318266387\n",
      "step: 168, acc: 0.859, loss: 0.556 (data_loss: 0.556, reg_loss: 0.000), lr: 0.0009792113431841994\n",
      "step: 169, acc: 0.914, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.0009792017547295446\n",
      "step: 170, acc: 0.875, loss: 0.490 (data_loss: 0.490, reg_loss: 0.000), lr: 0.0009791921664626683\n",
      "step: 171, acc: 0.906, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009791825783835653\n",
      "step: 172, acc: 0.836, loss: 0.501 (data_loss: 0.501, reg_loss: 0.000), lr: 0.0009791729904922305\n",
      "step: 173, acc: 0.859, loss: 0.467 (data_loss: 0.467, reg_loss: 0.000), lr: 0.0009791634027886574\n",
      "step: 174, acc: 0.828, loss: 0.479 (data_loss: 0.479, reg_loss: 0.000), lr: 0.0009791538152728412\n",
      "step: 175, acc: 0.898, loss: 0.445 (data_loss: 0.445, reg_loss: 0.000), lr: 0.0009791442279447763\n",
      "step: 176, acc: 0.906, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009791346408044572\n",
      "step: 177, acc: 0.867, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.000979125053851878\n",
      "step: 178, acc: 0.875, loss: 0.520 (data_loss: 0.520, reg_loss: 0.000), lr: 0.0009791154670870336\n",
      "step: 179, acc: 0.891, loss: 0.476 (data_loss: 0.476, reg_loss: 0.000), lr: 0.0009791058805099185\n",
      "step: 180, acc: 0.898, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009790962941205268\n",
      "step: 181, acc: 0.930, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000), lr: 0.0009790867079188532\n",
      "step: 182, acc: 0.891, loss: 0.399 (data_loss: 0.399, reg_loss: 0.000), lr: 0.0009790771219048925\n",
      "step: 183, acc: 0.844, loss: 0.454 (data_loss: 0.454, reg_loss: 0.000), lr: 0.0009790675360786386\n",
      "step: 184, acc: 0.883, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0009790579504400864\n",
      "step: 185, acc: 0.859, loss: 0.475 (data_loss: 0.475, reg_loss: 0.000), lr: 0.0009790483649892304\n",
      "step: 186, acc: 0.844, loss: 0.469 (data_loss: 0.469, reg_loss: 0.000), lr: 0.000979038779726065\n",
      "step: 187, acc: 0.867, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.0009790291946505845\n",
      "step: 188, acc: 0.945, loss: 0.350 (data_loss: 0.350, reg_loss: 0.000), lr: 0.0009790196097627835\n",
      "step: 189, acc: 0.906, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.0009790100250626568\n",
      "step: 190, acc: 0.859, loss: 0.486 (data_loss: 0.486, reg_loss: 0.000), lr: 0.0009790004405501984\n",
      "step: 191, acc: 0.891, loss: 0.336 (data_loss: 0.336, reg_loss: 0.000), lr: 0.0009789908562254028\n",
      "step: 192, acc: 0.938, loss: 0.253 (data_loss: 0.253, reg_loss: 0.000), lr: 0.000978981272088265\n",
      "step: 193, acc: 0.891, loss: 0.448 (data_loss: 0.448, reg_loss: 0.000), lr: 0.0009789716881387792\n",
      "step: 194, acc: 0.867, loss: 0.527 (data_loss: 0.527, reg_loss: 0.000), lr: 0.0009789621043769395\n",
      "step: 195, acc: 0.938, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.000978952520802741\n",
      "step: 196, acc: 0.875, loss: 0.430 (data_loss: 0.430, reg_loss: 0.000), lr: 0.0009789429374161781\n",
      "step: 197, acc: 0.906, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.000978933354217245\n",
      "step: 198, acc: 0.867, loss: 0.529 (data_loss: 0.529, reg_loss: 0.000), lr: 0.0009789237712059362\n",
      "step: 199, acc: 0.922, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.0009789141883822467\n",
      "step: 200, acc: 0.883, loss: 0.409 (data_loss: 0.409, reg_loss: 0.000), lr: 0.00097890460574617\n",
      "step: 201, acc: 0.820, loss: 0.551 (data_loss: 0.551, reg_loss: 0.000), lr: 0.0009788950232977015\n",
      "step: 202, acc: 0.875, loss: 0.464 (data_loss: 0.464, reg_loss: 0.000), lr: 0.0009788854410368354\n",
      "step: 203, acc: 0.859, loss: 0.474 (data_loss: 0.474, reg_loss: 0.000), lr: 0.0009788758589635664\n",
      "step: 204, acc: 0.961, loss: 0.270 (data_loss: 0.270, reg_loss: 0.000), lr: 0.0009788662770778885\n",
      "step: 205, acc: 0.898, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009788566953797965\n",
      "step: 206, acc: 0.852, loss: 0.465 (data_loss: 0.465, reg_loss: 0.000), lr: 0.0009788471138692848\n",
      "step: 207, acc: 0.875, loss: 0.396 (data_loss: 0.396, reg_loss: 0.000), lr: 0.000978837532546348\n",
      "step: 208, acc: 0.883, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.0009788279514109804\n",
      "step: 209, acc: 0.859, loss: 0.511 (data_loss: 0.511, reg_loss: 0.000), lr: 0.0009788183704631769\n",
      "step: 210, acc: 0.859, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009788087897029316\n",
      "step: 211, acc: 0.922, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.000978799209130239\n",
      "step: 212, acc: 0.906, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0009787896287450938\n",
      "step: 213, acc: 0.906, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009787800485474905\n",
      "step: 214, acc: 0.867, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009787704685374234\n",
      "step: 215, acc: 0.914, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009787608887148868\n",
      "step: 216, acc: 0.844, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.000978751309079876\n",
      "step: 217, acc: 0.898, loss: 0.411 (data_loss: 0.411, reg_loss: 0.000), lr: 0.0009787417296323847\n",
      "step: 218, acc: 0.844, loss: 0.472 (data_loss: 0.472, reg_loss: 0.000), lr: 0.0009787321503724076\n",
      "step: 219, acc: 0.875, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.0009787225712999392\n",
      "step: 220, acc: 0.922, loss: 0.382 (data_loss: 0.382, reg_loss: 0.000), lr: 0.0009787129924149743\n",
      "step: 221, acc: 0.914, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009787034137175071\n",
      "step: 222, acc: 0.812, loss: 0.486 (data_loss: 0.486, reg_loss: 0.000), lr: 0.000978693835207532\n",
      "step: 223, acc: 0.875, loss: 0.436 (data_loss: 0.436, reg_loss: 0.000), lr: 0.000978684256885044\n",
      "step: 224, acc: 0.844, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009786746787500368\n",
      "step: 225, acc: 0.789, loss: 0.608 (data_loss: 0.608, reg_loss: 0.000), lr: 0.0009786651008025053\n",
      "step: 226, acc: 0.844, loss: 0.447 (data_loss: 0.447, reg_loss: 0.000), lr: 0.0009786555230424441\n",
      "step: 227, acc: 0.883, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.000978645945469848\n",
      "step: 228, acc: 0.812, loss: 0.532 (data_loss: 0.532, reg_loss: 0.000), lr: 0.0009786363680847109\n",
      "step: 229, acc: 0.898, loss: 0.455 (data_loss: 0.455, reg_loss: 0.000), lr: 0.0009786267908870271\n",
      "step: 230, acc: 0.875, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009786172138767921\n",
      "step: 231, acc: 0.883, loss: 0.361 (data_loss: 0.361, reg_loss: 0.000), lr: 0.0009786076370539997\n",
      "step: 232, acc: 0.930, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009785980604186443\n",
      "step: 233, acc: 0.891, loss: 0.488 (data_loss: 0.488, reg_loss: 0.000), lr: 0.0009785884839707208\n",
      "step: 234, acc: 0.914, loss: 0.457 (data_loss: 0.457, reg_loss: 0.000), lr: 0.0009785789077102233\n",
      "step: 235, acc: 0.867, loss: 0.487 (data_loss: 0.487, reg_loss: 0.000), lr: 0.0009785693316371464\n",
      "step: 236, acc: 0.891, loss: 0.430 (data_loss: 0.430, reg_loss: 0.000), lr: 0.000978559755751485\n",
      "step: 237, acc: 0.914, loss: 0.341 (data_loss: 0.341, reg_loss: 0.000), lr: 0.0009785501800532333\n",
      "step: 238, acc: 0.906, loss: 0.337 (data_loss: 0.337, reg_loss: 0.000), lr: 0.0009785406045423855\n",
      "step: 239, acc: 0.914, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.0009785310292189364\n",
      "step: 240, acc: 0.891, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009785214540828809\n",
      "step: 241, acc: 0.883, loss: 0.484 (data_loss: 0.484, reg_loss: 0.000), lr: 0.0009785118791342127\n",
      "step: 242, acc: 0.930, loss: 0.314 (data_loss: 0.314, reg_loss: 0.000), lr: 0.0009785023043729268\n",
      "step: 243, acc: 0.914, loss: 0.337 (data_loss: 0.337, reg_loss: 0.000), lr: 0.0009784927297990175\n",
      "step: 244, acc: 0.898, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0009784831554124796\n",
      "step: 245, acc: 0.867, loss: 0.491 (data_loss: 0.491, reg_loss: 0.000), lr: 0.0009784735812133072\n",
      "step: 246, acc: 0.914, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.000978464007201495\n",
      "step: 247, acc: 0.875, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009784544333770377\n",
      "step: 248, acc: 0.906, loss: 0.443 (data_loss: 0.443, reg_loss: 0.000), lr: 0.0009784448597399294\n",
      "step: 249, acc: 0.867, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.0009784352862901647\n",
      "step: 250, acc: 0.875, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009784257130277386\n",
      "step: 251, acc: 0.906, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009784161399526447\n",
      "step: 252, acc: 0.906, loss: 0.361 (data_loss: 0.361, reg_loss: 0.000), lr: 0.0009784065670648782\n",
      "step: 253, acc: 0.930, loss: 0.349 (data_loss: 0.349, reg_loss: 0.000), lr: 0.000978396994364433\n",
      "step: 254, acc: 0.875, loss: 0.477 (data_loss: 0.477, reg_loss: 0.000), lr: 0.0009783874218513048\n",
      "step: 255, acc: 0.891, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009783778495254867\n",
      "step: 256, acc: 0.859, loss: 0.407 (data_loss: 0.407, reg_loss: 0.000), lr: 0.000978368277386974\n",
      "step: 257, acc: 0.859, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.0009783587054357612\n",
      "step: 258, acc: 0.930, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009783491336718421\n",
      "step: 259, acc: 0.891, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009783395620952121\n",
      "step: 260, acc: 0.852, loss: 0.500 (data_loss: 0.500, reg_loss: 0.000), lr: 0.0009783299907058652\n",
      "step: 261, acc: 0.938, loss: 0.345 (data_loss: 0.345, reg_loss: 0.000), lr: 0.0009783204195037958\n",
      "step: 262, acc: 0.914, loss: 0.409 (data_loss: 0.409, reg_loss: 0.000), lr: 0.000978310848488999\n",
      "step: 263, acc: 0.867, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0009783012776614687\n",
      "step: 264, acc: 0.867, loss: 0.466 (data_loss: 0.466, reg_loss: 0.000), lr: 0.0009782917070211997\n",
      "step: 265, acc: 0.914, loss: 0.429 (data_loss: 0.429, reg_loss: 0.000), lr: 0.0009782821365681863\n",
      "step: 266, acc: 0.898, loss: 0.556 (data_loss: 0.556, reg_loss: 0.000), lr: 0.0009782725663024232\n",
      "step: 267, acc: 0.898, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.000978262996223905\n",
      "step: 268, acc: 0.836, loss: 0.611 (data_loss: 0.611, reg_loss: 0.000), lr: 0.0009782534263326258\n",
      "step: 269, acc: 0.883, loss: 0.420 (data_loss: 0.420, reg_loss: 0.000), lr: 0.0009782438566285803\n",
      "step: 270, acc: 0.891, loss: 0.440 (data_loss: 0.440, reg_loss: 0.000), lr: 0.0009782342871117633\n",
      "step: 271, acc: 0.867, loss: 0.411 (data_loss: 0.411, reg_loss: 0.000), lr: 0.000978224717782169\n",
      "step: 272, acc: 0.867, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.0009782151486397918\n",
      "step: 273, acc: 0.898, loss: 0.349 (data_loss: 0.349, reg_loss: 0.000), lr: 0.0009782055796846265\n",
      "step: 274, acc: 0.867, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009781960109166675\n",
      "step: 275, acc: 0.820, loss: 0.555 (data_loss: 0.555, reg_loss: 0.000), lr: 0.0009781864423359092\n",
      "step: 276, acc: 0.875, loss: 0.443 (data_loss: 0.443, reg_loss: 0.000), lr: 0.0009781768739423463\n",
      "step: 277, acc: 0.867, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009781673057359733\n",
      "step: 278, acc: 0.906, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.0009781577377167843\n",
      "step: 279, acc: 0.883, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.000978148169884774\n",
      "step: 280, acc: 0.906, loss: 0.440 (data_loss: 0.440, reg_loss: 0.000), lr: 0.0009781386022399373\n",
      "step: 281, acc: 0.891, loss: 0.455 (data_loss: 0.455, reg_loss: 0.000), lr: 0.0009781290347822685\n",
      "step: 282, acc: 0.906, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.000978119467511762\n",
      "step: 283, acc: 0.859, loss: 0.489 (data_loss: 0.489, reg_loss: 0.000), lr: 0.0009781099004284122\n",
      "step: 284, acc: 0.898, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0009781003335322138\n",
      "step: 285, acc: 0.938, loss: 0.277 (data_loss: 0.277, reg_loss: 0.000), lr: 0.0009780907668231612\n",
      "step: 286, acc: 0.898, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.0009780812003012491\n",
      "step: 287, acc: 0.852, loss: 0.534 (data_loss: 0.534, reg_loss: 0.000), lr: 0.0009780716339664716\n",
      "step: 288, acc: 0.930, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.000978062067818824\n",
      "step: 289, acc: 0.906, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009780525018582998\n",
      "step: 290, acc: 0.906, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.000978042936084894\n",
      "step: 291, acc: 0.852, loss: 0.457 (data_loss: 0.457, reg_loss: 0.000), lr: 0.0009780333704986015\n",
      "step: 292, acc: 0.914, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009780238050994161\n",
      "step: 293, acc: 0.906, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000), lr: 0.0009780142398873328\n",
      "step: 294, acc: 0.852, loss: 0.489 (data_loss: 0.489, reg_loss: 0.000), lr: 0.0009780046748623461\n",
      "step: 295, acc: 0.914, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.00097799511002445\n",
      "step: 296, acc: 0.883, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009779855453736393\n",
      "step: 297, acc: 0.875, loss: 0.479 (data_loss: 0.479, reg_loss: 0.000), lr: 0.0009779759809099087\n",
      "step: 298, acc: 0.914, loss: 0.375 (data_loss: 0.375, reg_loss: 0.000), lr: 0.0009779664166332529\n",
      "step: 299, acc: 0.961, loss: 0.327 (data_loss: 0.327, reg_loss: 0.000), lr: 0.0009779568525436657\n",
      "step: 300, acc: 0.906, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009779472886411423\n",
      "step: 301, acc: 0.883, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009779377249256767\n",
      "step: 302, acc: 0.891, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.000977928161397264\n",
      "step: 303, acc: 0.875, loss: 0.396 (data_loss: 0.396, reg_loss: 0.000), lr: 0.0009779185980558977\n",
      "step: 304, acc: 0.898, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009779090349015733\n",
      "step: 305, acc: 0.883, loss: 0.407 (data_loss: 0.407, reg_loss: 0.000), lr: 0.0009778994719342852\n",
      "step: 306, acc: 0.891, loss: 0.409 (data_loss: 0.409, reg_loss: 0.000), lr: 0.0009778899091540275\n",
      "step: 307, acc: 0.922, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.0009778803465607948\n",
      "step: 308, acc: 0.867, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009778707841545818\n",
      "step: 309, acc: 0.867, loss: 0.464 (data_loss: 0.464, reg_loss: 0.000), lr: 0.000977861221935383\n",
      "step: 310, acc: 0.914, loss: 0.358 (data_loss: 0.358, reg_loss: 0.000), lr: 0.0009778516599031927\n",
      "step: 311, acc: 0.883, loss: 0.443 (data_loss: 0.443, reg_loss: 0.000), lr: 0.0009778420980580058\n",
      "step: 312, acc: 0.852, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009778325363998162\n",
      "step: 313, acc: 0.859, loss: 0.418 (data_loss: 0.418, reg_loss: 0.000), lr: 0.0009778229749286189\n",
      "step: 314, acc: 0.922, loss: 0.322 (data_loss: 0.322, reg_loss: 0.000), lr: 0.0009778134136444083\n",
      "step: 315, acc: 0.891, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.000977803852547179\n",
      "step: 316, acc: 0.906, loss: 0.323 (data_loss: 0.323, reg_loss: 0.000), lr: 0.0009777942916369255\n",
      "step: 317, acc: 0.883, loss: 0.331 (data_loss: 0.331, reg_loss: 0.000), lr: 0.0009777847309136419\n",
      "step: 318, acc: 0.922, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.0009777751703773235\n",
      "step: 319, acc: 0.930, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.0009777656100279641\n",
      "step: 320, acc: 0.883, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.0009777560498655585\n",
      "step: 321, acc: 0.859, loss: 0.458 (data_loss: 0.458, reg_loss: 0.000), lr: 0.0009777464898901014\n",
      "step: 322, acc: 0.891, loss: 0.411 (data_loss: 0.411, reg_loss: 0.000), lr: 0.000977736930101587\n",
      "step: 323, acc: 0.891, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009777273705000099\n",
      "step: 324, acc: 0.875, loss: 0.472 (data_loss: 0.472, reg_loss: 0.000), lr: 0.0009777178110853646\n",
      "step: 325, acc: 0.883, loss: 0.478 (data_loss: 0.478, reg_loss: 0.000), lr: 0.0009777082518576457\n",
      "step: 326, acc: 0.875, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009776986928168477\n",
      "step: 327, acc: 0.883, loss: 0.448 (data_loss: 0.448, reg_loss: 0.000), lr: 0.0009776891339629652\n",
      "step: 328, acc: 0.883, loss: 0.442 (data_loss: 0.442, reg_loss: 0.000), lr: 0.0009776795752959927\n",
      "step: 329, acc: 0.922, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.0009776700168159244\n",
      "step: 330, acc: 0.898, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.000977660458522755\n",
      "step: 331, acc: 0.867, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.0009776509004164793\n",
      "step: 332, acc: 0.891, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009776413424970917\n",
      "step: 333, acc: 0.891, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009776317847645863\n",
      "step: 334, acc: 0.859, loss: 0.498 (data_loss: 0.498, reg_loss: 0.000), lr: 0.000977622227218958\n",
      "step: 335, acc: 0.914, loss: 0.344 (data_loss: 0.344, reg_loss: 0.000), lr: 0.0009776126698602015\n",
      "step: 336, acc: 0.914, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000), lr: 0.0009776031126883108\n",
      "step: 337, acc: 0.898, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009775935557032808\n",
      "step: 338, acc: 0.922, loss: 0.271 (data_loss: 0.271, reg_loss: 0.000), lr: 0.0009775839989051062\n",
      "step: 339, acc: 0.875, loss: 0.443 (data_loss: 0.443, reg_loss: 0.000), lr: 0.0009775744422937807\n",
      "step: 340, acc: 0.930, loss: 0.312 (data_loss: 0.312, reg_loss: 0.000), lr: 0.0009775648858692996\n",
      "step: 341, acc: 0.820, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.000977555329631657\n",
      "step: 342, acc: 0.867, loss: 0.429 (data_loss: 0.429, reg_loss: 0.000), lr: 0.000977545773580848\n",
      "step: 343, acc: 0.891, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0009775362177168664\n",
      "step: 344, acc: 0.883, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0009775266620397072\n",
      "step: 345, acc: 0.898, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.0009775171065493648\n",
      "step: 346, acc: 0.828, loss: 0.452 (data_loss: 0.452, reg_loss: 0.000), lr: 0.0009775075512458336\n",
      "step: 347, acc: 0.922, loss: 0.307 (data_loss: 0.307, reg_loss: 0.000), lr: 0.000977497996129108\n",
      "step: 348, acc: 0.844, loss: 0.481 (data_loss: 0.481, reg_loss: 0.000), lr: 0.0009774884411991828\n",
      "step: 349, acc: 0.859, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009774788864560526\n",
      "step: 350, acc: 0.852, loss: 0.459 (data_loss: 0.459, reg_loss: 0.000), lr: 0.0009774693318997116\n",
      "step: 351, acc: 0.914, loss: 0.348 (data_loss: 0.348, reg_loss: 0.000), lr: 0.0009774597775301546\n",
      "step: 352, acc: 0.883, loss: 0.396 (data_loss: 0.396, reg_loss: 0.000), lr: 0.0009774502233473761\n",
      "step: 353, acc: 0.844, loss: 0.474 (data_loss: 0.474, reg_loss: 0.000), lr: 0.0009774406693513703\n",
      "step: 354, acc: 0.883, loss: 0.485 (data_loss: 0.485, reg_loss: 0.000), lr: 0.0009774311155421322\n",
      "step: 355, acc: 0.922, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.000977421561919656\n",
      "step: 356, acc: 0.875, loss: 0.488 (data_loss: 0.488, reg_loss: 0.000), lr: 0.0009774120084839362\n",
      "step: 357, acc: 0.883, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.0009774024552349676\n",
      "step: 358, acc: 0.906, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009773929021727444\n",
      "step: 359, acc: 0.898, loss: 0.328 (data_loss: 0.328, reg_loss: 0.000), lr: 0.0009773833492972615\n",
      "step: 360, acc: 0.852, loss: 0.440 (data_loss: 0.440, reg_loss: 0.000), lr: 0.0009773737966085128\n",
      "step: 361, acc: 0.914, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009773642441064936\n",
      "step: 362, acc: 0.898, loss: 0.321 (data_loss: 0.321, reg_loss: 0.000), lr: 0.000977354691791198\n",
      "step: 363, acc: 0.828, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.0009773451396626206\n",
      "step: 364, acc: 0.859, loss: 0.466 (data_loss: 0.466, reg_loss: 0.000), lr: 0.0009773355877207557\n",
      "step: 365, acc: 0.867, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.000977326035965598\n",
      "step: 366, acc: 0.859, loss: 0.443 (data_loss: 0.443, reg_loss: 0.000), lr: 0.0009773164843971424\n",
      "step: 367, acc: 0.922, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.0009773069330153827\n",
      "step: 368, acc: 0.906, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.000977297381820314\n",
      "step: 369, acc: 0.875, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009772878308119308\n",
      "step: 370, acc: 0.859, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.0009772782799902272\n",
      "step: 371, acc: 0.906, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.000977268729355198\n",
      "step: 372, acc: 0.906, loss: 0.336 (data_loss: 0.336, reg_loss: 0.000), lr: 0.000977259178906838\n",
      "step: 373, acc: 0.922, loss: 0.321 (data_loss: 0.321, reg_loss: 0.000), lr: 0.0009772496286451413\n",
      "step: 374, acc: 0.922, loss: 0.326 (data_loss: 0.326, reg_loss: 0.000), lr: 0.0009772400785701023\n",
      "step: 375, acc: 0.914, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.000977230528681716\n",
      "step: 376, acc: 0.898, loss: 0.396 (data_loss: 0.396, reg_loss: 0.000), lr: 0.000977220978979977\n",
      "step: 377, acc: 0.922, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.000977211429464879\n",
      "step: 378, acc: 0.875, loss: 0.376 (data_loss: 0.376, reg_loss: 0.000), lr: 0.0009772018801364173\n",
      "step: 379, acc: 0.867, loss: 0.422 (data_loss: 0.422, reg_loss: 0.000), lr: 0.0009771923309945865\n",
      "step: 380, acc: 0.891, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009771827820393806\n",
      "step: 381, acc: 0.906, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009771732332707942\n",
      "step: 382, acc: 0.914, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000), lr: 0.0009771636846888224\n",
      "step: 383, acc: 0.898, loss: 0.415 (data_loss: 0.415, reg_loss: 0.000), lr: 0.000977154136293459\n",
      "step: 384, acc: 0.867, loss: 0.437 (data_loss: 0.437, reg_loss: 0.000), lr: 0.0009771445880846989\n",
      "step: 385, acc: 0.898, loss: 0.337 (data_loss: 0.337, reg_loss: 0.000), lr: 0.0009771350400625367\n",
      "step: 386, acc: 0.859, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.0009771254922269668\n",
      "step: 387, acc: 0.930, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.0009771159445779837\n",
      "step: 388, acc: 0.891, loss: 0.375 (data_loss: 0.375, reg_loss: 0.000), lr: 0.000977106397115582\n",
      "step: 389, acc: 0.891, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009770968498397563\n",
      "step: 390, acc: 0.900, loss: 0.274 (data_loss: 0.274, reg_loss: 0.000), lr: 0.0009770873027505008\n",
      "training, acc: 0.886, loss: 0.422 (data_loss: 0.422, reg_loss: 0.000), lr: 0.0009770873027505008\n",
      "validation, acc: 0.892, loss: 0.392\n",
      "epoch: 7\n",
      "step: 0, acc: 0.859, loss: 0.514 (data_loss: 0.514, reg_loss: 0.000), lr: 0.0009770777558478104\n",
      "step: 1, acc: 0.852, loss: 0.500 (data_loss: 0.500, reg_loss: 0.000), lr: 0.0009770682091316794\n",
      "step: 2, acc: 0.883, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009770586626021028\n",
      "step: 3, acc: 0.906, loss: 0.341 (data_loss: 0.341, reg_loss: 0.000), lr: 0.0009770491162590744\n",
      "step: 4, acc: 0.922, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009770395701025891\n",
      "step: 5, acc: 0.891, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.0009770300241326417\n",
      "step: 6, acc: 0.906, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.0009770204783492262\n",
      "step: 7, acc: 0.930, loss: 0.309 (data_loss: 0.309, reg_loss: 0.000), lr: 0.0009770109327523373\n",
      "step: 8, acc: 0.906, loss: 0.447 (data_loss: 0.447, reg_loss: 0.000), lr: 0.0009770013873419703\n",
      "step: 9, acc: 0.938, loss: 0.344 (data_loss: 0.344, reg_loss: 0.000), lr: 0.0009769918421181185\n",
      "step: 10, acc: 0.922, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009769822970807768\n",
      "step: 11, acc: 0.867, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.0009769727522299402\n",
      "step: 12, acc: 0.883, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.0009769632075656031\n",
      "step: 13, acc: 0.867, loss: 0.458 (data_loss: 0.458, reg_loss: 0.000), lr: 0.0009769536630877599\n",
      "step: 14, acc: 0.883, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.0009769441187964048\n",
      "step: 15, acc: 0.906, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.0009769345746915331\n",
      "step: 16, acc: 0.922, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009769250307731386\n",
      "step: 17, acc: 0.891, loss: 0.364 (data_loss: 0.364, reg_loss: 0.000), lr: 0.000976915487041216\n",
      "step: 18, acc: 0.906, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009769059434957602\n",
      "step: 19, acc: 0.883, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009768964001367656\n",
      "step: 20, acc: 0.867, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009768868569642263\n",
      "step: 21, acc: 0.859, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.0009768773139781375\n",
      "step: 22, acc: 0.930, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.0009768677711784934\n",
      "step: 23, acc: 0.852, loss: 0.455 (data_loss: 0.455, reg_loss: 0.000), lr: 0.0009768582285652884\n",
      "step: 24, acc: 0.891, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000), lr: 0.000976848686138517\n",
      "step: 25, acc: 0.922, loss: 0.312 (data_loss: 0.312, reg_loss: 0.000), lr: 0.0009768391438981744\n",
      "step: 26, acc: 0.906, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009768296018442544\n",
      "step: 27, acc: 0.906, loss: 0.350 (data_loss: 0.350, reg_loss: 0.000), lr: 0.0009768200599767516\n",
      "step: 28, acc: 0.914, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000), lr: 0.000976810518295661\n",
      "step: 29, acc: 0.898, loss: 0.393 (data_loss: 0.393, reg_loss: 0.000), lr: 0.0009768009768009768\n",
      "step: 30, acc: 0.891, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009767914354926936\n",
      "step: 31, acc: 0.906, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009767818943708058\n",
      "step: 32, acc: 0.906, loss: 0.344 (data_loss: 0.344, reg_loss: 0.000), lr: 0.0009767723534353085\n",
      "step: 33, acc: 0.867, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.0009767628126861954\n",
      "step: 34, acc: 0.914, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009767532721234615\n",
      "step: 35, acc: 0.875, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.0009767437317471015\n",
      "step: 36, acc: 0.914, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.0009767341915571097\n",
      "step: 37, acc: 0.875, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009767246515534807\n",
      "step: 38, acc: 0.852, loss: 0.411 (data_loss: 0.411, reg_loss: 0.000), lr: 0.0009767151117362088\n",
      "step: 39, acc: 0.875, loss: 0.490 (data_loss: 0.490, reg_loss: 0.000), lr: 0.000976705572105289\n",
      "step: 40, acc: 0.898, loss: 0.356 (data_loss: 0.356, reg_loss: 0.000), lr: 0.0009766960326607155\n",
      "step: 41, acc: 0.906, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009766864934024828\n",
      "step: 42, acc: 0.852, loss: 0.448 (data_loss: 0.448, reg_loss: 0.000), lr: 0.0009766769543305856\n",
      "step: 43, acc: 0.875, loss: 0.376 (data_loss: 0.376, reg_loss: 0.000), lr: 0.0009766674154450185\n",
      "step: 44, acc: 0.906, loss: 0.440 (data_loss: 0.440, reg_loss: 0.000), lr: 0.000976657876745776\n",
      "step: 45, acc: 0.898, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009766483382328524\n",
      "step: 46, acc: 0.898, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0009766387999062427\n",
      "step: 47, acc: 0.883, loss: 0.414 (data_loss: 0.414, reg_loss: 0.000), lr: 0.000976629261765941\n",
      "step: 48, acc: 0.922, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.000976619723811942\n",
      "step: 49, acc: 0.914, loss: 0.315 (data_loss: 0.315, reg_loss: 0.000), lr: 0.0009766101860442405\n",
      "step: 50, acc: 0.914, loss: 0.414 (data_loss: 0.414, reg_loss: 0.000), lr: 0.0009766006484628305\n",
      "step: 51, acc: 0.906, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.000976591111067707\n",
      "step: 52, acc: 0.891, loss: 0.458 (data_loss: 0.458, reg_loss: 0.000), lr: 0.0009765815738588645\n",
      "step: 53, acc: 0.828, loss: 0.507 (data_loss: 0.507, reg_loss: 0.000), lr: 0.0009765720368362972\n",
      "step: 54, acc: 0.883, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.0009765625\n",
      "step: 55, acc: 0.883, loss: 0.475 (data_loss: 0.475, reg_loss: 0.000), lr: 0.0009765529633499673\n",
      "step: 56, acc: 0.898, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009765434268861937\n",
      "step: 57, acc: 0.930, loss: 0.331 (data_loss: 0.331, reg_loss: 0.000), lr: 0.0009765338906086736\n",
      "step: 58, acc: 0.891, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009765243545174016\n",
      "step: 59, acc: 0.883, loss: 0.390 (data_loss: 0.390, reg_loss: 0.000), lr: 0.0009765148186123726\n",
      "step: 60, acc: 0.898, loss: 0.427 (data_loss: 0.427, reg_loss: 0.000), lr: 0.0009765052828935805\n",
      "step: 61, acc: 0.906, loss: 0.364 (data_loss: 0.364, reg_loss: 0.000), lr: 0.0009764957473610202\n",
      "step: 62, acc: 0.891, loss: 0.320 (data_loss: 0.320, reg_loss: 0.000), lr: 0.0009764862120146862\n",
      "step: 63, acc: 0.867, loss: 0.452 (data_loss: 0.452, reg_loss: 0.000), lr: 0.0009764766768545735\n",
      "step: 64, acc: 0.867, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.0009764671418806758\n",
      "step: 65, acc: 0.836, loss: 0.517 (data_loss: 0.517, reg_loss: 0.000), lr: 0.000976457607092988\n",
      "step: 66, acc: 0.930, loss: 0.399 (data_loss: 0.399, reg_loss: 0.000), lr: 0.000976448072491505\n",
      "step: 67, acc: 0.844, loss: 0.473 (data_loss: 0.473, reg_loss: 0.000), lr: 0.0009764385380762209\n",
      "step: 68, acc: 0.875, loss: 0.414 (data_loss: 0.414, reg_loss: 0.000), lr: 0.0009764290038471303\n",
      "step: 69, acc: 0.867, loss: 0.407 (data_loss: 0.407, reg_loss: 0.000), lr: 0.000976419469804228\n",
      "step: 70, acc: 0.906, loss: 0.327 (data_loss: 0.327, reg_loss: 0.000), lr: 0.0009764099359475082\n",
      "step: 71, acc: 0.914, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.0009764004022769657\n",
      "step: 72, acc: 0.914, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.000976390868792595\n",
      "step: 73, acc: 0.953, loss: 0.259 (data_loss: 0.259, reg_loss: 0.000), lr: 0.0009763813354943907\n",
      "step: 74, acc: 0.891, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0009763718023823473\n",
      "step: 75, acc: 0.867, loss: 0.430 (data_loss: 0.430, reg_loss: 0.000), lr: 0.0009763622694564591\n",
      "step: 76, acc: 0.914, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.000976352736716721\n",
      "step: 77, acc: 0.938, loss: 0.315 (data_loss: 0.315, reg_loss: 0.000), lr: 0.0009763432041631274\n",
      "step: 78, acc: 0.875, loss: 0.451 (data_loss: 0.451, reg_loss: 0.000), lr: 0.0009763336717956729\n",
      "step: 79, acc: 0.875, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.0009763241396143519\n",
      "step: 80, acc: 0.875, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0009763146076191592\n",
      "step: 81, acc: 0.867, loss: 0.409 (data_loss: 0.409, reg_loss: 0.000), lr: 0.0009763050758100891\n",
      "step: 82, acc: 0.930, loss: 0.307 (data_loss: 0.307, reg_loss: 0.000), lr: 0.0009762955441871363\n",
      "step: 83, acc: 0.820, loss: 0.469 (data_loss: 0.469, reg_loss: 0.000), lr: 0.0009762860127502954\n",
      "step: 84, acc: 0.859, loss: 0.487 (data_loss: 0.487, reg_loss: 0.000), lr: 0.0009762764814995607\n",
      "step: 85, acc: 0.883, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009762669504349269\n",
      "step: 86, acc: 0.898, loss: 0.491 (data_loss: 0.491, reg_loss: 0.000), lr: 0.0009762574195563887\n",
      "step: 87, acc: 0.906, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.0009762478888639403\n",
      "step: 88, acc: 0.867, loss: 0.571 (data_loss: 0.571, reg_loss: 0.000), lr: 0.0009762383583575766\n",
      "step: 89, acc: 0.922, loss: 0.344 (data_loss: 0.344, reg_loss: 0.000), lr: 0.0009762288280372918\n",
      "step: 90, acc: 0.914, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.0009762192979030811\n",
      "step: 91, acc: 0.906, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009762097679549382\n",
      "step: 92, acc: 0.914, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.0009762002381928581\n",
      "step: 93, acc: 0.875, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009761907086168355\n",
      "step: 94, acc: 0.922, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009761811792268646\n",
      "step: 95, acc: 0.867, loss: 0.547 (data_loss: 0.547, reg_loss: 0.000), lr: 0.0009761716500229401\n",
      "step: 96, acc: 0.891, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009761621210050564\n",
      "step: 97, acc: 0.898, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.0009761525921732086\n",
      "step: 98, acc: 0.844, loss: 0.484 (data_loss: 0.484, reg_loss: 0.000), lr: 0.0009761430635273906\n",
      "step: 99, acc: 0.914, loss: 0.358 (data_loss: 0.358, reg_loss: 0.000), lr: 0.0009761335350675971\n",
      "step: 100, acc: 0.906, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009761240067938232\n",
      "step: 101, acc: 0.906, loss: 0.496 (data_loss: 0.496, reg_loss: 0.000), lr: 0.0009761144787060627\n",
      "step: 102, acc: 0.898, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009761049508043105\n",
      "step: 103, acc: 0.883, loss: 0.497 (data_loss: 0.497, reg_loss: 0.000), lr: 0.0009760954230885612\n",
      "step: 104, acc: 0.875, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.0009760858955588092\n",
      "step: 105, acc: 0.891, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.000976076368215049\n",
      "step: 106, acc: 0.875, loss: 0.334 (data_loss: 0.334, reg_loss: 0.000), lr: 0.0009760668410572755\n",
      "step: 107, acc: 0.859, loss: 0.497 (data_loss: 0.497, reg_loss: 0.000), lr: 0.0009760573140854831\n",
      "step: 108, acc: 0.891, loss: 0.364 (data_loss: 0.364, reg_loss: 0.000), lr: 0.0009760477872996663\n",
      "step: 109, acc: 0.914, loss: 0.350 (data_loss: 0.350, reg_loss: 0.000), lr: 0.0009760382606998194\n",
      "step: 110, acc: 0.969, loss: 0.258 (data_loss: 0.258, reg_loss: 0.000), lr: 0.0009760287342859375\n",
      "step: 111, acc: 0.875, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009760192080580146\n",
      "step: 112, acc: 0.906, loss: 0.416 (data_loss: 0.416, reg_loss: 0.000), lr: 0.0009760096820160455\n",
      "step: 113, acc: 0.891, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009760001561600251\n",
      "step: 114, acc: 0.883, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009759906304899474\n",
      "step: 115, acc: 0.930, loss: 0.324 (data_loss: 0.324, reg_loss: 0.000), lr: 0.000975981105005807\n",
      "step: 116, acc: 0.859, loss: 0.489 (data_loss: 0.489, reg_loss: 0.000), lr: 0.0009759715797075988\n",
      "step: 117, acc: 0.883, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.0009759620545953174\n",
      "step: 118, acc: 0.906, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.000975952529668957\n",
      "step: 119, acc: 0.922, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009759430049285122\n",
      "step: 120, acc: 0.922, loss: 0.286 (data_loss: 0.286, reg_loss: 0.000), lr: 0.0009759334803739778\n",
      "step: 121, acc: 0.883, loss: 0.409 (data_loss: 0.409, reg_loss: 0.000), lr: 0.0009759239560053481\n",
      "step: 122, acc: 0.898, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.0009759144318226177\n",
      "step: 123, acc: 0.859, loss: 0.519 (data_loss: 0.519, reg_loss: 0.000), lr: 0.0009759049078257813\n",
      "step: 124, acc: 0.844, loss: 0.447 (data_loss: 0.447, reg_loss: 0.000), lr: 0.0009758953840148337\n",
      "step: 125, acc: 0.867, loss: 0.363 (data_loss: 0.363, reg_loss: 0.000), lr: 0.0009758858603897688\n",
      "step: 126, acc: 0.898, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009758763369505816\n",
      "step: 127, acc: 0.898, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000), lr: 0.0009758668136972667\n",
      "step: 128, acc: 0.836, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.0009758572906298183\n",
      "step: 129, acc: 0.914, loss: 0.292 (data_loss: 0.292, reg_loss: 0.000), lr: 0.0009758477677482313\n",
      "step: 130, acc: 0.820, loss: 0.522 (data_loss: 0.522, reg_loss: 0.000), lr: 0.0009758382450525001\n",
      "step: 131, acc: 0.836, loss: 0.535 (data_loss: 0.535, reg_loss: 0.000), lr: 0.0009758287225426194\n",
      "step: 132, acc: 0.906, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.0009758192002185835\n",
      "step: 133, acc: 0.883, loss: 0.358 (data_loss: 0.358, reg_loss: 0.000), lr: 0.0009758096780803871\n",
      "step: 134, acc: 0.930, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.0009758001561280251\n",
      "step: 135, acc: 0.922, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.0009757906343614914\n",
      "step: 136, acc: 0.891, loss: 0.369 (data_loss: 0.369, reg_loss: 0.000), lr: 0.0009757811127807809\n",
      "step: 137, acc: 0.930, loss: 0.274 (data_loss: 0.274, reg_loss: 0.000), lr: 0.0009757715913858885\n",
      "step: 138, acc: 0.898, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009757620701768082\n",
      "step: 139, acc: 0.859, loss: 0.422 (data_loss: 0.422, reg_loss: 0.000), lr: 0.0009757525491535346\n",
      "step: 140, acc: 0.914, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009757430283160627\n",
      "step: 141, acc: 0.875, loss: 0.442 (data_loss: 0.442, reg_loss: 0.000), lr: 0.0009757335076643868\n",
      "step: 142, acc: 0.953, loss: 0.276 (data_loss: 0.276, reg_loss: 0.000), lr: 0.0009757239871985013\n",
      "step: 143, acc: 0.930, loss: 0.328 (data_loss: 0.328, reg_loss: 0.000), lr: 0.0009757144669184009\n",
      "step: 144, acc: 0.891, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009757049468240805\n",
      "step: 145, acc: 0.867, loss: 0.369 (data_loss: 0.369, reg_loss: 0.000), lr: 0.000975695426915534\n",
      "step: 146, acc: 0.898, loss: 0.516 (data_loss: 0.516, reg_loss: 0.000), lr: 0.0009756859071927565\n",
      "step: 147, acc: 0.828, loss: 0.504 (data_loss: 0.504, reg_loss: 0.000), lr: 0.0009756763876557425\n",
      "step: 148, acc: 0.883, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0009756668683044862\n",
      "step: 149, acc: 0.930, loss: 0.305 (data_loss: 0.305, reg_loss: 0.000), lr: 0.0009756573491389824\n",
      "step: 150, acc: 0.883, loss: 0.348 (data_loss: 0.348, reg_loss: 0.000), lr: 0.0009756478301592256\n",
      "step: 151, acc: 0.914, loss: 0.336 (data_loss: 0.336, reg_loss: 0.000), lr: 0.0009756383113652108\n",
      "step: 152, acc: 0.898, loss: 0.407 (data_loss: 0.407, reg_loss: 0.000), lr: 0.0009756287927569318\n",
      "step: 153, acc: 0.867, loss: 0.460 (data_loss: 0.460, reg_loss: 0.000), lr: 0.0009756192743343837\n",
      "step: 154, acc: 0.906, loss: 0.325 (data_loss: 0.325, reg_loss: 0.000), lr: 0.0009756097560975611\n",
      "step: 155, acc: 0.914, loss: 0.331 (data_loss: 0.331, reg_loss: 0.000), lr: 0.0009756002380464582\n",
      "step: 156, acc: 0.906, loss: 0.336 (data_loss: 0.336, reg_loss: 0.000), lr: 0.0009755907201810696\n",
      "step: 157, acc: 0.891, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009755812025013901\n",
      "step: 158, acc: 0.898, loss: 0.483 (data_loss: 0.483, reg_loss: 0.000), lr: 0.0009755716850074145\n",
      "step: 159, acc: 0.906, loss: 0.399 (data_loss: 0.399, reg_loss: 0.000), lr: 0.0009755621676991366\n",
      "step: 160, acc: 0.891, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000), lr: 0.0009755526505765515\n",
      "step: 161, acc: 0.891, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.000975543133639654\n",
      "step: 162, acc: 0.898, loss: 0.429 (data_loss: 0.429, reg_loss: 0.000), lr: 0.000975533616888438\n",
      "step: 163, acc: 0.891, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.0009755241003228984\n",
      "step: 164, acc: 0.922, loss: 0.280 (data_loss: 0.280, reg_loss: 0.000), lr: 0.00097551458394303\n",
      "step: 165, acc: 0.875, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.0009755050677488269\n",
      "step: 166, acc: 0.852, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.000975495551740284\n",
      "step: 167, acc: 0.883, loss: 0.416 (data_loss: 0.416, reg_loss: 0.000), lr: 0.0009754860359173958\n",
      "step: 168, acc: 0.867, loss: 0.523 (data_loss: 0.523, reg_loss: 0.000), lr: 0.000975476520280157\n",
      "step: 169, acc: 0.930, loss: 0.335 (data_loss: 0.335, reg_loss: 0.000), lr: 0.0009754670048285616\n",
      "step: 170, acc: 0.883, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.0009754574895626049\n",
      "step: 171, acc: 0.898, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.0009754479744822811\n",
      "step: 172, acc: 0.844, loss: 0.474 (data_loss: 0.474, reg_loss: 0.000), lr: 0.0009754384595875847\n",
      "step: 173, acc: 0.875, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.0009754289448785103\n",
      "step: 174, acc: 0.844, loss: 0.451 (data_loss: 0.451, reg_loss: 0.000), lr: 0.0009754194303550525\n",
      "step: 175, acc: 0.906, loss: 0.419 (data_loss: 0.419, reg_loss: 0.000), lr: 0.0009754099160172063\n",
      "step: 176, acc: 0.898, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.0009754004018649656\n",
      "step: 177, acc: 0.875, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009753908878983252\n",
      "step: 178, acc: 0.898, loss: 0.492 (data_loss: 0.492, reg_loss: 0.000), lr: 0.0009753813741172799\n",
      "step: 179, acc: 0.891, loss: 0.443 (data_loss: 0.443, reg_loss: 0.000), lr: 0.0009753718605218239\n",
      "step: 180, acc: 0.891, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.000975362347111952\n",
      "step: 181, acc: 0.930, loss: 0.299 (data_loss: 0.299, reg_loss: 0.000), lr: 0.000975352833887659\n",
      "step: 182, acc: 0.906, loss: 0.361 (data_loss: 0.361, reg_loss: 0.000), lr: 0.0009753433208489388\n",
      "step: 183, acc: 0.852, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009753338079957865\n",
      "step: 184, acc: 0.891, loss: 0.411 (data_loss: 0.411, reg_loss: 0.000), lr: 0.0009753242953281965\n",
      "step: 185, acc: 0.875, loss: 0.436 (data_loss: 0.436, reg_loss: 0.000), lr: 0.0009753147828461637\n",
      "step: 186, acc: 0.852, loss: 0.436 (data_loss: 0.436, reg_loss: 0.000), lr: 0.0009753052705496821\n",
      "step: 187, acc: 0.867, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.0009752957584387465\n",
      "step: 188, acc: 0.953, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.0009752862465133517\n",
      "step: 189, acc: 0.906, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.000975276734773492\n",
      "step: 190, acc: 0.867, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.000975267223219162\n",
      "step: 191, acc: 0.906, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.0009752577118503564\n",
      "step: 192, acc: 0.938, loss: 0.218 (data_loss: 0.218, reg_loss: 0.000), lr: 0.0009752482006670698\n",
      "step: 193, acc: 0.891, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009752386896692965\n",
      "step: 194, acc: 0.859, loss: 0.501 (data_loss: 0.501, reg_loss: 0.000), lr: 0.0009752291788570314\n",
      "step: 195, acc: 0.938, loss: 0.375 (data_loss: 0.375, reg_loss: 0.000), lr: 0.000975219668230269\n",
      "step: 196, acc: 0.891, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.0009752101577890036\n",
      "step: 197, acc: 0.906, loss: 0.337 (data_loss: 0.337, reg_loss: 0.000), lr: 0.0009752006475332299\n",
      "step: 198, acc: 0.867, loss: 0.502 (data_loss: 0.502, reg_loss: 0.000), lr: 0.0009751911374629429\n",
      "step: 199, acc: 0.930, loss: 0.322 (data_loss: 0.322, reg_loss: 0.000), lr: 0.0009751816275781365\n",
      "step: 200, acc: 0.891, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009751721178788055\n",
      "step: 201, acc: 0.828, loss: 0.521 (data_loss: 0.521, reg_loss: 0.000), lr: 0.0009751626083649447\n",
      "step: 202, acc: 0.875, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009751530990365488\n",
      "step: 203, acc: 0.883, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009751435898936119\n",
      "step: 204, acc: 0.961, loss: 0.234 (data_loss: 0.234, reg_loss: 0.000), lr: 0.0009751340809361287\n",
      "step: 205, acc: 0.906, loss: 0.321 (data_loss: 0.321, reg_loss: 0.000), lr: 0.0009751245721640941\n",
      "step: 206, acc: 0.859, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0009751150635775021\n",
      "step: 207, acc: 0.898, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009751055551763478\n",
      "step: 208, acc: 0.891, loss: 0.407 (data_loss: 0.407, reg_loss: 0.000), lr: 0.0009750960469606257\n",
      "step: 209, acc: 0.859, loss: 0.493 (data_loss: 0.493, reg_loss: 0.000), lr: 0.0009750865389303302\n",
      "step: 210, acc: 0.883, loss: 0.418 (data_loss: 0.418, reg_loss: 0.000), lr: 0.0009750770310854558\n",
      "step: 211, acc: 0.930, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000), lr: 0.0009750675234259971\n",
      "step: 212, acc: 0.914, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009750580159519492\n",
      "step: 213, acc: 0.906, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000), lr: 0.000975048508663306\n",
      "step: 214, acc: 0.867, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009750390015600623\n",
      "step: 215, acc: 0.906, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.000975029494642213\n",
      "step: 216, acc: 0.867, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.0009750199879097522\n",
      "step: 217, acc: 0.898, loss: 0.376 (data_loss: 0.376, reg_loss: 0.000), lr: 0.0009750104813626747\n",
      "step: 218, acc: 0.844, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.000975000975000975\n",
      "step: 219, acc: 0.883, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009749914688246479\n",
      "step: 220, acc: 0.922, loss: 0.350 (data_loss: 0.350, reg_loss: 0.000), lr: 0.0009749819628336875\n",
      "step: 221, acc: 0.914, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.0009749724570280889\n",
      "step: 222, acc: 0.828, loss: 0.451 (data_loss: 0.451, reg_loss: 0.000), lr: 0.0009749629514078466\n",
      "step: 223, acc: 0.875, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.0009749534459729547\n",
      "step: 224, acc: 0.859, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009749439407234084\n",
      "step: 225, acc: 0.789, loss: 0.577 (data_loss: 0.577, reg_loss: 0.000), lr: 0.0009749344356592021\n",
      "step: 226, acc: 0.836, loss: 0.422 (data_loss: 0.422, reg_loss: 0.000), lr: 0.0009749249307803299\n",
      "step: 227, acc: 0.891, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.000974915426086787\n",
      "step: 228, acc: 0.836, loss: 0.513 (data_loss: 0.513, reg_loss: 0.000), lr: 0.0009749059215785676\n",
      "step: 229, acc: 0.898, loss: 0.430 (data_loss: 0.430, reg_loss: 0.000), lr: 0.0009748964172556667\n",
      "step: 230, acc: 0.883, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009748869131180783\n",
      "step: 231, acc: 0.891, loss: 0.334 (data_loss: 0.334, reg_loss: 0.000), lr: 0.0009748774091657974\n",
      "step: 232, acc: 0.938, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009748679053988186\n",
      "step: 233, acc: 0.891, loss: 0.454 (data_loss: 0.454, reg_loss: 0.000), lr: 0.0009748584018171361\n",
      "step: 234, acc: 0.914, loss: 0.427 (data_loss: 0.427, reg_loss: 0.000), lr: 0.0009748488984207448\n",
      "step: 235, acc: 0.875, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.0009748393952096391\n",
      "step: 236, acc: 0.898, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.000974829892183814\n",
      "step: 237, acc: 0.930, loss: 0.312 (data_loss: 0.312, reg_loss: 0.000), lr: 0.0009748203893432635\n",
      "step: 238, acc: 0.906, loss: 0.305 (data_loss: 0.305, reg_loss: 0.000), lr: 0.0009748108866879825\n",
      "step: 239, acc: 0.930, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009748013842179657\n",
      "step: 240, acc: 0.891, loss: 0.324 (data_loss: 0.324, reg_loss: 0.000), lr: 0.0009747918819332074\n",
      "step: 241, acc: 0.883, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.0009747823798337021\n",
      "step: 242, acc: 0.930, loss: 0.288 (data_loss: 0.288, reg_loss: 0.000), lr: 0.0009747728779194449\n",
      "step: 243, acc: 0.922, loss: 0.316 (data_loss: 0.316, reg_loss: 0.000), lr: 0.0009747633761904298\n",
      "step: 244, acc: 0.898, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.0009747538746466516\n",
      "step: 245, acc: 0.883, loss: 0.460 (data_loss: 0.460, reg_loss: 0.000), lr: 0.0009747443732881051\n",
      "step: 246, acc: 0.930, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.0009747348721147848\n",
      "step: 247, acc: 0.883, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.000974725371126685\n",
      "step: 248, acc: 0.883, loss: 0.419 (data_loss: 0.419, reg_loss: 0.000), lr: 0.0009747158703238006\n",
      "step: 249, acc: 0.867, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009747063697061262\n",
      "step: 250, acc: 0.883, loss: 0.349 (data_loss: 0.349, reg_loss: 0.000), lr: 0.0009746968692736559\n",
      "step: 251, acc: 0.914, loss: 0.293 (data_loss: 0.293, reg_loss: 0.000), lr: 0.0009746873690263848\n",
      "step: 252, acc: 0.906, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009746778689643072\n",
      "step: 253, acc: 0.922, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.0009746683690874181\n",
      "step: 254, acc: 0.891, loss: 0.453 (data_loss: 0.453, reg_loss: 0.000), lr: 0.0009746588693957114\n",
      "step: 255, acc: 0.891, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.0009746493698891823\n",
      "step: 256, acc: 0.883, loss: 0.375 (data_loss: 0.375, reg_loss: 0.000), lr: 0.0009746398705678253\n",
      "step: 257, acc: 0.875, loss: 0.453 (data_loss: 0.453, reg_loss: 0.000), lr: 0.0009746303714316346\n",
      "step: 258, acc: 0.930, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009746208724806051\n",
      "step: 259, acc: 0.898, loss: 0.356 (data_loss: 0.356, reg_loss: 0.000), lr: 0.0009746113737147314\n",
      "step: 260, acc: 0.883, loss: 0.470 (data_loss: 0.470, reg_loss: 0.000), lr: 0.0009746018751340078\n",
      "step: 261, acc: 0.930, loss: 0.312 (data_loss: 0.312, reg_loss: 0.000), lr: 0.0009745923767384291\n",
      "step: 262, acc: 0.914, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.00097458287852799\n",
      "step: 263, acc: 0.875, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.0009745733805026851\n",
      "step: 264, acc: 0.883, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.0009745638826625085\n",
      "step: 265, acc: 0.930, loss: 0.399 (data_loss: 0.399, reg_loss: 0.000), lr: 0.0009745543850074553\n",
      "step: 266, acc: 0.898, loss: 0.533 (data_loss: 0.533, reg_loss: 0.000), lr: 0.00097454488753752\n",
      "step: 267, acc: 0.898, loss: 0.382 (data_loss: 0.382, reg_loss: 0.000), lr: 0.0009745353902526971\n",
      "step: 268, acc: 0.867, loss: 0.583 (data_loss: 0.583, reg_loss: 0.000), lr: 0.000974525893152981\n",
      "step: 269, acc: 0.875, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009745163962383668\n",
      "step: 270, acc: 0.891, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.0009745068995088487\n",
      "step: 271, acc: 0.859, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009744974029644211\n",
      "step: 272, acc: 0.875, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009744879066050789\n",
      "step: 273, acc: 0.898, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.000974478410430817\n",
      "step: 274, acc: 0.859, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009744689144416293\n",
      "step: 275, acc: 0.828, loss: 0.530 (data_loss: 0.530, reg_loss: 0.000), lr: 0.0009744594186375107\n",
      "step: 276, acc: 0.883, loss: 0.418 (data_loss: 0.418, reg_loss: 0.000), lr: 0.0009744499230184561\n",
      "step: 277, acc: 0.867, loss: 0.415 (data_loss: 0.415, reg_loss: 0.000), lr: 0.0009744404275844597\n",
      "step: 278, acc: 0.914, loss: 0.340 (data_loss: 0.340, reg_loss: 0.000), lr: 0.0009744309323355161\n",
      "step: 279, acc: 0.891, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009744214372716199\n",
      "step: 280, acc: 0.906, loss: 0.416 (data_loss: 0.416, reg_loss: 0.000), lr: 0.0009744119423927659\n",
      "step: 281, acc: 0.891, loss: 0.427 (data_loss: 0.427, reg_loss: 0.000), lr: 0.0009744024476989486\n",
      "step: 282, acc: 0.898, loss: 0.363 (data_loss: 0.363, reg_loss: 0.000), lr: 0.0009743929531901626\n",
      "step: 283, acc: 0.867, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.0009743834588664023\n",
      "step: 284, acc: 0.914, loss: 0.340 (data_loss: 0.340, reg_loss: 0.000), lr: 0.0009743739647276625\n",
      "step: 285, acc: 0.938, loss: 0.255 (data_loss: 0.255, reg_loss: 0.000), lr: 0.0009743644707739377\n",
      "step: 286, acc: 0.891, loss: 0.289 (data_loss: 0.289, reg_loss: 0.000), lr: 0.0009743549770052227\n",
      "step: 287, acc: 0.859, loss: 0.506 (data_loss: 0.506, reg_loss: 0.000), lr: 0.0009743454834215116\n",
      "step: 288, acc: 0.930, loss: 0.356 (data_loss: 0.356, reg_loss: 0.000), lr: 0.0009743359900227995\n",
      "step: 289, acc: 0.906, loss: 0.349 (data_loss: 0.349, reg_loss: 0.000), lr: 0.0009743264968090807\n",
      "step: 290, acc: 0.906, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.00097431700378035\n",
      "step: 291, acc: 0.867, loss: 0.425 (data_loss: 0.425, reg_loss: 0.000), lr: 0.0009743075109366018\n",
      "step: 292, acc: 0.922, loss: 0.382 (data_loss: 0.382, reg_loss: 0.000), lr: 0.0009742980182778308\n",
      "step: 293, acc: 0.922, loss: 0.275 (data_loss: 0.275, reg_loss: 0.000), lr: 0.0009742885258040317\n",
      "step: 294, acc: 0.859, loss: 0.464 (data_loss: 0.464, reg_loss: 0.000), lr: 0.0009742790335151987\n",
      "step: 295, acc: 0.914, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.0009742695414113268\n",
      "step: 296, acc: 0.891, loss: 0.354 (data_loss: 0.354, reg_loss: 0.000), lr: 0.0009742600494924104\n",
      "step: 297, acc: 0.875, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.0009742505577584444\n",
      "step: 298, acc: 0.914, loss: 0.340 (data_loss: 0.340, reg_loss: 0.000), lr: 0.0009742410662094229\n",
      "step: 299, acc: 0.945, loss: 0.296 (data_loss: 0.296, reg_loss: 0.000), lr: 0.0009742315748453406\n",
      "step: 300, acc: 0.906, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009742220836661925\n",
      "step: 301, acc: 0.898, loss: 0.363 (data_loss: 0.363, reg_loss: 0.000), lr: 0.0009742125926719729\n",
      "step: 302, acc: 0.891, loss: 0.393 (data_loss: 0.393, reg_loss: 0.000), lr: 0.0009742031018626763\n",
      "step: 303, acc: 0.891, loss: 0.366 (data_loss: 0.366, reg_loss: 0.000), lr: 0.0009741936112382976\n",
      "step: 304, acc: 0.906, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000), lr: 0.000974184120798831\n",
      "step: 305, acc: 0.898, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.0009741746305442714\n",
      "step: 306, acc: 0.906, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009741651404746131\n",
      "step: 307, acc: 0.922, loss: 0.316 (data_loss: 0.316, reg_loss: 0.000), lr: 0.0009741556505898513\n",
      "step: 308, acc: 0.883, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.00097414616088998\n",
      "step: 309, acc: 0.867, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0009741366713749938\n",
      "step: 310, acc: 0.914, loss: 0.331 (data_loss: 0.331, reg_loss: 0.000), lr: 0.0009741271820448879\n",
      "step: 311, acc: 0.898, loss: 0.419 (data_loss: 0.419, reg_loss: 0.000), lr: 0.0009741176928996561\n",
      "step: 312, acc: 0.859, loss: 0.416 (data_loss: 0.416, reg_loss: 0.000), lr: 0.0009741082039392935\n",
      "step: 313, acc: 0.867, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009740987151637946\n",
      "step: 314, acc: 0.938, loss: 0.293 (data_loss: 0.293, reg_loss: 0.000), lr: 0.0009740892265731541\n",
      "step: 315, acc: 0.906, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.0009740797381673664\n",
      "step: 316, acc: 0.922, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.0009740702499464261\n",
      "step: 317, acc: 0.906, loss: 0.301 (data_loss: 0.301, reg_loss: 0.000), lr: 0.000974060761910328\n",
      "step: 318, acc: 0.922, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.0009740512740590664\n",
      "step: 319, acc: 0.922, loss: 0.328 (data_loss: 0.328, reg_loss: 0.000), lr: 0.0009740417863926362\n",
      "step: 320, acc: 0.883, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.000974032298911032\n",
      "step: 321, acc: 0.875, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009740228116142481\n",
      "step: 322, acc: 0.891, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009740133245022792\n",
      "step: 323, acc: 0.891, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.00097400383757512\n",
      "step: 324, acc: 0.875, loss: 0.448 (data_loss: 0.448, reg_loss: 0.000), lr: 0.0009739943508327652\n",
      "step: 325, acc: 0.891, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.0009739848642752091\n",
      "step: 326, acc: 0.891, loss: 0.354 (data_loss: 0.354, reg_loss: 0.000), lr: 0.0009739753779024466\n",
      "step: 327, acc: 0.875, loss: 0.430 (data_loss: 0.430, reg_loss: 0.000), lr: 0.0009739658917144723\n",
      "step: 328, acc: 0.898, loss: 0.416 (data_loss: 0.416, reg_loss: 0.000), lr: 0.0009739564057112804\n",
      "step: 329, acc: 0.922, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.0009739469198928658\n",
      "step: 330, acc: 0.922, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009739374342592233\n",
      "step: 331, acc: 0.883, loss: 0.429 (data_loss: 0.429, reg_loss: 0.000), lr: 0.0009739279488103471\n",
      "step: 332, acc: 0.898, loss: 0.416 (data_loss: 0.416, reg_loss: 0.000), lr: 0.0009739184635462319\n",
      "step: 333, acc: 0.914, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.0009739089784668724\n",
      "step: 334, acc: 0.875, loss: 0.465 (data_loss: 0.465, reg_loss: 0.000), lr: 0.0009738994935722633\n",
      "step: 335, acc: 0.922, loss: 0.314 (data_loss: 0.314, reg_loss: 0.000), lr: 0.0009738900088623991\n",
      "step: 336, acc: 0.922, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.0009738805243372742\n",
      "step: 337, acc: 0.906, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009738710399968838\n",
      "step: 338, acc: 0.938, loss: 0.245 (data_loss: 0.245, reg_loss: 0.000), lr: 0.0009738615558412216\n",
      "step: 339, acc: 0.875, loss: 0.414 (data_loss: 0.414, reg_loss: 0.000), lr: 0.0009738520718702829\n",
      "step: 340, acc: 0.930, loss: 0.288 (data_loss: 0.288, reg_loss: 0.000), lr: 0.000973842588084062\n",
      "step: 341, acc: 0.836, loss: 0.452 (data_loss: 0.452, reg_loss: 0.000), lr: 0.0009738331044825538\n",
      "step: 342, acc: 0.875, loss: 0.393 (data_loss: 0.393, reg_loss: 0.000), lr: 0.0009738236210657526\n",
      "step: 343, acc: 0.891, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009738141378336531\n",
      "step: 344, acc: 0.891, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009738046547862501\n",
      "step: 345, acc: 0.898, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.0009737951719235376\n",
      "step: 346, acc: 0.867, loss: 0.425 (data_loss: 0.425, reg_loss: 0.000), lr: 0.0009737856892455108\n",
      "step: 347, acc: 0.922, loss: 0.276 (data_loss: 0.276, reg_loss: 0.000), lr: 0.0009737762067521644\n",
      "step: 348, acc: 0.852, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.0009737667244434923\n",
      "step: 349, acc: 0.859, loss: 0.414 (data_loss: 0.414, reg_loss: 0.000), lr: 0.0009737572423194897\n",
      "step: 350, acc: 0.852, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.0009737477603801511\n",
      "step: 351, acc: 0.914, loss: 0.320 (data_loss: 0.320, reg_loss: 0.000), lr: 0.0009737382786254711\n",
      "step: 352, acc: 0.906, loss: 0.368 (data_loss: 0.368, reg_loss: 0.000), lr: 0.0009737287970554442\n",
      "step: 353, acc: 0.852, loss: 0.440 (data_loss: 0.440, reg_loss: 0.000), lr: 0.0009737193156700649\n",
      "step: 354, acc: 0.891, loss: 0.457 (data_loss: 0.457, reg_loss: 0.000), lr: 0.0009737098344693283\n",
      "step: 355, acc: 0.922, loss: 0.326 (data_loss: 0.326, reg_loss: 0.000), lr: 0.0009737003534532284\n",
      "step: 356, acc: 0.883, loss: 0.457 (data_loss: 0.457, reg_loss: 0.000), lr: 0.00097369087262176\n",
      "step: 357, acc: 0.891, loss: 0.315 (data_loss: 0.315, reg_loss: 0.000), lr: 0.0009736813919749179\n",
      "step: 358, acc: 0.906, loss: 0.336 (data_loss: 0.336, reg_loss: 0.000), lr: 0.0009736719115126968\n",
      "step: 359, acc: 0.922, loss: 0.298 (data_loss: 0.298, reg_loss: 0.000), lr: 0.0009736624312350907\n",
      "step: 360, acc: 0.852, loss: 0.411 (data_loss: 0.411, reg_loss: 0.000), lr: 0.0009736529511420949\n",
      "step: 361, acc: 0.914, loss: 0.354 (data_loss: 0.354, reg_loss: 0.000), lr: 0.0009736434712337038\n",
      "step: 362, acc: 0.922, loss: 0.292 (data_loss: 0.292, reg_loss: 0.000), lr: 0.0009736339915099116\n",
      "step: 363, acc: 0.844, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.0009736245119707133\n",
      "step: 364, acc: 0.852, loss: 0.448 (data_loss: 0.448, reg_loss: 0.000), lr: 0.0009736150326161038\n",
      "step: 365, acc: 0.867, loss: 0.411 (data_loss: 0.411, reg_loss: 0.000), lr: 0.0009736055534460769\n",
      "step: 366, acc: 0.859, loss: 0.412 (data_loss: 0.412, reg_loss: 0.000), lr: 0.0009735960744606278\n",
      "step: 367, acc: 0.930, loss: 0.257 (data_loss: 0.257, reg_loss: 0.000), lr: 0.0009735865956597508\n",
      "step: 368, acc: 0.914, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009735771170434411\n",
      "step: 369, acc: 0.891, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009735676386116926\n",
      "step: 370, acc: 0.883, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009735581603645001\n",
      "step: 371, acc: 0.922, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009735486823018585\n",
      "step: 372, acc: 0.914, loss: 0.306 (data_loss: 0.306, reg_loss: 0.000), lr: 0.0009735392044237623\n",
      "step: 373, acc: 0.930, loss: 0.292 (data_loss: 0.292, reg_loss: 0.000), lr: 0.0009735297267302056\n",
      "step: 374, acc: 0.930, loss: 0.300 (data_loss: 0.300, reg_loss: 0.000), lr: 0.0009735202492211838\n",
      "step: 375, acc: 0.906, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009735107718966911\n",
      "step: 376, acc: 0.906, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.000973501294756722\n",
      "step: 377, acc: 0.922, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.0009734918178012713\n",
      "step: 378, acc: 0.875, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000), lr: 0.0009734823410303339\n",
      "step: 379, acc: 0.875, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009734728644439037\n",
      "step: 380, acc: 0.906, loss: 0.418 (data_loss: 0.418, reg_loss: 0.000), lr: 0.0009734633880419757\n",
      "step: 381, acc: 0.898, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009734539118245448\n",
      "step: 382, acc: 0.914, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.000973444435791605\n",
      "step: 383, acc: 0.898, loss: 0.390 (data_loss: 0.390, reg_loss: 0.000), lr: 0.0009734349599431514\n",
      "step: 384, acc: 0.898, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009734254842791783\n",
      "step: 385, acc: 0.898, loss: 0.312 (data_loss: 0.312, reg_loss: 0.000), lr: 0.0009734160087996809\n",
      "step: 386, acc: 0.852, loss: 0.420 (data_loss: 0.420, reg_loss: 0.000), lr: 0.0009734065335046529\n",
      "step: 387, acc: 0.930, loss: 0.279 (data_loss: 0.279, reg_loss: 0.000), lr: 0.0009733970583940895\n",
      "step: 388, acc: 0.891, loss: 0.354 (data_loss: 0.354, reg_loss: 0.000), lr: 0.0009733875834679854\n",
      "step: 389, acc: 0.891, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.0009733781087263348\n",
      "step: 390, acc: 0.900, loss: 0.246 (data_loss: 0.246, reg_loss: 0.000), lr: 0.0009733686341691324\n",
      "training, acc: 0.893, loss: 0.390 (data_loss: 0.390, reg_loss: 0.000), lr: 0.0009733686341691324\n",
      "validation, acc: 0.898, loss: 0.367\n",
      "epoch: 8\n",
      "step: 0, acc: 0.859, loss: 0.493 (data_loss: 0.493, reg_loss: 0.000), lr: 0.0009733591597963733\n",
      "step: 1, acc: 0.867, loss: 0.472 (data_loss: 0.472, reg_loss: 0.000), lr: 0.0009733496856080515\n",
      "step: 2, acc: 0.883, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.000973340211604162\n",
      "step: 3, acc: 0.906, loss: 0.315 (data_loss: 0.315, reg_loss: 0.000), lr: 0.0009733307377846991\n",
      "step: 4, acc: 0.930, loss: 0.334 (data_loss: 0.334, reg_loss: 0.000), lr: 0.000973321264149658\n",
      "step: 5, acc: 0.891, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009733117906990325\n",
      "step: 6, acc: 0.922, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009733023174328178\n",
      "step: 7, acc: 0.930, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.0009732928443510084\n",
      "step: 8, acc: 0.906, loss: 0.425 (data_loss: 0.425, reg_loss: 0.000), lr: 0.0009732833714535988\n",
      "step: 9, acc: 0.945, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.0009732738987405836\n",
      "step: 10, acc: 0.938, loss: 0.336 (data_loss: 0.336, reg_loss: 0.000), lr: 0.0009732644262119574\n",
      "step: 11, acc: 0.891, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.0009732549538677152\n",
      "step: 12, acc: 0.891, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009732454817078512\n",
      "step: 13, acc: 0.891, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.00097323600973236\n",
      "step: 14, acc: 0.875, loss: 0.382 (data_loss: 0.382, reg_loss: 0.000), lr: 0.0009732265379412367\n",
      "step: 15, acc: 0.906, loss: 0.288 (data_loss: 0.288, reg_loss: 0.000), lr: 0.0009732170663344753\n",
      "step: 16, acc: 0.930, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0009732075949120707\n",
      "step: 17, acc: 0.898, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.0009731981236740177\n",
      "step: 18, acc: 0.906, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.0009731886526203105\n",
      "step: 19, acc: 0.898, loss: 0.349 (data_loss: 0.349, reg_loss: 0.000), lr: 0.000973179181750944\n",
      "step: 20, acc: 0.875, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009731697110659127\n",
      "step: 21, acc: 0.867, loss: 0.454 (data_loss: 0.454, reg_loss: 0.000), lr: 0.0009731602405652116\n",
      "step: 22, acc: 0.930, loss: 0.270 (data_loss: 0.270, reg_loss: 0.000), lr: 0.0009731507702488346\n",
      "step: 23, acc: 0.859, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009731413001167769\n",
      "step: 24, acc: 0.891, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.000973131830169033\n",
      "step: 25, acc: 0.930, loss: 0.285 (data_loss: 0.285, reg_loss: 0.000), lr: 0.0009731223604055974\n",
      "step: 26, acc: 0.914, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.0009731128908264647\n",
      "step: 27, acc: 0.906, loss: 0.322 (data_loss: 0.322, reg_loss: 0.000), lr: 0.0009731034214316296\n",
      "step: 28, acc: 0.922, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000), lr: 0.000973093952221087\n",
      "step: 29, acc: 0.914, loss: 0.368 (data_loss: 0.368, reg_loss: 0.000), lr: 0.000973084483194831\n",
      "step: 30, acc: 0.906, loss: 0.382 (data_loss: 0.382, reg_loss: 0.000), lr: 0.0009730750143528564\n",
      "step: 31, acc: 0.906, loss: 0.420 (data_loss: 0.420, reg_loss: 0.000), lr: 0.0009730655456951582\n",
      "step: 32, acc: 0.914, loss: 0.320 (data_loss: 0.320, reg_loss: 0.000), lr: 0.0009730560772217302\n",
      "step: 33, acc: 0.867, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.0009730466089325678\n",
      "step: 34, acc: 0.922, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.0009730371408276654\n",
      "step: 35, acc: 0.891, loss: 0.375 (data_loss: 0.375, reg_loss: 0.000), lr: 0.0009730276729070175\n",
      "step: 36, acc: 0.906, loss: 0.327 (data_loss: 0.327, reg_loss: 0.000), lr: 0.0009730182051706187\n",
      "step: 37, acc: 0.875, loss: 0.368 (data_loss: 0.368, reg_loss: 0.000), lr: 0.0009730087376184637\n",
      "step: 38, acc: 0.852, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009729992702505473\n",
      "step: 39, acc: 0.875, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.0009729898030668639\n",
      "step: 40, acc: 0.891, loss: 0.335 (data_loss: 0.335, reg_loss: 0.000), lr: 0.000972980336067408\n",
      "step: 41, acc: 0.906, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.0009729708692521747\n",
      "step: 42, acc: 0.867, loss: 0.425 (data_loss: 0.425, reg_loss: 0.000), lr: 0.000972961402621158\n",
      "step: 43, acc: 0.891, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.000972951936174353\n",
      "step: 44, acc: 0.906, loss: 0.415 (data_loss: 0.415, reg_loss: 0.000), lr: 0.000972942469911754\n",
      "step: 45, acc: 0.891, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009729330038333561\n",
      "step: 46, acc: 0.914, loss: 0.412 (data_loss: 0.412, reg_loss: 0.000), lr: 0.0009729235379391533\n",
      "step: 47, acc: 0.875, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.0009729140722291406\n",
      "step: 48, acc: 0.922, loss: 0.312 (data_loss: 0.312, reg_loss: 0.000), lr: 0.0009729046067033128\n",
      "step: 49, acc: 0.922, loss: 0.282 (data_loss: 0.282, reg_loss: 0.000), lr: 0.000972895141361664\n",
      "step: 50, acc: 0.914, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009728856762041893\n",
      "step: 51, acc: 0.922, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.0009728762112308831\n",
      "step: 52, acc: 0.891, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009728667464417399\n",
      "step: 53, acc: 0.844, loss: 0.473 (data_loss: 0.473, reg_loss: 0.000), lr: 0.0009728572818367545\n",
      "step: 54, acc: 0.891, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009728478174159215\n",
      "step: 55, acc: 0.883, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009728383531792358\n",
      "step: 56, acc: 0.898, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.0009728288891266916\n",
      "step: 57, acc: 0.938, loss: 0.309 (data_loss: 0.309, reg_loss: 0.000), lr: 0.0009728194252582834\n",
      "step: 58, acc: 0.891, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.0009728099615740066\n",
      "step: 59, acc: 0.898, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009728004980738551\n",
      "step: 60, acc: 0.898, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.0009727910347578235\n",
      "step: 61, acc: 0.914, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.0009727815716259072\n",
      "step: 62, acc: 0.906, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.0009727721086781\n",
      "step: 63, acc: 0.867, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009727626459143969\n",
      "step: 64, acc: 0.875, loss: 0.460 (data_loss: 0.460, reg_loss: 0.000), lr: 0.0009727531833347924\n",
      "step: 65, acc: 0.852, loss: 0.484 (data_loss: 0.484, reg_loss: 0.000), lr: 0.0009727437209392815\n",
      "step: 66, acc: 0.938, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009727342587278581\n",
      "step: 67, acc: 0.859, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009727247967005175\n",
      "step: 68, acc: 0.875, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009727153348572542\n",
      "step: 69, acc: 0.875, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009727058731980624\n",
      "step: 70, acc: 0.922, loss: 0.305 (data_loss: 0.305, reg_loss: 0.000), lr: 0.0009726964117229371\n",
      "step: 71, acc: 0.930, loss: 0.314 (data_loss: 0.314, reg_loss: 0.000), lr: 0.0009726869504318729\n",
      "step: 72, acc: 0.914, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.0009726774893248646\n",
      "step: 73, acc: 0.961, loss: 0.231 (data_loss: 0.231, reg_loss: 0.000), lr: 0.0009726680284019065\n",
      "step: 74, acc: 0.891, loss: 0.408 (data_loss: 0.408, reg_loss: 0.000), lr: 0.0009726585676629932\n",
      "step: 75, acc: 0.875, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.0009726491071081197\n",
      "step: 76, acc: 0.922, loss: 0.305 (data_loss: 0.305, reg_loss: 0.000), lr: 0.0009726396467372803\n",
      "step: 77, acc: 0.938, loss: 0.297 (data_loss: 0.297, reg_loss: 0.000), lr: 0.0009726301865504698\n",
      "step: 78, acc: 0.883, loss: 0.430 (data_loss: 0.430, reg_loss: 0.000), lr: 0.0009726207265476829\n",
      "step: 79, acc: 0.891, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0009726112667289139\n",
      "step: 80, acc: 0.883, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009726018070941576\n",
      "step: 81, acc: 0.875, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009725923476434086\n",
      "step: 82, acc: 0.938, loss: 0.282 (data_loss: 0.282, reg_loss: 0.000), lr: 0.000972582888376662\n",
      "step: 83, acc: 0.828, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009725734292939116\n",
      "step: 84, acc: 0.867, loss: 0.458 (data_loss: 0.458, reg_loss: 0.000), lr: 0.0009725639703951527\n",
      "step: 85, acc: 0.891, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.0009725545116803797\n",
      "step: 86, acc: 0.898, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.0009725450531495872\n",
      "step: 87, acc: 0.914, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009725355948027697\n",
      "step: 88, acc: 0.883, loss: 0.548 (data_loss: 0.548, reg_loss: 0.000), lr: 0.0009725261366399221\n",
      "step: 89, acc: 0.922, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.0009725166786610391\n",
      "step: 90, acc: 0.914, loss: 0.309 (data_loss: 0.309, reg_loss: 0.000), lr: 0.000972507220866115\n",
      "step: 91, acc: 0.906, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.0009724977632551445\n",
      "step: 92, acc: 0.914, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.0009724883058281226\n",
      "step: 93, acc: 0.883, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0009724788485850433\n",
      "step: 94, acc: 0.922, loss: 0.348 (data_loss: 0.348, reg_loss: 0.000), lr: 0.0009724693915259017\n",
      "step: 95, acc: 0.867, loss: 0.523 (data_loss: 0.523, reg_loss: 0.000), lr: 0.0009724599346506925\n",
      "step: 96, acc: 0.891, loss: 0.327 (data_loss: 0.327, reg_loss: 0.000), lr: 0.00097245047795941\n",
      "step: 97, acc: 0.906, loss: 0.306 (data_loss: 0.306, reg_loss: 0.000), lr: 0.0009724410214520489\n",
      "step: 98, acc: 0.844, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.000972431565128604\n",
      "step: 99, acc: 0.898, loss: 0.331 (data_loss: 0.331, reg_loss: 0.000), lr: 0.0009724221089890701\n",
      "step: 100, acc: 0.930, loss: 0.326 (data_loss: 0.326, reg_loss: 0.000), lr: 0.0009724126530334413\n",
      "step: 101, acc: 0.906, loss: 0.490 (data_loss: 0.490, reg_loss: 0.000), lr: 0.0009724031972617125\n",
      "step: 102, acc: 0.914, loss: 0.335 (data_loss: 0.335, reg_loss: 0.000), lr: 0.0009723937416738788\n",
      "step: 103, acc: 0.883, loss: 0.466 (data_loss: 0.466, reg_loss: 0.000), lr: 0.0009723842862699339\n",
      "step: 104, acc: 0.891, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009723748310498731\n",
      "step: 105, acc: 0.898, loss: 0.305 (data_loss: 0.305, reg_loss: 0.000), lr: 0.0009723653760136908\n",
      "step: 106, acc: 0.883, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.0009723559211613819\n",
      "step: 107, acc: 0.859, loss: 0.462 (data_loss: 0.462, reg_loss: 0.000), lr: 0.0009723464664929408\n",
      "step: 108, acc: 0.906, loss: 0.340 (data_loss: 0.340, reg_loss: 0.000), lr: 0.000972337012008362\n",
      "step: 109, acc: 0.914, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009723275577076406\n",
      "step: 110, acc: 0.977, loss: 0.231 (data_loss: 0.231, reg_loss: 0.000), lr: 0.0009723181035907707\n",
      "step: 111, acc: 0.875, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009723086496577474\n",
      "step: 112, acc: 0.906, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009722991959085651\n",
      "step: 113, acc: 0.891, loss: 0.334 (data_loss: 0.334, reg_loss: 0.000), lr: 0.0009722897423432184\n",
      "step: 114, acc: 0.875, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009722802889617019\n",
      "step: 115, acc: 0.938, loss: 0.299 (data_loss: 0.299, reg_loss: 0.000), lr: 0.0009722708357640103\n",
      "step: 116, acc: 0.852, loss: 0.467 (data_loss: 0.467, reg_loss: 0.000), lr: 0.0009722613827501386\n",
      "step: 117, acc: 0.891, loss: 0.327 (data_loss: 0.327, reg_loss: 0.000), lr: 0.000972251929920081\n",
      "step: 118, acc: 0.906, loss: 0.327 (data_loss: 0.327, reg_loss: 0.000), lr: 0.0009722424772738321\n",
      "step: 119, acc: 0.930, loss: 0.348 (data_loss: 0.348, reg_loss: 0.000), lr: 0.0009722330248113869\n",
      "step: 120, acc: 0.930, loss: 0.263 (data_loss: 0.263, reg_loss: 0.000), lr: 0.0009722235725327397\n",
      "step: 121, acc: 0.883, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009722141204378852\n",
      "step: 122, acc: 0.898, loss: 0.464 (data_loss: 0.464, reg_loss: 0.000), lr: 0.0009722046685268185\n",
      "step: 123, acc: 0.867, loss: 0.499 (data_loss: 0.499, reg_loss: 0.000), lr: 0.0009721952167995334\n",
      "step: 124, acc: 0.852, loss: 0.430 (data_loss: 0.430, reg_loss: 0.000), lr: 0.0009721857652560251\n",
      "step: 125, acc: 0.875, loss: 0.332 (data_loss: 0.332, reg_loss: 0.000), lr: 0.0009721763138962881\n",
      "step: 126, acc: 0.930, loss: 0.323 (data_loss: 0.323, reg_loss: 0.000), lr: 0.0009721668627203174\n",
      "step: 127, acc: 0.906, loss: 0.323 (data_loss: 0.323, reg_loss: 0.000), lr: 0.000972157411728107\n",
      "step: 128, acc: 0.836, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0009721479609196519\n",
      "step: 129, acc: 0.922, loss: 0.265 (data_loss: 0.265, reg_loss: 0.000), lr: 0.0009721385102949469\n",
      "step: 130, acc: 0.820, loss: 0.497 (data_loss: 0.497, reg_loss: 0.000), lr: 0.0009721290598539862\n",
      "step: 131, acc: 0.852, loss: 0.512 (data_loss: 0.512, reg_loss: 0.000), lr: 0.0009721196095967648\n",
      "step: 132, acc: 0.906, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.0009721101595232771\n",
      "step: 133, acc: 0.891, loss: 0.334 (data_loss: 0.334, reg_loss: 0.000), lr: 0.0009721007096335181\n",
      "step: 134, acc: 0.938, loss: 0.289 (data_loss: 0.289, reg_loss: 0.000), lr: 0.000972091259927482\n",
      "step: 135, acc: 0.922, loss: 0.291 (data_loss: 0.291, reg_loss: 0.000), lr: 0.0009720818104051636\n",
      "step: 136, acc: 0.891, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.000972072361066558\n",
      "step: 137, acc: 0.938, loss: 0.255 (data_loss: 0.255, reg_loss: 0.000), lr: 0.0009720629119116589\n",
      "step: 138, acc: 0.906, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.0009720534629404617\n",
      "step: 139, acc: 0.859, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.000972044014152961\n",
      "step: 140, acc: 0.914, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.0009720345655491509\n",
      "step: 141, acc: 0.891, loss: 0.423 (data_loss: 0.423, reg_loss: 0.000), lr: 0.0009720251171290266\n",
      "step: 142, acc: 0.953, loss: 0.255 (data_loss: 0.255, reg_loss: 0.000), lr: 0.0009720156688925825\n",
      "step: 143, acc: 0.930, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000), lr: 0.0009720062208398135\n",
      "step: 144, acc: 0.891, loss: 0.419 (data_loss: 0.419, reg_loss: 0.000), lr: 0.0009719967729707137\n",
      "step: 145, acc: 0.883, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009719873252852782\n",
      "step: 146, acc: 0.898, loss: 0.497 (data_loss: 0.497, reg_loss: 0.000), lr: 0.0009719778777835018\n",
      "step: 147, acc: 0.844, loss: 0.483 (data_loss: 0.483, reg_loss: 0.000), lr: 0.0009719684304653785\n",
      "step: 148, acc: 0.898, loss: 0.412 (data_loss: 0.412, reg_loss: 0.000), lr: 0.0009719589833309033\n",
      "step: 149, acc: 0.930, loss: 0.280 (data_loss: 0.280, reg_loss: 0.000), lr: 0.0009719495363800711\n",
      "step: 150, acc: 0.883, loss: 0.324 (data_loss: 0.324, reg_loss: 0.000), lr: 0.0009719400896128763\n",
      "step: 151, acc: 0.922, loss: 0.310 (data_loss: 0.310, reg_loss: 0.000), lr: 0.0009719306430293135\n",
      "step: 152, acc: 0.914, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009719211966293773\n",
      "step: 153, acc: 0.883, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009719117504130625\n",
      "step: 154, acc: 0.914, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000), lr: 0.0009719023043803638\n",
      "step: 155, acc: 0.922, loss: 0.307 (data_loss: 0.307, reg_loss: 0.000), lr: 0.0009718928585312755\n",
      "step: 156, acc: 0.906, loss: 0.306 (data_loss: 0.306, reg_loss: 0.000), lr: 0.0009718834128657928\n",
      "step: 157, acc: 0.883, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009718739673839097\n",
      "step: 158, acc: 0.906, loss: 0.459 (data_loss: 0.459, reg_loss: 0.000), lr: 0.0009718645220856213\n",
      "step: 159, acc: 0.906, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000), lr: 0.000971855076970922\n",
      "step: 160, acc: 0.898, loss: 0.321 (data_loss: 0.321, reg_loss: 0.000), lr: 0.0009718456320398069\n",
      "step: 161, acc: 0.891, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.00097183618729227\n",
      "step: 162, acc: 0.914, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009718267427283064\n",
      "step: 163, acc: 0.898, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009718172983479106\n",
      "step: 164, acc: 0.930, loss: 0.257 (data_loss: 0.257, reg_loss: 0.000), lr: 0.0009718078541510773\n",
      "step: 165, acc: 0.891, loss: 0.315 (data_loss: 0.315, reg_loss: 0.000), lr: 0.0009717984101378011\n",
      "step: 166, acc: 0.852, loss: 0.434 (data_loss: 0.434, reg_loss: 0.000), lr: 0.0009717889663080764\n",
      "step: 167, acc: 0.906, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009717795226618986\n",
      "step: 168, acc: 0.898, loss: 0.499 (data_loss: 0.499, reg_loss: 0.000), lr: 0.0009717700791992615\n",
      "step: 169, acc: 0.930, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009717606359201601\n",
      "step: 170, acc: 0.883, loss: 0.442 (data_loss: 0.442, reg_loss: 0.000), lr: 0.0009717511928245893\n",
      "step: 171, acc: 0.898, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.0009717417499125432\n",
      "step: 172, acc: 0.852, loss: 0.454 (data_loss: 0.454, reg_loss: 0.000), lr: 0.0009717323071840169\n",
      "step: 173, acc: 0.883, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.0009717228646390051\n",
      "step: 174, acc: 0.875, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0009717134222775019\n",
      "step: 175, acc: 0.906, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.0009717039800995024\n",
      "step: 176, acc: 0.898, loss: 0.345 (data_loss: 0.345, reg_loss: 0.000), lr: 0.0009716945381050011\n",
      "step: 177, acc: 0.891, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009716850962939932\n",
      "step: 178, acc: 0.898, loss: 0.472 (data_loss: 0.472, reg_loss: 0.000), lr: 0.0009716756546664724\n",
      "step: 179, acc: 0.883, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.0009716662132224338\n",
      "step: 180, acc: 0.898, loss: 0.332 (data_loss: 0.332, reg_loss: 0.000), lr: 0.0009716567719618724\n",
      "step: 181, acc: 0.930, loss: 0.277 (data_loss: 0.277, reg_loss: 0.000), lr: 0.0009716473308847821\n",
      "step: 182, acc: 0.906, loss: 0.332 (data_loss: 0.332, reg_loss: 0.000), lr: 0.000971637889991158\n",
      "step: 183, acc: 0.867, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.000971628449280995\n",
      "step: 184, acc: 0.906, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009716190087542873\n",
      "step: 185, acc: 0.883, loss: 0.407 (data_loss: 0.407, reg_loss: 0.000), lr: 0.0009716095684110297\n",
      "step: 186, acc: 0.859, loss: 0.412 (data_loss: 0.412, reg_loss: 0.000), lr: 0.0009716001282512169\n",
      "step: 187, acc: 0.883, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009715906882748436\n",
      "step: 188, acc: 0.945, loss: 0.299 (data_loss: 0.299, reg_loss: 0.000), lr: 0.0009715812484819043\n",
      "step: 189, acc: 0.906, loss: 0.321 (data_loss: 0.321, reg_loss: 0.000), lr: 0.0009715718088723937\n",
      "step: 190, acc: 0.875, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009715623694463067\n",
      "step: 191, acc: 0.914, loss: 0.281 (data_loss: 0.281, reg_loss: 0.000), lr: 0.0009715529302036375\n",
      "step: 192, acc: 0.945, loss: 0.194 (data_loss: 0.194, reg_loss: 0.000), lr: 0.000971543491144381\n",
      "step: 193, acc: 0.891, loss: 0.412 (data_loss: 0.412, reg_loss: 0.000), lr: 0.000971534052268532\n",
      "step: 194, acc: 0.867, loss: 0.483 (data_loss: 0.483, reg_loss: 0.000), lr: 0.000971524613576085\n",
      "step: 195, acc: 0.938, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.0009715151750670346\n",
      "step: 196, acc: 0.891, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.0009715057367413755\n",
      "step: 197, acc: 0.914, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.0009714962985991023\n",
      "step: 198, acc: 0.883, loss: 0.483 (data_loss: 0.483, reg_loss: 0.000), lr: 0.0009714868606402098\n",
      "step: 199, acc: 0.938, loss: 0.301 (data_loss: 0.301, reg_loss: 0.000), lr: 0.0009714774228646927\n",
      "step: 200, acc: 0.891, loss: 0.348 (data_loss: 0.348, reg_loss: 0.000), lr: 0.0009714679852725455\n",
      "step: 201, acc: 0.844, loss: 0.498 (data_loss: 0.498, reg_loss: 0.000), lr: 0.0009714585478637627\n",
      "step: 202, acc: 0.883, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009714491106383392\n",
      "step: 203, acc: 0.906, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.0009714396735962696\n",
      "step: 204, acc: 0.961, loss: 0.209 (data_loss: 0.209, reg_loss: 0.000), lr: 0.0009714302367375489\n",
      "step: 205, acc: 0.914, loss: 0.299 (data_loss: 0.299, reg_loss: 0.000), lr: 0.0009714208000621709\n",
      "step: 206, acc: 0.859, loss: 0.407 (data_loss: 0.407, reg_loss: 0.000), lr: 0.0009714113635701311\n",
      "step: 207, acc: 0.906, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.0009714019272614239\n",
      "step: 208, acc: 0.891, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009713924911360436\n",
      "step: 209, acc: 0.859, loss: 0.482 (data_loss: 0.482, reg_loss: 0.000), lr: 0.0009713830551939852\n",
      "step: 210, acc: 0.891, loss: 0.399 (data_loss: 0.399, reg_loss: 0.000), lr: 0.0009713736194352433\n",
      "step: 211, acc: 0.922, loss: 0.316 (data_loss: 0.316, reg_loss: 0.000), lr: 0.0009713641838598127\n",
      "step: 212, acc: 0.914, loss: 0.356 (data_loss: 0.356, reg_loss: 0.000), lr: 0.0009713547484676879\n",
      "step: 213, acc: 0.914, loss: 0.358 (data_loss: 0.358, reg_loss: 0.000), lr: 0.0009713453132588635\n",
      "step: 214, acc: 0.867, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.0009713358782333344\n",
      "step: 215, acc: 0.914, loss: 0.335 (data_loss: 0.335, reg_loss: 0.000), lr: 0.0009713264433910949\n",
      "step: 216, acc: 0.867, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0009713170087321399\n",
      "step: 217, acc: 0.906, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009713075742564642\n",
      "step: 218, acc: 0.844, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.000971298139964062\n",
      "step: 219, acc: 0.883, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.0009712887058549284\n",
      "step: 220, acc: 0.922, loss: 0.327 (data_loss: 0.327, reg_loss: 0.000), lr: 0.0009712792719290577\n",
      "step: 221, acc: 0.930, loss: 0.327 (data_loss: 0.327, reg_loss: 0.000), lr: 0.000971269838186445\n",
      "step: 222, acc: 0.828, loss: 0.425 (data_loss: 0.425, reg_loss: 0.000), lr: 0.0009712604046270845\n",
      "step: 223, acc: 0.875, loss: 0.382 (data_loss: 0.382, reg_loss: 0.000), lr: 0.0009712509712509711\n",
      "step: 224, acc: 0.867, loss: 0.346 (data_loss: 0.346, reg_loss: 0.000), lr: 0.0009712415380580998\n",
      "step: 225, acc: 0.797, loss: 0.552 (data_loss: 0.552, reg_loss: 0.000), lr: 0.0009712321050484644\n",
      "step: 226, acc: 0.852, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.0009712226722220602\n",
      "step: 227, acc: 0.891, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009712132395788819\n",
      "step: 228, acc: 0.844, loss: 0.500 (data_loss: 0.500, reg_loss: 0.000), lr: 0.000971203807118924\n",
      "step: 229, acc: 0.898, loss: 0.414 (data_loss: 0.414, reg_loss: 0.000), lr: 0.0009711943748421808\n",
      "step: 230, acc: 0.898, loss: 0.361 (data_loss: 0.361, reg_loss: 0.000), lr: 0.0009711849427486475\n",
      "step: 231, acc: 0.898, loss: 0.314 (data_loss: 0.314, reg_loss: 0.000), lr: 0.0009711755108383188\n",
      "step: 232, acc: 0.938, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009711660791111888\n",
      "step: 233, acc: 0.898, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0009711566475672526\n",
      "step: 234, acc: 0.914, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0009711472162065049\n",
      "step: 235, acc: 0.883, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009711377850289399\n",
      "step: 236, acc: 0.906, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009711283540345527\n",
      "step: 237, acc: 0.922, loss: 0.293 (data_loss: 0.293, reg_loss: 0.000), lr: 0.0009711189232233378\n",
      "step: 238, acc: 0.914, loss: 0.282 (data_loss: 0.282, reg_loss: 0.000), lr: 0.0009711094925952902\n",
      "step: 239, acc: 0.938, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.000971100062150404\n",
      "step: 240, acc: 0.906, loss: 0.301 (data_loss: 0.301, reg_loss: 0.000), lr: 0.0009710906318886741\n",
      "step: 241, acc: 0.883, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.0009710812018100954\n",
      "step: 242, acc: 0.930, loss: 0.268 (data_loss: 0.268, reg_loss: 0.000), lr: 0.0009710717719146622\n",
      "step: 243, acc: 0.922, loss: 0.301 (data_loss: 0.301, reg_loss: 0.000), lr: 0.0009710623422023694\n",
      "step: 244, acc: 0.898, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009710529126732118\n",
      "step: 245, acc: 0.875, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0009710434833271834\n",
      "step: 246, acc: 0.930, loss: 0.295 (data_loss: 0.295, reg_loss: 0.000), lr: 0.0009710340541642796\n",
      "step: 247, acc: 0.891, loss: 0.332 (data_loss: 0.332, reg_loss: 0.000), lr: 0.0009710246251844947\n",
      "step: 248, acc: 0.883, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.0009710151963878235\n",
      "step: 249, acc: 0.859, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009710057677742607\n",
      "step: 250, acc: 0.883, loss: 0.331 (data_loss: 0.331, reg_loss: 0.000), lr: 0.0009709963393438006\n",
      "step: 251, acc: 0.922, loss: 0.268 (data_loss: 0.268, reg_loss: 0.000), lr: 0.0009709869110964386\n",
      "step: 252, acc: 0.922, loss: 0.306 (data_loss: 0.306, reg_loss: 0.000), lr: 0.0009709774830321684\n",
      "step: 253, acc: 0.930, loss: 0.296 (data_loss: 0.296, reg_loss: 0.000), lr: 0.0009709680551509856\n",
      "step: 254, acc: 0.891, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0009709586274528841\n",
      "step: 255, acc: 0.891, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009709491999378594\n",
      "step: 256, acc: 0.883, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.0009709397726059052\n",
      "step: 257, acc: 0.875, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009709303454570169\n",
      "step: 258, acc: 0.938, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000), lr: 0.000970920918491189\n",
      "step: 259, acc: 0.898, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.0009709114917084158\n",
      "step: 260, acc: 0.906, loss: 0.447 (data_loss: 0.447, reg_loss: 0.000), lr: 0.0009709020651086925\n",
      "step: 261, acc: 0.945, loss: 0.289 (data_loss: 0.289, reg_loss: 0.000), lr: 0.0009708926386920136\n",
      "step: 262, acc: 0.914, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009708832124583735\n",
      "step: 263, acc: 0.883, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009708737864077671\n",
      "step: 264, acc: 0.883, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009708643605401888\n",
      "step: 265, acc: 0.938, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009708549348556339\n",
      "step: 266, acc: 0.891, loss: 0.517 (data_loss: 0.517, reg_loss: 0.000), lr: 0.0009708455093540966\n",
      "step: 267, acc: 0.906, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.0009708360840355715\n",
      "step: 268, acc: 0.867, loss: 0.563 (data_loss: 0.563, reg_loss: 0.000), lr: 0.0009708266589000535\n",
      "step: 269, acc: 0.883, loss: 0.375 (data_loss: 0.375, reg_loss: 0.000), lr: 0.000970817233947537\n",
      "step: 270, acc: 0.898, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.000970807809178017\n",
      "step: 271, acc: 0.867, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.0009707983845914879\n",
      "step: 272, acc: 0.875, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009707889601879449\n",
      "step: 273, acc: 0.914, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.0009707795359673818\n",
      "step: 274, acc: 0.859, loss: 0.376 (data_loss: 0.376, reg_loss: 0.000), lr: 0.0009707701119297938\n",
      "step: 275, acc: 0.836, loss: 0.512 (data_loss: 0.512, reg_loss: 0.000), lr: 0.0009707606880751758\n",
      "step: 276, acc: 0.891, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009707512644035219\n",
      "step: 277, acc: 0.875, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.000970741840914827\n",
      "step: 278, acc: 0.930, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.0009707324176090862\n",
      "step: 279, acc: 0.891, loss: 0.396 (data_loss: 0.396, reg_loss: 0.000), lr: 0.0009707229944862934\n",
      "step: 280, acc: 0.906, loss: 0.399 (data_loss: 0.399, reg_loss: 0.000), lr: 0.0009707135715464437\n",
      "step: 281, acc: 0.914, loss: 0.407 (data_loss: 0.407, reg_loss: 0.000), lr: 0.0009707041487895319\n",
      "step: 282, acc: 0.898, loss: 0.337 (data_loss: 0.337, reg_loss: 0.000), lr: 0.0009706947262155526\n",
      "step: 283, acc: 0.883, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.0009706853038245002\n",
      "step: 284, acc: 0.914, loss: 0.316 (data_loss: 0.316, reg_loss: 0.000), lr: 0.0009706758816163695\n",
      "step: 285, acc: 0.938, loss: 0.242 (data_loss: 0.242, reg_loss: 0.000), lr: 0.0009706664595911554\n",
      "step: 286, acc: 0.914, loss: 0.269 (data_loss: 0.269, reg_loss: 0.000), lr: 0.0009706570377488523\n",
      "step: 287, acc: 0.867, loss: 0.485 (data_loss: 0.485, reg_loss: 0.000), lr: 0.0009706476160894549\n",
      "step: 288, acc: 0.930, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.0009706381946129579\n",
      "step: 289, acc: 0.906, loss: 0.332 (data_loss: 0.332, reg_loss: 0.000), lr: 0.0009706287733193564\n",
      "step: 290, acc: 0.906, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009706193522086443\n",
      "step: 291, acc: 0.867, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.0009706099312808168\n",
      "step: 292, acc: 0.922, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009706005105358686\n",
      "step: 293, acc: 0.922, loss: 0.256 (data_loss: 0.256, reg_loss: 0.000), lr: 0.0009705910899737941\n",
      "step: 294, acc: 0.867, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.0009705816695945881\n",
      "step: 295, acc: 0.930, loss: 0.408 (data_loss: 0.408, reg_loss: 0.000), lr: 0.0009705722493982453\n",
      "step: 296, acc: 0.891, loss: 0.332 (data_loss: 0.332, reg_loss: 0.000), lr: 0.0009705628293847602\n",
      "step: 297, acc: 0.883, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0009705534095541278\n",
      "step: 298, acc: 0.930, loss: 0.315 (data_loss: 0.315, reg_loss: 0.000), lr: 0.0009705439899063424\n",
      "step: 299, acc: 0.945, loss: 0.275 (data_loss: 0.275, reg_loss: 0.000), lr: 0.0009705345704413992\n",
      "step: 300, acc: 0.906, loss: 0.364 (data_loss: 0.364, reg_loss: 0.000), lr: 0.0009705251511592923\n",
      "step: 301, acc: 0.898, loss: 0.337 (data_loss: 0.337, reg_loss: 0.000), lr: 0.0009705157320600167\n",
      "step: 302, acc: 0.898, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.0009705063131435671\n",
      "step: 303, acc: 0.891, loss: 0.345 (data_loss: 0.345, reg_loss: 0.000), lr: 0.000970496894409938\n",
      "step: 304, acc: 0.914, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000), lr: 0.000970487475859124\n",
      "step: 305, acc: 0.898, loss: 0.361 (data_loss: 0.361, reg_loss: 0.000), lr: 0.0009704780574911203\n",
      "step: 306, acc: 0.914, loss: 0.369 (data_loss: 0.369, reg_loss: 0.000), lr: 0.0009704686393059209\n",
      "step: 307, acc: 0.914, loss: 0.292 (data_loss: 0.292, reg_loss: 0.000), lr: 0.0009704592213035208\n",
      "step: 308, acc: 0.883, loss: 0.350 (data_loss: 0.350, reg_loss: 0.000), lr: 0.0009704498034839148\n",
      "step: 309, acc: 0.883, loss: 0.419 (data_loss: 0.419, reg_loss: 0.000), lr: 0.0009704403858470975\n",
      "step: 310, acc: 0.922, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.0009704309683930633\n",
      "step: 311, acc: 0.898, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.0009704215511218073\n",
      "step: 312, acc: 0.859, loss: 0.396 (data_loss: 0.396, reg_loss: 0.000), lr: 0.0009704121340333241\n",
      "step: 313, acc: 0.867, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009704027171276079\n",
      "step: 314, acc: 0.938, loss: 0.272 (data_loss: 0.272, reg_loss: 0.000), lr: 0.000970393300404654\n",
      "step: 315, acc: 0.898, loss: 0.356 (data_loss: 0.356, reg_loss: 0.000), lr: 0.0009703838838644568\n",
      "step: 316, acc: 0.922, loss: 0.275 (data_loss: 0.275, reg_loss: 0.000), lr: 0.0009703744675070109\n",
      "step: 317, acc: 0.914, loss: 0.280 (data_loss: 0.280, reg_loss: 0.000), lr: 0.0009703650513323113\n",
      "step: 318, acc: 0.922, loss: 0.337 (data_loss: 0.337, reg_loss: 0.000), lr: 0.0009703556353403522\n",
      "step: 319, acc: 0.914, loss: 0.310 (data_loss: 0.310, reg_loss: 0.000), lr: 0.0009703462195311288\n",
      "step: 320, acc: 0.898, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009703368039046353\n",
      "step: 321, acc: 0.898, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.0009703273884608667\n",
      "step: 322, acc: 0.891, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.0009703179731998178\n",
      "step: 323, acc: 0.906, loss: 0.340 (data_loss: 0.340, reg_loss: 0.000), lr: 0.0009703085581214826\n",
      "step: 324, acc: 0.891, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.0009702991432258565\n",
      "step: 325, acc: 0.891, loss: 0.440 (data_loss: 0.440, reg_loss: 0.000), lr: 0.0009702897285129338\n",
      "step: 326, acc: 0.898, loss: 0.332 (data_loss: 0.332, reg_loss: 0.000), lr: 0.0009702803139827096\n",
      "step: 327, acc: 0.883, loss: 0.418 (data_loss: 0.418, reg_loss: 0.000), lr: 0.0009702708996351782\n",
      "step: 328, acc: 0.898, loss: 0.398 (data_loss: 0.398, reg_loss: 0.000), lr: 0.0009702614854703342\n",
      "step: 329, acc: 0.922, loss: 0.293 (data_loss: 0.293, reg_loss: 0.000), lr: 0.0009702520714881727\n",
      "step: 330, acc: 0.930, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000), lr: 0.000970242657688688\n",
      "step: 331, acc: 0.898, loss: 0.408 (data_loss: 0.408, reg_loss: 0.000), lr: 0.0009702332440718748\n",
      "step: 332, acc: 0.906, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.000970223830637728\n",
      "step: 333, acc: 0.914, loss: 0.363 (data_loss: 0.363, reg_loss: 0.000), lr: 0.0009702144173862424\n",
      "step: 334, acc: 0.875, loss: 0.441 (data_loss: 0.441, reg_loss: 0.000), lr: 0.0009702050043174123\n",
      "step: 335, acc: 0.930, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.0009701955914312325\n",
      "step: 336, acc: 0.930, loss: 0.291 (data_loss: 0.291, reg_loss: 0.000), lr: 0.000970186178727698\n",
      "step: 337, acc: 0.922, loss: 0.326 (data_loss: 0.326, reg_loss: 0.000), lr: 0.000970176766206803\n",
      "step: 338, acc: 0.945, loss: 0.227 (data_loss: 0.227, reg_loss: 0.000), lr: 0.0009701673538685423\n",
      "step: 339, acc: 0.875, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009701579417129109\n",
      "step: 340, acc: 0.938, loss: 0.272 (data_loss: 0.272, reg_loss: 0.000), lr: 0.0009701485297399032\n",
      "step: 341, acc: 0.836, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0009701391179495139\n",
      "step: 342, acc: 0.875, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.0009701297063417378\n",
      "step: 343, acc: 0.891, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009701202949165697\n",
      "step: 344, acc: 0.898, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009701108836740039\n",
      "step: 345, acc: 0.891, loss: 0.364 (data_loss: 0.364, reg_loss: 0.000), lr: 0.0009701014726140354\n",
      "step: 346, acc: 0.867, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0009700920617366588\n",
      "step: 347, acc: 0.938, loss: 0.254 (data_loss: 0.254, reg_loss: 0.000), lr: 0.0009700826510418688\n",
      "step: 348, acc: 0.852, loss: 0.450 (data_loss: 0.450, reg_loss: 0.000), lr: 0.00097007324052966\n",
      "step: 349, acc: 0.875, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009700638302000271\n",
      "step: 350, acc: 0.859, loss: 0.418 (data_loss: 0.418, reg_loss: 0.000), lr: 0.0009700544200529651\n",
      "step: 351, acc: 0.906, loss: 0.299 (data_loss: 0.299, reg_loss: 0.000), lr: 0.0009700450100884681\n",
      "step: 352, acc: 0.914, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.0009700356003065311\n",
      "step: 353, acc: 0.875, loss: 0.414 (data_loss: 0.414, reg_loss: 0.000), lr: 0.0009700261907071491\n",
      "step: 354, acc: 0.906, loss: 0.436 (data_loss: 0.436, reg_loss: 0.000), lr: 0.0009700167812903164\n",
      "step: 355, acc: 0.930, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009700073720560276\n",
      "step: 356, acc: 0.898, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009699979630042778\n",
      "step: 357, acc: 0.898, loss: 0.297 (data_loss: 0.297, reg_loss: 0.000), lr: 0.0009699885541350613\n",
      "step: 358, acc: 0.906, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.0009699791454483728\n",
      "step: 359, acc: 0.922, loss: 0.276 (data_loss: 0.276, reg_loss: 0.000), lr: 0.0009699697369442074\n",
      "step: 360, acc: 0.859, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009699603286225595\n",
      "step: 361, acc: 0.938, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.0009699509204834236\n",
      "step: 362, acc: 0.922, loss: 0.272 (data_loss: 0.272, reg_loss: 0.000), lr: 0.0009699415125267946\n",
      "step: 363, acc: 0.852, loss: 0.437 (data_loss: 0.437, reg_loss: 0.000), lr: 0.0009699321047526674\n",
      "step: 364, acc: 0.852, loss: 0.434 (data_loss: 0.434, reg_loss: 0.000), lr: 0.0009699226971610363\n",
      "step: 365, acc: 0.867, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009699132897518962\n",
      "step: 366, acc: 0.867, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.0009699038825252418\n",
      "step: 367, acc: 0.930, loss: 0.239 (data_loss: 0.239, reg_loss: 0.000), lr: 0.0009698944754810677\n",
      "step: 368, acc: 0.914, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009698850686193686\n",
      "step: 369, acc: 0.914, loss: 0.382 (data_loss: 0.382, reg_loss: 0.000), lr: 0.0009698756619401392\n",
      "step: 370, acc: 0.883, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.0009698662554433745\n",
      "step: 371, acc: 0.922, loss: 0.336 (data_loss: 0.336, reg_loss: 0.000), lr: 0.0009698568491290686\n",
      "step: 372, acc: 0.930, loss: 0.285 (data_loss: 0.285, reg_loss: 0.000), lr: 0.0009698474429972165\n",
      "step: 373, acc: 0.930, loss: 0.271 (data_loss: 0.271, reg_loss: 0.000), lr: 0.0009698380370478132\n",
      "step: 374, acc: 0.930, loss: 0.281 (data_loss: 0.281, reg_loss: 0.000), lr: 0.0009698286312808527\n",
      "step: 375, acc: 0.914, loss: 0.366 (data_loss: 0.366, reg_loss: 0.000), lr: 0.0009698192256963301\n",
      "step: 376, acc: 0.914, loss: 0.346 (data_loss: 0.346, reg_loss: 0.000), lr: 0.0009698098202942403\n",
      "step: 377, acc: 0.930, loss: 0.323 (data_loss: 0.323, reg_loss: 0.000), lr: 0.0009698004150745777\n",
      "step: 378, acc: 0.898, loss: 0.316 (data_loss: 0.316, reg_loss: 0.000), lr: 0.000969791010037337\n",
      "step: 379, acc: 0.875, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0009697816051825128\n",
      "step: 380, acc: 0.922, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.0009697722005101003\n",
      "step: 381, acc: 0.898, loss: 0.346 (data_loss: 0.346, reg_loss: 0.000), lr: 0.0009697627960200936\n",
      "step: 382, acc: 0.914, loss: 0.315 (data_loss: 0.315, reg_loss: 0.000), lr: 0.0009697533917124875\n",
      "step: 383, acc: 0.914, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009697439875872772\n",
      "step: 384, acc: 0.898, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009697345836444565\n",
      "step: 385, acc: 0.914, loss: 0.293 (data_loss: 0.293, reg_loss: 0.000), lr: 0.0009697251798840208\n",
      "step: 386, acc: 0.859, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.0009697157763059646\n",
      "step: 387, acc: 0.930, loss: 0.262 (data_loss: 0.262, reg_loss: 0.000), lr: 0.0009697063729102828\n",
      "step: 388, acc: 0.891, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.0009696969696969698\n",
      "step: 389, acc: 0.906, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009696875666660202\n",
      "step: 390, acc: 0.900, loss: 0.226 (data_loss: 0.226, reg_loss: 0.000), lr: 0.0009696781638174291\n",
      "training, acc: 0.898, loss: 0.368 (data_loss: 0.368, reg_loss: 0.000), lr: 0.0009696781638174291\n",
      "validation, acc: 0.903, loss: 0.349\n",
      "epoch: 9\n",
      "step: 0, acc: 0.867, loss: 0.477 (data_loss: 0.477, reg_loss: 0.000), lr: 0.0009696687611511908\n",
      "step: 1, acc: 0.867, loss: 0.451 (data_loss: 0.451, reg_loss: 0.000), lr: 0.0009696593586673002\n",
      "step: 2, acc: 0.891, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009696499563657519\n",
      "step: 3, acc: 0.898, loss: 0.296 (data_loss: 0.296, reg_loss: 0.000), lr: 0.0009696405542465408\n",
      "step: 4, acc: 0.938, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.0009696311523096614\n",
      "step: 5, acc: 0.883, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.0009696217505551083\n",
      "step: 6, acc: 0.922, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009696123489828768\n",
      "step: 7, acc: 0.930, loss: 0.263 (data_loss: 0.263, reg_loss: 0.000), lr: 0.0009696029475929608\n",
      "step: 8, acc: 0.914, loss: 0.408 (data_loss: 0.408, reg_loss: 0.000), lr: 0.0009695935463853553\n",
      "step: 9, acc: 0.938, loss: 0.287 (data_loss: 0.287, reg_loss: 0.000), lr: 0.0009695841453600553\n",
      "step: 10, acc: 0.938, loss: 0.320 (data_loss: 0.320, reg_loss: 0.000), lr: 0.0009695747445170548\n",
      "step: 11, acc: 0.883, loss: 0.363 (data_loss: 0.363, reg_loss: 0.000), lr: 0.0009695653438563492\n",
      "step: 12, acc: 0.906, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.0009695559433779328\n",
      "step: 13, acc: 0.891, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.0009695465430818007\n",
      "step: 14, acc: 0.883, loss: 0.366 (data_loss: 0.366, reg_loss: 0.000), lr: 0.0009695371429679472\n",
      "step: 15, acc: 0.914, loss: 0.264 (data_loss: 0.264, reg_loss: 0.000), lr: 0.0009695277430363669\n",
      "step: 16, acc: 0.930, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009695183432870551\n",
      "step: 17, acc: 0.914, loss: 0.320 (data_loss: 0.320, reg_loss: 0.000), lr: 0.0009695089437200059\n",
      "step: 18, acc: 0.914, loss: 0.312 (data_loss: 0.312, reg_loss: 0.000), lr: 0.0009694995443352141\n",
      "step: 19, acc: 0.906, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009694901451326746\n",
      "step: 20, acc: 0.875, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0009694807461123823\n",
      "step: 21, acc: 0.867, loss: 0.434 (data_loss: 0.434, reg_loss: 0.000), lr: 0.0009694713472743313\n",
      "step: 22, acc: 0.930, loss: 0.254 (data_loss: 0.254, reg_loss: 0.000), lr: 0.0009694619486185167\n",
      "step: 23, acc: 0.875, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.0009694525501449333\n",
      "step: 24, acc: 0.906, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009694431518535753\n",
      "step: 25, acc: 0.930, loss: 0.266 (data_loss: 0.266, reg_loss: 0.000), lr: 0.0009694337537444379\n",
      "step: 26, acc: 0.914, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009694243558175156\n",
      "step: 27, acc: 0.914, loss: 0.300 (data_loss: 0.300, reg_loss: 0.000), lr: 0.0009694149580728031\n",
      "step: 28, acc: 0.930, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.0009694055605102951\n",
      "step: 29, acc: 0.914, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009693961631299863\n",
      "step: 30, acc: 0.906, loss: 0.369 (data_loss: 0.369, reg_loss: 0.000), lr: 0.0009693867659318716\n",
      "step: 31, acc: 0.898, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.0009693773689159453\n",
      "step: 32, acc: 0.914, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.0009693679720822024\n",
      "step: 33, acc: 0.891, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009693585754306376\n",
      "step: 34, acc: 0.922, loss: 0.348 (data_loss: 0.348, reg_loss: 0.000), lr: 0.0009693491789612454\n",
      "step: 35, acc: 0.891, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009693397826740207\n",
      "step: 36, acc: 0.906, loss: 0.307 (data_loss: 0.307, reg_loss: 0.000), lr: 0.0009693303865689583\n",
      "step: 37, acc: 0.875, loss: 0.354 (data_loss: 0.354, reg_loss: 0.000), lr: 0.0009693209906460525\n",
      "step: 38, acc: 0.867, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.0009693115949052984\n",
      "step: 39, acc: 0.883, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0009693021993466903\n",
      "step: 40, acc: 0.891, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.0009692928039702235\n",
      "step: 41, acc: 0.898, loss: 0.322 (data_loss: 0.322, reg_loss: 0.000), lr: 0.0009692834087758921\n",
      "step: 42, acc: 0.875, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0009692740137636909\n",
      "step: 43, acc: 0.906, loss: 0.336 (data_loss: 0.336, reg_loss: 0.000), lr: 0.0009692646189336151\n",
      "step: 44, acc: 0.922, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.000969255224285659\n",
      "step: 45, acc: 0.891, loss: 0.366 (data_loss: 0.366, reg_loss: 0.000), lr: 0.0009692458298198172\n",
      "step: 46, acc: 0.914, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009692364355360847\n",
      "step: 47, acc: 0.883, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.000969227041434456\n",
      "step: 48, acc: 0.922, loss: 0.292 (data_loss: 0.292, reg_loss: 0.000), lr: 0.0009692176475149259\n",
      "step: 49, acc: 0.922, loss: 0.258 (data_loss: 0.258, reg_loss: 0.000), lr: 0.0009692082537774891\n",
      "step: 50, acc: 0.914, loss: 0.382 (data_loss: 0.382, reg_loss: 0.000), lr: 0.0009691988602221405\n",
      "step: 51, acc: 0.922, loss: 0.321 (data_loss: 0.321, reg_loss: 0.000), lr: 0.0009691894668488743\n",
      "step: 52, acc: 0.898, loss: 0.429 (data_loss: 0.429, reg_loss: 0.000), lr: 0.0009691800736576856\n",
      "step: 53, acc: 0.859, loss: 0.449 (data_loss: 0.449, reg_loss: 0.000), lr: 0.000969170680648569\n",
      "step: 54, acc: 0.914, loss: 0.314 (data_loss: 0.314, reg_loss: 0.000), lr: 0.0009691612878215194\n",
      "step: 55, acc: 0.906, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.000969151895176531\n",
      "step: 56, acc: 0.906, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.0009691425027135989\n",
      "step: 57, acc: 0.938, loss: 0.293 (data_loss: 0.293, reg_loss: 0.000), lr: 0.000969133110432718\n",
      "step: 58, acc: 0.891, loss: 0.354 (data_loss: 0.354, reg_loss: 0.000), lr: 0.0009691237183338826\n",
      "step: 59, acc: 0.898, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000), lr: 0.0009691143264170875\n",
      "step: 60, acc: 0.898, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009691049346823276\n",
      "step: 61, acc: 0.922, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.0009690955431295973\n",
      "step: 62, acc: 0.914, loss: 0.276 (data_loss: 0.276, reg_loss: 0.000), lr: 0.0009690861517588913\n",
      "step: 63, acc: 0.867, loss: 0.419 (data_loss: 0.419, reg_loss: 0.000), lr: 0.0009690767605702046\n",
      "step: 64, acc: 0.883, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.0009690673695635321\n",
      "step: 65, acc: 0.852, loss: 0.459 (data_loss: 0.459, reg_loss: 0.000), lr: 0.0009690579787388679\n",
      "step: 66, acc: 0.938, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009690485880962071\n",
      "step: 67, acc: 0.875, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009690391976355445\n",
      "step: 68, acc: 0.875, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.0009690298073568743\n",
      "step: 69, acc: 0.883, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.0009690204172601916\n",
      "step: 70, acc: 0.922, loss: 0.289 (data_loss: 0.289, reg_loss: 0.000), lr: 0.0009690110273454913\n",
      "step: 71, acc: 0.938, loss: 0.297 (data_loss: 0.297, reg_loss: 0.000), lr: 0.0009690016376127676\n",
      "step: 72, acc: 0.922, loss: 0.297 (data_loss: 0.297, reg_loss: 0.000), lr: 0.0009689922480620155\n",
      "step: 73, acc: 0.961, loss: 0.212 (data_loss: 0.212, reg_loss: 0.000), lr: 0.0009689828586932297\n",
      "step: 74, acc: 0.891, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009689734695064049\n",
      "step: 75, acc: 0.859, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000), lr: 0.0009689640805015359\n",
      "step: 76, acc: 0.922, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.000968954691678617\n",
      "step: 77, acc: 0.938, loss: 0.284 (data_loss: 0.284, reg_loss: 0.000), lr: 0.0009689453030376436\n",
      "step: 78, acc: 0.883, loss: 0.415 (data_loss: 0.415, reg_loss: 0.000), lr: 0.0009689359145786099\n",
      "step: 79, acc: 0.891, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009689265263015106\n",
      "step: 80, acc: 0.883, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.0009689171382063405\n",
      "step: 81, acc: 0.883, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.0009689077502930947\n",
      "step: 82, acc: 0.953, loss: 0.264 (data_loss: 0.264, reg_loss: 0.000), lr: 0.0009688983625617672\n",
      "step: 83, acc: 0.844, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009688889750123533\n",
      "step: 84, acc: 0.875, loss: 0.436 (data_loss: 0.436, reg_loss: 0.000), lr: 0.0009688795876448477\n",
      "step: 85, acc: 0.891, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.0009688702004592444\n",
      "step: 86, acc: 0.898, loss: 0.440 (data_loss: 0.440, reg_loss: 0.000), lr: 0.0009688608134555389\n",
      "step: 87, acc: 0.906, loss: 0.341 (data_loss: 0.341, reg_loss: 0.000), lr: 0.0009688514266337258\n",
      "step: 88, acc: 0.883, loss: 0.532 (data_loss: 0.532, reg_loss: 0.000), lr: 0.0009688420399937995\n",
      "step: 89, acc: 0.922, loss: 0.298 (data_loss: 0.298, reg_loss: 0.000), lr: 0.0009688326535357548\n",
      "step: 90, acc: 0.922, loss: 0.292 (data_loss: 0.292, reg_loss: 0.000), lr: 0.0009688232672595865\n",
      "step: 91, acc: 0.906, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.0009688138811652895\n",
      "step: 92, acc: 0.922, loss: 0.300 (data_loss: 0.300, reg_loss: 0.000), lr: 0.000968804495252858\n",
      "step: 93, acc: 0.883, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.0009687951095222871\n",
      "step: 94, acc: 0.930, loss: 0.328 (data_loss: 0.328, reg_loss: 0.000), lr: 0.0009687857239735716\n",
      "step: 95, acc: 0.867, loss: 0.505 (data_loss: 0.505, reg_loss: 0.000), lr: 0.0009687763386067059\n",
      "step: 96, acc: 0.906, loss: 0.309 (data_loss: 0.309, reg_loss: 0.000), lr: 0.0009687669534216848\n",
      "step: 97, acc: 0.922, loss: 0.285 (data_loss: 0.285, reg_loss: 0.000), lr: 0.0009687575684185033\n",
      "step: 98, acc: 0.867, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.0009687481835971558\n",
      "step: 99, acc: 0.914, loss: 0.310 (data_loss: 0.310, reg_loss: 0.000), lr: 0.000968738798957637\n",
      "step: 100, acc: 0.930, loss: 0.305 (data_loss: 0.305, reg_loss: 0.000), lr: 0.0009687294144999417\n",
      "step: 101, acc: 0.906, loss: 0.488 (data_loss: 0.488, reg_loss: 0.000), lr: 0.0009687200302240651\n",
      "step: 102, acc: 0.922, loss: 0.317 (data_loss: 0.317, reg_loss: 0.000), lr: 0.0009687106461300011\n",
      "step: 103, acc: 0.883, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000), lr: 0.0009687012622177447\n",
      "step: 104, acc: 0.891, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.0009686918784872909\n",
      "step: 105, acc: 0.898, loss: 0.286 (data_loss: 0.286, reg_loss: 0.000), lr: 0.000968682494938634\n",
      "step: 106, acc: 0.891, loss: 0.293 (data_loss: 0.293, reg_loss: 0.000), lr: 0.0009686731115717689\n",
      "step: 107, acc: 0.867, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.0009686637283866905\n",
      "step: 108, acc: 0.906, loss: 0.322 (data_loss: 0.322, reg_loss: 0.000), lr: 0.0009686543453833934\n",
      "step: 109, acc: 0.914, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.0009686449625618722\n",
      "step: 110, acc: 0.977, loss: 0.211 (data_loss: 0.211, reg_loss: 0.000), lr: 0.0009686355799221217\n",
      "step: 111, acc: 0.883, loss: 0.399 (data_loss: 0.399, reg_loss: 0.000), lr: 0.0009686261974641367\n",
      "step: 112, acc: 0.906, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.0009686168151879117\n",
      "step: 113, acc: 0.898, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.0009686074330934416\n",
      "step: 114, acc: 0.867, loss: 0.344 (data_loss: 0.344, reg_loss: 0.000), lr: 0.000968598051180721\n",
      "step: 115, acc: 0.945, loss: 0.281 (data_loss: 0.281, reg_loss: 0.000), lr: 0.0009685886694497449\n",
      "step: 116, acc: 0.859, loss: 0.451 (data_loss: 0.451, reg_loss: 0.000), lr: 0.0009685792879005075\n",
      "step: 117, acc: 0.898, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009685699065330039\n",
      "step: 118, acc: 0.906, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009685605253472291\n",
      "step: 119, acc: 0.922, loss: 0.325 (data_loss: 0.325, reg_loss: 0.000), lr: 0.0009685511443431771\n",
      "step: 120, acc: 0.930, loss: 0.245 (data_loss: 0.245, reg_loss: 0.000), lr: 0.000968541763520843\n",
      "step: 121, acc: 0.883, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009685323828802217\n",
      "step: 122, acc: 0.898, loss: 0.451 (data_loss: 0.451, reg_loss: 0.000), lr: 0.0009685230024213075\n",
      "step: 123, acc: 0.867, loss: 0.484 (data_loss: 0.484, reg_loss: 0.000), lr: 0.0009685136221440954\n",
      "step: 124, acc: 0.859, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.0009685042420485801\n",
      "step: 125, acc: 0.883, loss: 0.309 (data_loss: 0.309, reg_loss: 0.000), lr: 0.0009684948621347565\n",
      "step: 126, acc: 0.930, loss: 0.299 (data_loss: 0.299, reg_loss: 0.000), lr: 0.0009684854824026188\n",
      "step: 127, acc: 0.914, loss: 0.307 (data_loss: 0.307, reg_loss: 0.000), lr: 0.000968476102852162\n",
      "step: 128, acc: 0.836, loss: 0.420 (data_loss: 0.420, reg_loss: 0.000), lr: 0.0009684667234833811\n",
      "step: 129, acc: 0.922, loss: 0.245 (data_loss: 0.245, reg_loss: 0.000), lr: 0.0009684573442962706\n",
      "step: 130, acc: 0.820, loss: 0.478 (data_loss: 0.478, reg_loss: 0.000), lr: 0.0009684479652908249\n",
      "step: 131, acc: 0.852, loss: 0.495 (data_loss: 0.495, reg_loss: 0.000), lr: 0.0009684385864670393\n",
      "step: 132, acc: 0.922, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.000968429207824908\n",
      "step: 133, acc: 0.883, loss: 0.317 (data_loss: 0.317, reg_loss: 0.000), lr: 0.0009684198293644261\n",
      "step: 134, acc: 0.938, loss: 0.270 (data_loss: 0.270, reg_loss: 0.000), lr: 0.000968410451085588\n",
      "step: 135, acc: 0.930, loss: 0.275 (data_loss: 0.275, reg_loss: 0.000), lr: 0.000968401072988389\n",
      "step: 136, acc: 0.891, loss: 0.331 (data_loss: 0.331, reg_loss: 0.000), lr: 0.0009683916950728231\n",
      "step: 137, acc: 0.945, loss: 0.241 (data_loss: 0.241, reg_loss: 0.000), lr: 0.0009683823173388854\n",
      "step: 138, acc: 0.906, loss: 0.348 (data_loss: 0.348, reg_loss: 0.000), lr: 0.0009683729397865707\n",
      "step: 139, acc: 0.867, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009683635624158734\n",
      "step: 140, acc: 0.914, loss: 0.334 (data_loss: 0.334, reg_loss: 0.000), lr: 0.0009683541852267885\n",
      "step: 141, acc: 0.891, loss: 0.409 (data_loss: 0.409, reg_loss: 0.000), lr: 0.0009683448082193107\n",
      "step: 142, acc: 0.953, loss: 0.240 (data_loss: 0.240, reg_loss: 0.000), lr: 0.0009683354313934347\n",
      "step: 143, acc: 0.938, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.0009683260547491551\n",
      "step: 144, acc: 0.906, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.0009683166782864667\n",
      "step: 145, acc: 0.883, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.0009683073020053646\n",
      "step: 146, acc: 0.898, loss: 0.483 (data_loss: 0.483, reg_loss: 0.000), lr: 0.0009682979259058428\n",
      "step: 147, acc: 0.844, loss: 0.465 (data_loss: 0.465, reg_loss: 0.000), lr: 0.0009682885499878964\n",
      "step: 148, acc: 0.898, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.0009682791742515204\n",
      "step: 149, acc: 0.938, loss: 0.261 (data_loss: 0.261, reg_loss: 0.000), lr: 0.0009682697986967089\n",
      "step: 150, acc: 0.891, loss: 0.304 (data_loss: 0.304, reg_loss: 0.000), lr: 0.0009682604233234571\n",
      "step: 151, acc: 0.906, loss: 0.290 (data_loss: 0.290, reg_loss: 0.000), lr: 0.0009682510481317596\n",
      "step: 152, acc: 0.914, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.0009682416731216113\n",
      "step: 153, acc: 0.891, loss: 0.412 (data_loss: 0.412, reg_loss: 0.000), lr: 0.0009682322982930065\n",
      "step: 154, acc: 0.922, loss: 0.284 (data_loss: 0.284, reg_loss: 0.000), lr: 0.0009682229236459403\n",
      "step: 155, acc: 0.922, loss: 0.289 (data_loss: 0.289, reg_loss: 0.000), lr: 0.0009682135491804074\n",
      "step: 156, acc: 0.914, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.0009682041748964022\n",
      "step: 157, acc: 0.891, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.0009681948007939198\n",
      "step: 158, acc: 0.906, loss: 0.442 (data_loss: 0.442, reg_loss: 0.000), lr: 0.0009681854268729548\n",
      "step: 159, acc: 0.914, loss: 0.369 (data_loss: 0.369, reg_loss: 0.000), lr: 0.0009681760531335019\n",
      "step: 160, acc: 0.898, loss: 0.305 (data_loss: 0.305, reg_loss: 0.000), lr: 0.0009681666795755557\n",
      "step: 161, acc: 0.891, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009681573061991112\n",
      "step: 162, acc: 0.922, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009681479330041631\n",
      "step: 163, acc: 0.898, loss: 0.358 (data_loss: 0.358, reg_loss: 0.000), lr: 0.0009681385599907058\n",
      "step: 164, acc: 0.945, loss: 0.240 (data_loss: 0.240, reg_loss: 0.000), lr: 0.0009681291871587344\n",
      "step: 165, acc: 0.891, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000), lr: 0.0009681198145082437\n",
      "step: 166, acc: 0.852, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009681104420392279\n",
      "step: 167, acc: 0.906, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009681010697516822\n",
      "step: 168, acc: 0.906, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000), lr: 0.0009680916976456009\n",
      "step: 169, acc: 0.930, loss: 0.289 (data_loss: 0.289, reg_loss: 0.000), lr: 0.0009680823257209795\n",
      "step: 170, acc: 0.883, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0009680729539778118\n",
      "step: 171, acc: 0.898, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.000968063582416093\n",
      "step: 172, acc: 0.852, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0009680542110358181\n",
      "step: 173, acc: 0.875, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000), lr: 0.0009680448398369814\n",
      "step: 174, acc: 0.883, loss: 0.416 (data_loss: 0.416, reg_loss: 0.000), lr: 0.0009680354688195775\n",
      "step: 175, acc: 0.906, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009680260979836016\n",
      "step: 176, acc: 0.906, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000), lr: 0.0009680167273290484\n",
      "step: 177, acc: 0.891, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009680073568559121\n",
      "step: 178, acc: 0.898, loss: 0.458 (data_loss: 0.458, reg_loss: 0.000), lr: 0.0009679979865641879\n",
      "step: 179, acc: 0.883, loss: 0.398 (data_loss: 0.398, reg_loss: 0.000), lr: 0.0009679886164538706\n",
      "step: 180, acc: 0.906, loss: 0.316 (data_loss: 0.316, reg_loss: 0.000), lr: 0.0009679792465249545\n",
      "step: 181, acc: 0.930, loss: 0.261 (data_loss: 0.261, reg_loss: 0.000), lr: 0.0009679698767774347\n",
      "step: 182, acc: 0.914, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.0009679605072113059\n",
      "step: 183, acc: 0.891, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.0009679511378265625\n",
      "step: 184, acc: 0.914, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009679417686231996\n",
      "step: 185, acc: 0.883, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009679323996012118\n",
      "step: 186, acc: 0.867, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009679230307605939\n",
      "step: 187, acc: 0.891, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.0009679136621013406\n",
      "step: 188, acc: 0.945, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.0009679042936234464\n",
      "step: 189, acc: 0.914, loss: 0.310 (data_loss: 0.310, reg_loss: 0.000), lr: 0.0009678949253269066\n",
      "step: 190, acc: 0.883, loss: 0.415 (data_loss: 0.415, reg_loss: 0.000), lr: 0.0009678855572117154\n",
      "step: 191, acc: 0.914, loss: 0.264 (data_loss: 0.264, reg_loss: 0.000), lr: 0.0009678761892778676\n",
      "step: 192, acc: 0.953, loss: 0.177 (data_loss: 0.177, reg_loss: 0.000), lr: 0.0009678668215253582\n",
      "step: 193, acc: 0.883, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.0009678574539541817\n",
      "step: 194, acc: 0.867, loss: 0.469 (data_loss: 0.469, reg_loss: 0.000), lr: 0.0009678480865643328\n",
      "step: 195, acc: 0.938, loss: 0.335 (data_loss: 0.335, reg_loss: 0.000), lr: 0.0009678387193558064\n",
      "step: 196, acc: 0.891, loss: 0.366 (data_loss: 0.366, reg_loss: 0.000), lr: 0.0009678293523285975\n",
      "step: 197, acc: 0.922, loss: 0.292 (data_loss: 0.292, reg_loss: 0.000), lr: 0.0009678199854827002\n",
      "step: 198, acc: 0.883, loss: 0.468 (data_loss: 0.468, reg_loss: 0.000), lr: 0.0009678106188181096\n",
      "step: 199, acc: 0.938, loss: 0.287 (data_loss: 0.287, reg_loss: 0.000), lr: 0.0009678012523348206\n",
      "step: 200, acc: 0.906, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009677918860328275\n",
      "step: 201, acc: 0.844, loss: 0.479 (data_loss: 0.479, reg_loss: 0.000), lr: 0.0009677825199121253\n",
      "step: 202, acc: 0.883, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.0009677731539727087\n",
      "step: 203, acc: 0.906, loss: 0.399 (data_loss: 0.399, reg_loss: 0.000), lr: 0.0009677637882145727\n",
      "step: 204, acc: 0.969, loss: 0.192 (data_loss: 0.192, reg_loss: 0.000), lr: 0.0009677544226377114\n",
      "step: 205, acc: 0.922, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.00096774505724212\n",
      "step: 206, acc: 0.859, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.0009677356920277934\n",
      "step: 207, acc: 0.906, loss: 0.314 (data_loss: 0.314, reg_loss: 0.000), lr: 0.0009677263269947259\n",
      "step: 208, acc: 0.891, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.0009677169621429124\n",
      "step: 209, acc: 0.875, loss: 0.475 (data_loss: 0.475, reg_loss: 0.000), lr: 0.0009677075974723478\n",
      "step: 210, acc: 0.891, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009676982329830267\n",
      "step: 211, acc: 0.930, loss: 0.298 (data_loss: 0.298, reg_loss: 0.000), lr: 0.0009676888686749437\n",
      "step: 212, acc: 0.914, loss: 0.340 (data_loss: 0.340, reg_loss: 0.000), lr: 0.0009676795045480936\n",
      "step: 213, acc: 0.922, loss: 0.341 (data_loss: 0.341, reg_loss: 0.000), lr: 0.0009676701406024715\n",
      "step: 214, acc: 0.867, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009676607768380716\n",
      "step: 215, acc: 0.922, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.000967651413254889\n",
      "step: 216, acc: 0.883, loss: 0.350 (data_loss: 0.350, reg_loss: 0.000), lr: 0.0009676420498529185\n",
      "step: 217, acc: 0.922, loss: 0.331 (data_loss: 0.331, reg_loss: 0.000), lr: 0.0009676326866321544\n",
      "step: 218, acc: 0.844, loss: 0.409 (data_loss: 0.409, reg_loss: 0.000), lr: 0.0009676233235925919\n",
      "step: 219, acc: 0.883, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009676139607342256\n",
      "step: 220, acc: 0.922, loss: 0.310 (data_loss: 0.310, reg_loss: 0.000), lr: 0.00096760459805705\n",
      "step: 221, acc: 0.930, loss: 0.309 (data_loss: 0.309, reg_loss: 0.000), lr: 0.0009675952355610602\n",
      "step: 222, acc: 0.836, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.0009675858732462506\n",
      "step: 223, acc: 0.891, loss: 0.366 (data_loss: 0.366, reg_loss: 0.000), lr: 0.0009675765111126164\n",
      "step: 224, acc: 0.859, loss: 0.325 (data_loss: 0.325, reg_loss: 0.000), lr: 0.0009675671491601518\n",
      "step: 225, acc: 0.797, loss: 0.532 (data_loss: 0.532, reg_loss: 0.000), lr: 0.0009675577873888518\n",
      "step: 226, acc: 0.859, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009675484257987114\n",
      "step: 227, acc: 0.883, loss: 0.354 (data_loss: 0.354, reg_loss: 0.000), lr: 0.0009675390643897248\n",
      "step: 228, acc: 0.844, loss: 0.491 (data_loss: 0.491, reg_loss: 0.000), lr: 0.0009675297031618871\n",
      "step: 229, acc: 0.898, loss: 0.402 (data_loss: 0.402, reg_loss: 0.000), lr: 0.0009675203421151929\n",
      "step: 230, acc: 0.898, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000), lr: 0.0009675109812496372\n",
      "step: 231, acc: 0.898, loss: 0.298 (data_loss: 0.298, reg_loss: 0.000), lr: 0.0009675016205652145\n",
      "step: 232, acc: 0.938, loss: 0.292 (data_loss: 0.292, reg_loss: 0.000), lr: 0.0009674922600619195\n",
      "step: 233, acc: 0.906, loss: 0.408 (data_loss: 0.408, reg_loss: 0.000), lr: 0.0009674828997397472\n",
      "step: 234, acc: 0.906, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.000967473539598692\n",
      "step: 235, acc: 0.891, loss: 0.425 (data_loss: 0.425, reg_loss: 0.000), lr: 0.0009674641796387489\n",
      "step: 236, acc: 0.914, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0009674548198599125\n",
      "step: 237, acc: 0.938, loss: 0.279 (data_loss: 0.279, reg_loss: 0.000), lr: 0.0009674454602621778\n",
      "step: 238, acc: 0.922, loss: 0.265 (data_loss: 0.265, reg_loss: 0.000), lr: 0.0009674361008455391\n",
      "step: 239, acc: 0.938, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009674267416099916\n",
      "step: 240, acc: 0.914, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.0009674173825555298\n",
      "step: 241, acc: 0.883, loss: 0.420 (data_loss: 0.420, reg_loss: 0.000), lr: 0.0009674080236821484\n",
      "step: 242, acc: 0.930, loss: 0.254 (data_loss: 0.254, reg_loss: 0.000), lr: 0.0009673986649898423\n",
      "step: 243, acc: 0.930, loss: 0.290 (data_loss: 0.290, reg_loss: 0.000), lr: 0.0009673893064786063\n",
      "step: 244, acc: 0.898, loss: 0.349 (data_loss: 0.349, reg_loss: 0.000), lr: 0.0009673799481484347\n",
      "step: 245, acc: 0.875, loss: 0.420 (data_loss: 0.420, reg_loss: 0.000), lr: 0.0009673705899993228\n",
      "step: 246, acc: 0.938, loss: 0.277 (data_loss: 0.277, reg_loss: 0.000), lr: 0.000967361232031265\n",
      "step: 247, acc: 0.906, loss: 0.317 (data_loss: 0.317, reg_loss: 0.000), lr: 0.0009673518742442564\n",
      "step: 248, acc: 0.883, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009673425166382913\n",
      "step: 249, acc: 0.859, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000), lr: 0.0009673331592133646\n",
      "step: 250, acc: 0.883, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.0009673238019694714\n",
      "step: 251, acc: 0.922, loss: 0.250 (data_loss: 0.250, reg_loss: 0.000), lr: 0.0009673144449066058\n",
      "step: 252, acc: 0.922, loss: 0.289 (data_loss: 0.289, reg_loss: 0.000), lr: 0.000967305088024763\n",
      "step: 253, acc: 0.922, loss: 0.279 (data_loss: 0.279, reg_loss: 0.000), lr: 0.0009672957313239378\n",
      "step: 254, acc: 0.891, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0009672863748041245\n",
      "step: 255, acc: 0.898, loss: 0.369 (data_loss: 0.369, reg_loss: 0.000), lr: 0.0009672770184653183\n",
      "step: 256, acc: 0.883, loss: 0.336 (data_loss: 0.336, reg_loss: 0.000), lr: 0.0009672676623075136\n",
      "step: 257, acc: 0.891, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.0009672583063307056\n",
      "step: 258, acc: 0.938, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009672489505348887\n",
      "step: 259, acc: 0.906, loss: 0.324 (data_loss: 0.324, reg_loss: 0.000), lr: 0.0009672395949200576\n",
      "step: 260, acc: 0.906, loss: 0.429 (data_loss: 0.429, reg_loss: 0.000), lr: 0.0009672302394862074\n",
      "step: 261, acc: 0.953, loss: 0.271 (data_loss: 0.271, reg_loss: 0.000), lr: 0.0009672208842333325\n",
      "step: 262, acc: 0.914, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000), lr: 0.0009672115291614276\n",
      "step: 263, acc: 0.891, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009672021742704877\n",
      "step: 264, acc: 0.883, loss: 0.397 (data_loss: 0.397, reg_loss: 0.000), lr: 0.0009671928195605076\n",
      "step: 265, acc: 0.922, loss: 0.363 (data_loss: 0.363, reg_loss: 0.000), lr: 0.0009671834650314818\n",
      "step: 266, acc: 0.891, loss: 0.505 (data_loss: 0.505, reg_loss: 0.000), lr: 0.0009671741106834053\n",
      "step: 267, acc: 0.898, loss: 0.331 (data_loss: 0.331, reg_loss: 0.000), lr: 0.0009671647565162727\n",
      "step: 268, acc: 0.867, loss: 0.547 (data_loss: 0.547, reg_loss: 0.000), lr: 0.0009671554025300786\n",
      "step: 269, acc: 0.883, loss: 0.361 (data_loss: 0.361, reg_loss: 0.000), lr: 0.0009671460487248179\n",
      "step: 270, acc: 0.898, loss: 0.358 (data_loss: 0.358, reg_loss: 0.000), lr: 0.0009671366951004856\n",
      "step: 271, acc: 0.875, loss: 0.358 (data_loss: 0.358, reg_loss: 0.000), lr: 0.000967127341657076\n",
      "step: 272, acc: 0.883, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009671179883945841\n",
      "step: 273, acc: 0.914, loss: 0.276 (data_loss: 0.276, reg_loss: 0.000), lr: 0.0009671086353130046\n",
      "step: 274, acc: 0.891, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009670992824123326\n",
      "step: 275, acc: 0.844, loss: 0.499 (data_loss: 0.499, reg_loss: 0.000), lr: 0.0009670899296925622\n",
      "step: 276, acc: 0.898, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009670805771536884\n",
      "step: 277, acc: 0.875, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009670712247957063\n",
      "step: 278, acc: 0.930, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000), lr: 0.0009670618726186103\n",
      "step: 279, acc: 0.898, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009670525206223951\n",
      "step: 280, acc: 0.906, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009670431688070555\n",
      "step: 281, acc: 0.914, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.0009670338171725865\n",
      "step: 282, acc: 0.906, loss: 0.317 (data_loss: 0.317, reg_loss: 0.000), lr: 0.0009670244657189827\n",
      "step: 283, acc: 0.891, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009670151144462387\n",
      "step: 284, acc: 0.922, loss: 0.298 (data_loss: 0.298, reg_loss: 0.000), lr: 0.0009670057633543496\n",
      "step: 285, acc: 0.938, loss: 0.232 (data_loss: 0.232, reg_loss: 0.000), lr: 0.0009669964124433098\n",
      "step: 286, acc: 0.906, loss: 0.254 (data_loss: 0.254, reg_loss: 0.000), lr: 0.0009669870617131142\n",
      "step: 287, acc: 0.867, loss: 0.468 (data_loss: 0.468, reg_loss: 0.000), lr: 0.0009669777111637578\n",
      "step: 288, acc: 0.938, loss: 0.316 (data_loss: 0.316, reg_loss: 0.000), lr: 0.0009669683607952349\n",
      "step: 289, acc: 0.898, loss: 0.320 (data_loss: 0.320, reg_loss: 0.000), lr: 0.0009669590106075403\n",
      "step: 290, acc: 0.906, loss: 0.315 (data_loss: 0.315, reg_loss: 0.000), lr: 0.000966949660600669\n",
      "step: 291, acc: 0.883, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.000966940310774616\n",
      "step: 292, acc: 0.914, loss: 0.345 (data_loss: 0.345, reg_loss: 0.000), lr: 0.0009669309611293754\n",
      "step: 293, acc: 0.922, loss: 0.242 (data_loss: 0.242, reg_loss: 0.000), lr: 0.0009669216116649423\n",
      "step: 294, acc: 0.867, loss: 0.432 (data_loss: 0.432, reg_loss: 0.000), lr: 0.0009669122623813116\n",
      "step: 295, acc: 0.930, loss: 0.390 (data_loss: 0.390, reg_loss: 0.000), lr: 0.0009669029132784778\n",
      "step: 296, acc: 0.898, loss: 0.315 (data_loss: 0.315, reg_loss: 0.000), lr: 0.0009668935643564356\n",
      "step: 297, acc: 0.891, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.00096688421561518\n",
      "step: 298, acc: 0.930, loss: 0.297 (data_loss: 0.297, reg_loss: 0.000), lr: 0.0009668748670547059\n",
      "step: 299, acc: 0.945, loss: 0.260 (data_loss: 0.260, reg_loss: 0.000), lr: 0.0009668655186750075\n",
      "step: 300, acc: 0.906, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009668561704760799\n",
      "step: 301, acc: 0.898, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.0009668468224579181\n",
      "step: 302, acc: 0.914, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.0009668374746205163\n",
      "step: 303, acc: 0.898, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000), lr: 0.0009668281269638695\n",
      "step: 304, acc: 0.930, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009668187794879729\n",
      "step: 305, acc: 0.891, loss: 0.346 (data_loss: 0.346, reg_loss: 0.000), lr: 0.0009668094321928205\n",
      "step: 306, acc: 0.922, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000), lr: 0.0009668000850784074\n",
      "step: 307, acc: 0.922, loss: 0.273 (data_loss: 0.273, reg_loss: 0.000), lr: 0.0009667907381447285\n",
      "step: 308, acc: 0.883, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009667813913917786\n",
      "step: 309, acc: 0.891, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.000966772044819552\n",
      "step: 310, acc: 0.922, loss: 0.295 (data_loss: 0.295, reg_loss: 0.000), lr: 0.0009667626984280437\n",
      "step: 311, acc: 0.898, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.000966753352217249\n",
      "step: 312, acc: 0.859, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000), lr: 0.0009667440061871616\n",
      "step: 313, acc: 0.883, loss: 0.366 (data_loss: 0.366, reg_loss: 0.000), lr: 0.000966734660337777\n",
      "step: 314, acc: 0.930, loss: 0.256 (data_loss: 0.256, reg_loss: 0.000), lr: 0.00096672531466909\n",
      "step: 315, acc: 0.906, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.0009667159691810949\n",
      "step: 316, acc: 0.914, loss: 0.261 (data_loss: 0.261, reg_loss: 0.000), lr: 0.0009667066238737868\n",
      "step: 317, acc: 0.930, loss: 0.266 (data_loss: 0.266, reg_loss: 0.000), lr: 0.0009666972787471603\n",
      "step: 318, acc: 0.922, loss: 0.315 (data_loss: 0.315, reg_loss: 0.000), lr: 0.0009666879338012103\n",
      "step: 319, acc: 0.914, loss: 0.295 (data_loss: 0.295, reg_loss: 0.000), lr: 0.0009666785890359315\n",
      "step: 320, acc: 0.898, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009666692444513185\n",
      "step: 321, acc: 0.906, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000), lr: 0.0009666599000473665\n",
      "step: 322, acc: 0.891, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000), lr: 0.0009666505558240697\n",
      "step: 323, acc: 0.906, loss: 0.325 (data_loss: 0.325, reg_loss: 0.000), lr: 0.0009666412117814231\n",
      "step: 324, acc: 0.898, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.0009666318679194215\n",
      "step: 325, acc: 0.891, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0009666225242380599\n",
      "step: 326, acc: 0.898, loss: 0.316 (data_loss: 0.316, reg_loss: 0.000), lr: 0.0009666131807373325\n",
      "step: 327, acc: 0.883, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.0009666038374172344\n",
      "step: 328, acc: 0.898, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009665944942777607\n",
      "step: 329, acc: 0.922, loss: 0.280 (data_loss: 0.280, reg_loss: 0.000), lr: 0.0009665851513189055\n",
      "step: 330, acc: 0.930, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.0009665758085406639\n",
      "step: 331, acc: 0.898, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.0009665664659430307\n",
      "step: 332, acc: 0.906, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009665571235260005\n",
      "step: 333, acc: 0.922, loss: 0.345 (data_loss: 0.345, reg_loss: 0.000), lr: 0.000966547781289568\n",
      "step: 334, acc: 0.875, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009665384392337283\n",
      "step: 335, acc: 0.930, loss: 0.279 (data_loss: 0.279, reg_loss: 0.000), lr: 0.000966529097358476\n",
      "step: 336, acc: 0.930, loss: 0.274 (data_loss: 0.274, reg_loss: 0.000), lr: 0.0009665197556638058\n",
      "step: 337, acc: 0.914, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009665104141497124\n",
      "step: 338, acc: 0.945, loss: 0.213 (data_loss: 0.213, reg_loss: 0.000), lr: 0.0009665010728161909\n",
      "step: 339, acc: 0.883, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009664917316632356\n",
      "step: 340, acc: 0.930, loss: 0.259 (data_loss: 0.259, reg_loss: 0.000), lr: 0.0009664823906908415\n",
      "step: 341, acc: 0.828, loss: 0.416 (data_loss: 0.416, reg_loss: 0.000), lr: 0.0009664730498990036\n",
      "step: 342, acc: 0.891, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.0009664637092877163\n",
      "step: 343, acc: 0.891, loss: 0.354 (data_loss: 0.354, reg_loss: 0.000), lr: 0.0009664543688569744\n",
      "step: 344, acc: 0.898, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009664450286067728\n",
      "step: 345, acc: 0.906, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009664356885371064\n",
      "step: 346, acc: 0.883, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.0009664263486479695\n",
      "step: 347, acc: 0.938, loss: 0.238 (data_loss: 0.238, reg_loss: 0.000), lr: 0.0009664170089393573\n",
      "step: 348, acc: 0.867, loss: 0.440 (data_loss: 0.440, reg_loss: 0.000), lr: 0.0009664076694112646\n",
      "step: 349, acc: 0.883, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009663983300636857\n",
      "step: 350, acc: 0.859, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.0009663889908966157\n",
      "step: 351, acc: 0.914, loss: 0.284 (data_loss: 0.284, reg_loss: 0.000), lr: 0.0009663796519100493\n",
      "step: 352, acc: 0.914, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.0009663703131039815\n",
      "step: 353, acc: 0.883, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009663609744784067\n",
      "step: 354, acc: 0.914, loss: 0.419 (data_loss: 0.419, reg_loss: 0.000), lr: 0.0009663516360333198\n",
      "step: 355, acc: 0.930, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.0009663422977687157\n",
      "step: 356, acc: 0.898, loss: 0.415 (data_loss: 0.415, reg_loss: 0.000), lr: 0.000966332959684589\n",
      "step: 357, acc: 0.906, loss: 0.282 (data_loss: 0.282, reg_loss: 0.000), lr: 0.0009663236217809344\n",
      "step: 358, acc: 0.914, loss: 0.304 (data_loss: 0.304, reg_loss: 0.000), lr: 0.0009663142840577469\n",
      "step: 359, acc: 0.922, loss: 0.259 (data_loss: 0.259, reg_loss: 0.000), lr: 0.0009663049465150213\n",
      "step: 360, acc: 0.875, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.000966295609152752\n",
      "step: 361, acc: 0.938, loss: 0.317 (data_loss: 0.317, reg_loss: 0.000), lr: 0.000966286271970934\n",
      "step: 362, acc: 0.938, loss: 0.257 (data_loss: 0.257, reg_loss: 0.000), lr: 0.0009662769349695623\n",
      "step: 363, acc: 0.859, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009662675981486312\n",
      "step: 364, acc: 0.859, loss: 0.423 (data_loss: 0.423, reg_loss: 0.000), lr: 0.0009662582615081359\n",
      "step: 365, acc: 0.883, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.000966248925048071\n",
      "step: 366, acc: 0.867, loss: 0.368 (data_loss: 0.368, reg_loss: 0.000), lr: 0.0009662395887684311\n",
      "step: 367, acc: 0.938, loss: 0.225 (data_loss: 0.225, reg_loss: 0.000), lr: 0.0009662302526692111\n",
      "step: 368, acc: 0.914, loss: 0.346 (data_loss: 0.346, reg_loss: 0.000), lr: 0.0009662209167504057\n",
      "step: 369, acc: 0.922, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.0009662115810120101\n",
      "step: 370, acc: 0.875, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009662022454540184\n",
      "step: 371, acc: 0.930, loss: 0.320 (data_loss: 0.320, reg_loss: 0.000), lr: 0.0009661929100764258\n",
      "step: 372, acc: 0.938, loss: 0.270 (data_loss: 0.270, reg_loss: 0.000), lr: 0.0009661835748792271\n",
      "step: 373, acc: 0.938, loss: 0.256 (data_loss: 0.256, reg_loss: 0.000), lr: 0.0009661742398624168\n",
      "step: 374, acc: 0.930, loss: 0.267 (data_loss: 0.267, reg_loss: 0.000), lr: 0.0009661649050259898\n",
      "step: 375, acc: 0.914, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.0009661555703699411\n",
      "step: 376, acc: 0.906, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000), lr: 0.0009661462358942649\n",
      "step: 377, acc: 0.930, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.0009661369015989567\n",
      "step: 378, acc: 0.898, loss: 0.296 (data_loss: 0.296, reg_loss: 0.000), lr: 0.0009661275674840105\n",
      "step: 379, acc: 0.883, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009661182335494218\n",
      "step: 380, acc: 0.922, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000), lr: 0.0009661088997951849\n",
      "step: 381, acc: 0.898, loss: 0.334 (data_loss: 0.334, reg_loss: 0.000), lr: 0.0009660995662212947\n",
      "step: 382, acc: 0.922, loss: 0.301 (data_loss: 0.301, reg_loss: 0.000), lr: 0.0009660902328277462\n",
      "step: 383, acc: 0.906, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009660808996145337\n",
      "step: 384, acc: 0.898, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.0009660715665816525\n",
      "step: 385, acc: 0.922, loss: 0.278 (data_loss: 0.278, reg_loss: 0.000), lr: 0.0009660622337290967\n",
      "step: 386, acc: 0.867, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.000966052901056862\n",
      "step: 387, acc: 0.930, loss: 0.250 (data_loss: 0.250, reg_loss: 0.000), lr: 0.0009660435685649423\n",
      "step: 388, acc: 0.891, loss: 0.328 (data_loss: 0.328, reg_loss: 0.000), lr: 0.0009660342362533327\n",
      "step: 389, acc: 0.906, loss: 0.350 (data_loss: 0.350, reg_loss: 0.000), lr: 0.0009660249041220283\n",
      "step: 390, acc: 0.912, loss: 0.211 (data_loss: 0.211, reg_loss: 0.000), lr: 0.0009660155721710234\n",
      "training, acc: 0.902, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009660155721710234\n",
      "validation, acc: 0.906, loss: 0.335\n",
      "epoch: 10\n",
      "step: 0, acc: 0.875, loss: 0.464 (data_loss: 0.464, reg_loss: 0.000), lr: 0.0009660062404003129\n",
      "step: 1, acc: 0.883, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.0009659969088098919\n",
      "step: 2, acc: 0.891, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.0009659875773997547\n",
      "step: 3, acc: 0.898, loss: 0.280 (data_loss: 0.280, reg_loss: 0.000), lr: 0.0009659782461698962\n",
      "step: 4, acc: 0.938, loss: 0.296 (data_loss: 0.296, reg_loss: 0.000), lr: 0.0009659689151203113\n",
      "step: 5, acc: 0.891, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009659595842509951\n",
      "step: 6, acc: 0.922, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009659502535619416\n",
      "step: 7, acc: 0.938, loss: 0.248 (data_loss: 0.248, reg_loss: 0.000), lr: 0.0009659409230531461\n",
      "step: 8, acc: 0.914, loss: 0.396 (data_loss: 0.396, reg_loss: 0.000), lr: 0.0009659315927246033\n",
      "step: 9, acc: 0.938, loss: 0.270 (data_loss: 0.270, reg_loss: 0.000), lr: 0.0009659222625763078\n",
      "step: 10, acc: 0.938, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009659129326082546\n",
      "step: 11, acc: 0.883, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009659036028204385\n",
      "step: 12, acc: 0.906, loss: 0.337 (data_loss: 0.337, reg_loss: 0.000), lr: 0.0009658942732128542\n",
      "step: 13, acc: 0.891, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009658849437854963\n",
      "step: 14, acc: 0.883, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.0009658756145383597\n",
      "step: 15, acc: 0.914, loss: 0.247 (data_loss: 0.247, reg_loss: 0.000), lr: 0.0009658662854714394\n",
      "step: 16, acc: 0.930, loss: 0.335 (data_loss: 0.335, reg_loss: 0.000), lr: 0.0009658569565847298\n",
      "step: 17, acc: 0.914, loss: 0.307 (data_loss: 0.307, reg_loss: 0.000), lr: 0.0009658476278782259\n",
      "step: 18, acc: 0.914, loss: 0.293 (data_loss: 0.293, reg_loss: 0.000), lr: 0.0009658382993519226\n",
      "step: 19, acc: 0.914, loss: 0.314 (data_loss: 0.314, reg_loss: 0.000), lr: 0.0009658289710058143\n",
      "step: 20, acc: 0.883, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009658196428398961\n",
      "step: 21, acc: 0.883, loss: 0.418 (data_loss: 0.418, reg_loss: 0.000), lr: 0.0009658103148541626\n",
      "step: 22, acc: 0.938, loss: 0.241 (data_loss: 0.241, reg_loss: 0.000), lr: 0.0009658009870486088\n",
      "step: 23, acc: 0.875, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.0009657916594232293\n",
      "step: 24, acc: 0.906, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.0009657823319780187\n",
      "step: 25, acc: 0.930, loss: 0.252 (data_loss: 0.252, reg_loss: 0.000), lr: 0.0009657730047129724\n",
      "step: 26, acc: 0.930, loss: 0.369 (data_loss: 0.369, reg_loss: 0.000), lr: 0.0009657636776280845\n",
      "step: 27, acc: 0.914, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.00096575435072335\n",
      "step: 28, acc: 0.922, loss: 0.298 (data_loss: 0.298, reg_loss: 0.000), lr: 0.0009657450239987638\n",
      "step: 29, acc: 0.922, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.0009657356974543208\n",
      "step: 30, acc: 0.906, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009657263710900154\n",
      "step: 31, acc: 0.898, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009657170449058426\n",
      "step: 32, acc: 0.914, loss: 0.291 (data_loss: 0.291, reg_loss: 0.000), lr: 0.0009657077189017974\n",
      "step: 33, acc: 0.891, loss: 0.350 (data_loss: 0.350, reg_loss: 0.000), lr: 0.000965698393077874\n",
      "step: 34, acc: 0.922, loss: 0.335 (data_loss: 0.335, reg_loss: 0.000), lr: 0.0009656890674340676\n",
      "step: 35, acc: 0.906, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.000965679741970373\n",
      "step: 36, acc: 0.906, loss: 0.292 (data_loss: 0.292, reg_loss: 0.000), lr: 0.0009656704166867849\n",
      "step: 37, acc: 0.891, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000), lr: 0.000965661091583298\n",
      "step: 38, acc: 0.867, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000), lr: 0.0009656517666599071\n",
      "step: 39, acc: 0.883, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009656424419166072\n",
      "step: 40, acc: 0.898, loss: 0.307 (data_loss: 0.307, reg_loss: 0.000), lr: 0.0009656331173533928\n",
      "step: 41, acc: 0.898, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009656237929702587\n",
      "step: 42, acc: 0.875, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.0009656144687672\n",
      "step: 43, acc: 0.906, loss: 0.322 (data_loss: 0.322, reg_loss: 0.000), lr: 0.0009656051447442112\n",
      "step: 44, acc: 0.922, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.000965595820901287\n",
      "step: 45, acc: 0.898, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009655864972384227\n",
      "step: 46, acc: 0.914, loss: 0.385 (data_loss: 0.385, reg_loss: 0.000), lr: 0.0009655771737556125\n",
      "step: 47, acc: 0.898, loss: 0.335 (data_loss: 0.335, reg_loss: 0.000), lr: 0.0009655678504528513\n",
      "step: 48, acc: 0.914, loss: 0.276 (data_loss: 0.276, reg_loss: 0.000), lr: 0.000965558527330134\n",
      "step: 49, acc: 0.930, loss: 0.239 (data_loss: 0.239, reg_loss: 0.000), lr: 0.0009655492043874556\n",
      "step: 50, acc: 0.914, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.0009655398816248105\n",
      "step: 51, acc: 0.930, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009655305590421936\n",
      "step: 52, acc: 0.898, loss: 0.420 (data_loss: 0.420, reg_loss: 0.000), lr: 0.0009655212366396001\n",
      "step: 53, acc: 0.867, loss: 0.431 (data_loss: 0.431, reg_loss: 0.000), lr: 0.0009655119144170239\n",
      "step: 54, acc: 0.922, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.0009655025923744605\n",
      "step: 55, acc: 0.906, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.0009654932705119045\n",
      "step: 56, acc: 0.906, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.0009654839488293508\n",
      "step: 57, acc: 0.938, loss: 0.280 (data_loss: 0.280, reg_loss: 0.000), lr: 0.0009654746273267938\n",
      "step: 58, acc: 0.922, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000), lr: 0.0009654653060042287\n",
      "step: 59, acc: 0.898, loss: 0.328 (data_loss: 0.328, reg_loss: 0.000), lr: 0.0009654559848616502\n",
      "step: 60, acc: 0.922, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009654466638990529\n",
      "step: 61, acc: 0.930, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.0009654373431164317\n",
      "step: 62, acc: 0.914, loss: 0.263 (data_loss: 0.263, reg_loss: 0.000), lr: 0.0009654280225137816\n",
      "step: 63, acc: 0.875, loss: 0.410 (data_loss: 0.410, reg_loss: 0.000), lr: 0.000965418702091097\n",
      "step: 64, acc: 0.883, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000), lr: 0.0009654093818483728\n",
      "step: 65, acc: 0.852, loss: 0.440 (data_loss: 0.440, reg_loss: 0.000), lr: 0.0009654000617856039\n",
      "step: 66, acc: 0.945, loss: 0.368 (data_loss: 0.368, reg_loss: 0.000), lr: 0.0009653907419027852\n",
      "step: 67, acc: 0.875, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.0009653814221999112\n",
      "step: 68, acc: 0.891, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009653721026769769\n",
      "step: 69, acc: 0.891, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.000965362783333977\n",
      "step: 70, acc: 0.922, loss: 0.277 (data_loss: 0.277, reg_loss: 0.000), lr: 0.0009653534641709062\n",
      "step: 71, acc: 0.938, loss: 0.284 (data_loss: 0.284, reg_loss: 0.000), lr: 0.0009653441451877594\n",
      "step: 72, acc: 0.938, loss: 0.280 (data_loss: 0.280, reg_loss: 0.000), lr: 0.0009653348263845314\n",
      "step: 73, acc: 0.969, loss: 0.198 (data_loss: 0.198, reg_loss: 0.000), lr: 0.0009653255077612172\n",
      "step: 74, acc: 0.906, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.000965316189317811\n",
      "step: 75, acc: 0.859, loss: 0.364 (data_loss: 0.364, reg_loss: 0.000), lr: 0.0009653068710543082\n",
      "step: 76, acc: 0.938, loss: 0.267 (data_loss: 0.267, reg_loss: 0.000), lr: 0.0009652975529707033\n",
      "step: 77, acc: 0.938, loss: 0.274 (data_loss: 0.274, reg_loss: 0.000), lr: 0.0009652882350669911\n",
      "step: 78, acc: 0.883, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.0009652789173431664\n",
      "step: 79, acc: 0.898, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.000965269599799224\n",
      "step: 80, acc: 0.883, loss: 0.371 (data_loss: 0.371, reg_loss: 0.000), lr: 0.0009652602824351587\n",
      "step: 81, acc: 0.891, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.0009652509652509653\n",
      "step: 82, acc: 0.938, loss: 0.252 (data_loss: 0.252, reg_loss: 0.000), lr: 0.0009652416482466385\n",
      "step: 83, acc: 0.859, loss: 0.412 (data_loss: 0.412, reg_loss: 0.000), lr: 0.0009652323314221733\n",
      "step: 84, acc: 0.875, loss: 0.419 (data_loss: 0.419, reg_loss: 0.000), lr: 0.0009652230147775643\n",
      "step: 85, acc: 0.898, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009652136983128064\n",
      "step: 86, acc: 0.898, loss: 0.422 (data_loss: 0.422, reg_loss: 0.000), lr: 0.0009652043820278946\n",
      "step: 87, acc: 0.906, loss: 0.325 (data_loss: 0.325, reg_loss: 0.000), lr: 0.000965195065922823\n",
      "step: 88, acc: 0.883, loss: 0.519 (data_loss: 0.519, reg_loss: 0.000), lr: 0.0009651857499975871\n",
      "step: 89, acc: 0.930, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.0009651764342521813\n",
      "step: 90, acc: 0.922, loss: 0.279 (data_loss: 0.279, reg_loss: 0.000), lr: 0.0009651671186866007\n",
      "step: 91, acc: 0.914, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000), lr: 0.0009651578033008397\n",
      "step: 92, acc: 0.914, loss: 0.285 (data_loss: 0.285, reg_loss: 0.000), lr: 0.0009651484880948933\n",
      "step: 93, acc: 0.883, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.0009651391730687566\n",
      "step: 94, acc: 0.930, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.0009651298582224238\n",
      "step: 95, acc: 0.891, loss: 0.492 (data_loss: 0.492, reg_loss: 0.000), lr: 0.00096512054355589\n",
      "step: 96, acc: 0.914, loss: 0.296 (data_loss: 0.296, reg_loss: 0.000), lr: 0.0009651112290691503\n",
      "step: 97, acc: 0.922, loss: 0.270 (data_loss: 0.270, reg_loss: 0.000), lr: 0.0009651019147621989\n",
      "step: 98, acc: 0.875, loss: 0.434 (data_loss: 0.434, reg_loss: 0.000), lr: 0.0009650926006350309\n",
      "step: 99, acc: 0.914, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.0009650832866876411\n",
      "step: 100, acc: 0.945, loss: 0.288 (data_loss: 0.288, reg_loss: 0.000), lr: 0.0009650739729200244\n",
      "step: 101, acc: 0.914, loss: 0.487 (data_loss: 0.487, reg_loss: 0.000), lr: 0.0009650646593321752\n",
      "step: 102, acc: 0.922, loss: 0.304 (data_loss: 0.304, reg_loss: 0.000), lr: 0.0009650553459240887\n",
      "step: 103, acc: 0.883, loss: 0.426 (data_loss: 0.426, reg_loss: 0.000), lr: 0.0009650460326957596\n",
      "step: 104, acc: 0.883, loss: 0.366 (data_loss: 0.366, reg_loss: 0.000), lr: 0.0009650367196471826\n",
      "step: 105, acc: 0.898, loss: 0.272 (data_loss: 0.272, reg_loss: 0.000), lr: 0.0009650274067783525\n",
      "step: 106, acc: 0.898, loss: 0.279 (data_loss: 0.279, reg_loss: 0.000), lr: 0.0009650180940892644\n",
      "step: 107, acc: 0.867, loss: 0.414 (data_loss: 0.414, reg_loss: 0.000), lr: 0.0009650087815799125\n",
      "step: 108, acc: 0.906, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.000964999469250292\n",
      "step: 109, acc: 0.922, loss: 0.300 (data_loss: 0.300, reg_loss: 0.000), lr: 0.0009649901571003975\n",
      "step: 110, acc: 0.977, loss: 0.197 (data_loss: 0.197, reg_loss: 0.000), lr: 0.0009649808451302242\n",
      "step: 111, acc: 0.883, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000), lr: 0.0009649715333397665\n",
      "step: 112, acc: 0.906, loss: 0.356 (data_loss: 0.356, reg_loss: 0.000), lr: 0.0009649622217290192\n",
      "step: 113, acc: 0.898, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009649529102979776\n",
      "step: 114, acc: 0.867, loss: 0.331 (data_loss: 0.331, reg_loss: 0.000), lr: 0.0009649435990466358\n",
      "step: 115, acc: 0.938, loss: 0.269 (data_loss: 0.269, reg_loss: 0.000), lr: 0.0009649342879749889\n",
      "step: 116, acc: 0.859, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0009649249770830317\n",
      "step: 117, acc: 0.898, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.0009649156663707592\n",
      "step: 118, acc: 0.914, loss: 0.295 (data_loss: 0.295, reg_loss: 0.000), lr: 0.0009649063558381659\n",
      "step: 119, acc: 0.922, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009648970454852467\n",
      "step: 120, acc: 0.930, loss: 0.231 (data_loss: 0.231, reg_loss: 0.000), lr: 0.0009648877353119966\n",
      "step: 121, acc: 0.883, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009648784253184099\n",
      "step: 122, acc: 0.898, loss: 0.442 (data_loss: 0.442, reg_loss: 0.000), lr: 0.0009648691155044818\n",
      "step: 123, acc: 0.875, loss: 0.471 (data_loss: 0.471, reg_loss: 0.000), lr: 0.0009648598058702071\n",
      "step: 124, acc: 0.859, loss: 0.407 (data_loss: 0.407, reg_loss: 0.000), lr: 0.0009648504964155805\n",
      "step: 125, acc: 0.883, loss: 0.291 (data_loss: 0.291, reg_loss: 0.000), lr: 0.0009648411871405967\n",
      "step: 126, acc: 0.938, loss: 0.280 (data_loss: 0.280, reg_loss: 0.000), lr: 0.0009648318780452505\n",
      "step: 127, acc: 0.914, loss: 0.293 (data_loss: 0.293, reg_loss: 0.000), lr: 0.0009648225691295372\n",
      "step: 128, acc: 0.836, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0009648132603934509\n",
      "step: 129, acc: 0.930, loss: 0.230 (data_loss: 0.230, reg_loss: 0.000), lr: 0.0009648039518369867\n",
      "step: 130, acc: 0.820, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.0009647946434601396\n",
      "step: 131, acc: 0.859, loss: 0.481 (data_loss: 0.481, reg_loss: 0.000), lr: 0.000964785335262904\n",
      "step: 132, acc: 0.922, loss: 0.317 (data_loss: 0.317, reg_loss: 0.000), lr: 0.000964776027245275\n",
      "step: 133, acc: 0.883, loss: 0.304 (data_loss: 0.304, reg_loss: 0.000), lr: 0.0009647667194072472\n",
      "step: 134, acc: 0.945, loss: 0.257 (data_loss: 0.257, reg_loss: 0.000), lr: 0.0009647574117488158\n",
      "step: 135, acc: 0.930, loss: 0.263 (data_loss: 0.263, reg_loss: 0.000), lr: 0.0009647481042699752\n",
      "step: 136, acc: 0.914, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.0009647387969707201\n",
      "step: 137, acc: 0.945, loss: 0.231 (data_loss: 0.231, reg_loss: 0.000), lr: 0.0009647294898510458\n",
      "step: 138, acc: 0.906, loss: 0.334 (data_loss: 0.334, reg_loss: 0.000), lr: 0.0009647201829109467\n",
      "step: 139, acc: 0.867, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0009647108761504176\n",
      "step: 140, acc: 0.922, loss: 0.321 (data_loss: 0.321, reg_loss: 0.000), lr: 0.0009647015695694538\n",
      "step: 141, acc: 0.898, loss: 0.398 (data_loss: 0.398, reg_loss: 0.000), lr: 0.0009646922631680495\n",
      "step: 142, acc: 0.953, loss: 0.229 (data_loss: 0.229, reg_loss: 0.000), lr: 0.0009646829569461997\n",
      "step: 143, acc: 0.938, loss: 0.268 (data_loss: 0.268, reg_loss: 0.000), lr: 0.0009646736509038991\n",
      "step: 144, acc: 0.906, loss: 0.390 (data_loss: 0.390, reg_loss: 0.000), lr: 0.000964664345041143\n",
      "step: 145, acc: 0.883, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.0009646550393579257\n",
      "step: 146, acc: 0.898, loss: 0.474 (data_loss: 0.474, reg_loss: 0.000), lr: 0.000964645733854242\n",
      "step: 147, acc: 0.836, loss: 0.452 (data_loss: 0.452, reg_loss: 0.000), lr: 0.0009646364285300871\n",
      "step: 148, acc: 0.898, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009646271233854554\n",
      "step: 149, acc: 0.938, loss: 0.246 (data_loss: 0.246, reg_loss: 0.000), lr: 0.0009646178184203418\n",
      "step: 150, acc: 0.891, loss: 0.287 (data_loss: 0.287, reg_loss: 0.000), lr: 0.0009646085136347412\n",
      "step: 151, acc: 0.898, loss: 0.274 (data_loss: 0.274, reg_loss: 0.000), lr: 0.0009645992090286486\n",
      "step: 152, acc: 0.914, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009645899046020584\n",
      "step: 153, acc: 0.891, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009645806003549656\n",
      "step: 154, acc: 0.922, loss: 0.270 (data_loss: 0.270, reg_loss: 0.000), lr: 0.0009645712962873652\n",
      "step: 155, acc: 0.938, loss: 0.275 (data_loss: 0.275, reg_loss: 0.000), lr: 0.0009645619923992516\n",
      "step: 156, acc: 0.914, loss: 0.263 (data_loss: 0.263, reg_loss: 0.000), lr: 0.0009645526886906198\n",
      "step: 157, acc: 0.891, loss: 0.350 (data_loss: 0.350, reg_loss: 0.000), lr: 0.0009645433851614647\n",
      "step: 158, acc: 0.906, loss: 0.429 (data_loss: 0.429, reg_loss: 0.000), lr: 0.0009645340818117808\n",
      "step: 159, acc: 0.914, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009645247786415633\n",
      "step: 160, acc: 0.906, loss: 0.292 (data_loss: 0.292, reg_loss: 0.000), lr: 0.0009645154756508068\n",
      "step: 161, acc: 0.883, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.0009645061728395062\n",
      "step: 162, acc: 0.922, loss: 0.382 (data_loss: 0.382, reg_loss: 0.000), lr: 0.0009644968702076562\n",
      "step: 163, acc: 0.898, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000), lr: 0.0009644875677552515\n",
      "step: 164, acc: 0.945, loss: 0.227 (data_loss: 0.227, reg_loss: 0.000), lr: 0.0009644782654822875\n",
      "step: 165, acc: 0.906, loss: 0.292 (data_loss: 0.292, reg_loss: 0.000), lr: 0.0009644689633887582\n",
      "step: 166, acc: 0.859, loss: 0.396 (data_loss: 0.396, reg_loss: 0.000), lr: 0.0009644596614746588\n",
      "step: 167, acc: 0.914, loss: 0.341 (data_loss: 0.341, reg_loss: 0.000), lr: 0.0009644503597399843\n",
      "step: 168, acc: 0.914, loss: 0.465 (data_loss: 0.465, reg_loss: 0.000), lr: 0.0009644410581847291\n",
      "step: 169, acc: 0.922, loss: 0.274 (data_loss: 0.274, reg_loss: 0.000), lr: 0.0009644317568088882\n",
      "step: 170, acc: 0.883, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.0009644224556124564\n",
      "step: 171, acc: 0.898, loss: 0.317 (data_loss: 0.317, reg_loss: 0.000), lr: 0.0009644131545954288\n",
      "step: 172, acc: 0.852, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0009644038537577996\n",
      "step: 173, acc: 0.898, loss: 0.363 (data_loss: 0.363, reg_loss: 0.000), lr: 0.000964394553099564\n",
      "step: 174, acc: 0.891, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000), lr: 0.0009643852526207171\n",
      "step: 175, acc: 0.906, loss: 0.380 (data_loss: 0.380, reg_loss: 0.000), lr: 0.000964375952321253\n",
      "step: 176, acc: 0.906, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.0009643666522011668\n",
      "step: 177, acc: 0.898, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009643573522604536\n",
      "step: 178, acc: 0.898, loss: 0.446 (data_loss: 0.446, reg_loss: 0.000), lr: 0.0009643480524991081\n",
      "step: 179, acc: 0.883, loss: 0.383 (data_loss: 0.383, reg_loss: 0.000), lr: 0.0009643387529171247\n",
      "step: 180, acc: 0.914, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.0009643294535144986\n",
      "step: 181, acc: 0.945, loss: 0.249 (data_loss: 0.249, reg_loss: 0.000), lr: 0.0009643201542912247\n",
      "step: 182, acc: 0.922, loss: 0.295 (data_loss: 0.295, reg_loss: 0.000), lr: 0.0009643108552472976\n",
      "step: 183, acc: 0.891, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000), lr: 0.000964301556382712\n",
      "step: 184, acc: 0.914, loss: 0.368 (data_loss: 0.368, reg_loss: 0.000), lr: 0.0009642922576974631\n",
      "step: 185, acc: 0.891, loss: 0.367 (data_loss: 0.367, reg_loss: 0.000), lr: 0.0009642829591915452\n",
      "step: 186, acc: 0.867, loss: 0.382 (data_loss: 0.382, reg_loss: 0.000), lr: 0.0009642736608649534\n",
      "step: 187, acc: 0.891, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009642643627176825\n",
      "step: 188, acc: 0.945, loss: 0.272 (data_loss: 0.272, reg_loss: 0.000), lr: 0.0009642550647497277\n",
      "step: 189, acc: 0.914, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000), lr: 0.000964245766961083\n",
      "step: 190, acc: 0.883, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009642364693517438\n",
      "step: 191, acc: 0.906, loss: 0.251 (data_loss: 0.251, reg_loss: 0.000), lr: 0.0009642271719217049\n",
      "step: 192, acc: 0.969, loss: 0.163 (data_loss: 0.163, reg_loss: 0.000), lr: 0.0009642178746709606\n",
      "step: 193, acc: 0.883, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009642085775995063\n",
      "step: 194, acc: 0.875, loss: 0.459 (data_loss: 0.459, reg_loss: 0.000), lr: 0.0009641992807073365\n",
      "step: 195, acc: 0.938, loss: 0.320 (data_loss: 0.320, reg_loss: 0.000), lr: 0.0009641899839944463\n",
      "step: 196, acc: 0.891, loss: 0.354 (data_loss: 0.354, reg_loss: 0.000), lr: 0.0009641806874608303\n",
      "step: 197, acc: 0.922, loss: 0.278 (data_loss: 0.278, reg_loss: 0.000), lr: 0.000964171391106483\n",
      "step: 198, acc: 0.883, loss: 0.456 (data_loss: 0.456, reg_loss: 0.000), lr: 0.0009641620949313999\n",
      "step: 199, acc: 0.945, loss: 0.276 (data_loss: 0.276, reg_loss: 0.000), lr: 0.0009641527989355754\n",
      "step: 200, acc: 0.914, loss: 0.314 (data_loss: 0.314, reg_loss: 0.000), lr: 0.0009641435031190042\n",
      "step: 201, acc: 0.859, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.0009641342074816815\n",
      "step: 202, acc: 0.883, loss: 0.364 (data_loss: 0.364, reg_loss: 0.000), lr: 0.0009641249120236018\n",
      "step: 203, acc: 0.914, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.00096411561674476\n",
      "step: 204, acc: 0.969, loss: 0.179 (data_loss: 0.179, reg_loss: 0.000), lr: 0.000964106321645151\n",
      "step: 205, acc: 0.922, loss: 0.270 (data_loss: 0.270, reg_loss: 0.000), lr: 0.0009640970267247697\n",
      "step: 206, acc: 0.852, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0009640877319836105\n",
      "step: 207, acc: 0.906, loss: 0.299 (data_loss: 0.299, reg_loss: 0.000), lr: 0.0009640784374216686\n",
      "step: 208, acc: 0.898, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000), lr: 0.0009640691430389389\n",
      "step: 209, acc: 0.883, loss: 0.469 (data_loss: 0.469, reg_loss: 0.000), lr: 0.0009640598488354158\n",
      "step: 210, acc: 0.891, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000), lr: 0.0009640505548110942\n",
      "step: 211, acc: 0.938, loss: 0.284 (data_loss: 0.284, reg_loss: 0.000), lr: 0.0009640412609659692\n",
      "step: 212, acc: 0.922, loss: 0.327 (data_loss: 0.327, reg_loss: 0.000), lr: 0.0009640319673000357\n",
      "step: 213, acc: 0.914, loss: 0.328 (data_loss: 0.328, reg_loss: 0.000), lr: 0.0009640226738132881\n",
      "step: 214, acc: 0.875, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000), lr: 0.0009640133805057214\n",
      "step: 215, acc: 0.930, loss: 0.307 (data_loss: 0.307, reg_loss: 0.000), lr: 0.0009640040873773306\n",
      "step: 216, acc: 0.891, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.0009639947944281101\n",
      "step: 217, acc: 0.922, loss: 0.315 (data_loss: 0.315, reg_loss: 0.000), lr: 0.0009639855016580549\n",
      "step: 218, acc: 0.844, loss: 0.398 (data_loss: 0.398, reg_loss: 0.000), lr: 0.0009639762090671604\n",
      "step: 219, acc: 0.883, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.0009639669166554204\n",
      "step: 220, acc: 0.914, loss: 0.297 (data_loss: 0.297, reg_loss: 0.000), lr: 0.0009639576244228304\n",
      "step: 221, acc: 0.930, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.0009639483323693849\n",
      "step: 222, acc: 0.836, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.0009639390404950792\n",
      "step: 223, acc: 0.906, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009639297487999075\n",
      "step: 224, acc: 0.875, loss: 0.309 (data_loss: 0.309, reg_loss: 0.000), lr: 0.0009639204572838649\n",
      "step: 225, acc: 0.812, loss: 0.515 (data_loss: 0.515, reg_loss: 0.000), lr: 0.0009639111659469464\n",
      "step: 226, acc: 0.867, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009639018747891465\n",
      "step: 227, acc: 0.883, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.0009638925838104602\n",
      "step: 228, acc: 0.836, loss: 0.484 (data_loss: 0.484, reg_loss: 0.000), lr: 0.0009638832930108824\n",
      "step: 229, acc: 0.898, loss: 0.395 (data_loss: 0.395, reg_loss: 0.000), lr: 0.0009638740023904075\n",
      "step: 230, acc: 0.898, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000), lr: 0.0009638647119490308\n",
      "step: 231, acc: 0.898, loss: 0.285 (data_loss: 0.285, reg_loss: 0.000), lr: 0.0009638554216867469\n",
      "step: 232, acc: 0.938, loss: 0.281 (data_loss: 0.281, reg_loss: 0.000), lr: 0.000963846131603551\n",
      "step: 233, acc: 0.914, loss: 0.392 (data_loss: 0.392, reg_loss: 0.000), lr: 0.0009638368416994372\n",
      "step: 234, acc: 0.906, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.0009638275519744008\n",
      "step: 235, acc: 0.891, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009638182624284366\n",
      "step: 236, acc: 0.898, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009638089730615392\n",
      "step: 237, acc: 0.945, loss: 0.269 (data_loss: 0.269, reg_loss: 0.000), lr: 0.0009637996838737036\n",
      "step: 238, acc: 0.922, loss: 0.252 (data_loss: 0.252, reg_loss: 0.000), lr: 0.0009637903948649247\n",
      "step: 239, acc: 0.938, loss: 0.418 (data_loss: 0.418, reg_loss: 0.000), lr: 0.0009637811060351973\n",
      "step: 240, acc: 0.906, loss: 0.270 (data_loss: 0.270, reg_loss: 0.000), lr: 0.0009637718173845161\n",
      "step: 241, acc: 0.891, loss: 0.407 (data_loss: 0.407, reg_loss: 0.000), lr: 0.0009637625289128759\n",
      "step: 242, acc: 0.930, loss: 0.242 (data_loss: 0.242, reg_loss: 0.000), lr: 0.0009637532406202717\n",
      "step: 243, acc: 0.922, loss: 0.282 (data_loss: 0.282, reg_loss: 0.000), lr: 0.0009637439525066981\n",
      "step: 244, acc: 0.898, loss: 0.339 (data_loss: 0.339, reg_loss: 0.000), lr: 0.00096373466457215\n",
      "step: 245, acc: 0.867, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0009637253768166224\n",
      "step: 246, acc: 0.938, loss: 0.263 (data_loss: 0.263, reg_loss: 0.000), lr: 0.0009637160892401099\n",
      "step: 247, acc: 0.906, loss: 0.306 (data_loss: 0.306, reg_loss: 0.000), lr: 0.0009637068018426074\n",
      "step: 248, acc: 0.883, loss: 0.386 (data_loss: 0.386, reg_loss: 0.000), lr: 0.0009636975146241097\n",
      "step: 249, acc: 0.867, loss: 0.344 (data_loss: 0.344, reg_loss: 0.000), lr: 0.0009636882275846119\n",
      "step: 250, acc: 0.883, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009636789407241084\n",
      "step: 251, acc: 0.930, loss: 0.236 (data_loss: 0.236, reg_loss: 0.000), lr: 0.0009636696540425941\n",
      "step: 252, acc: 0.922, loss: 0.275 (data_loss: 0.275, reg_loss: 0.000), lr: 0.0009636603675400642\n",
      "step: 253, acc: 0.922, loss: 0.266 (data_loss: 0.266, reg_loss: 0.000), lr: 0.0009636510812165132\n",
      "step: 254, acc: 0.891, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009636417950719358\n",
      "step: 255, acc: 0.891, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000), lr: 0.0009636325091063272\n",
      "step: 256, acc: 0.883, loss: 0.323 (data_loss: 0.323, reg_loss: 0.000), lr: 0.0009636232233196821\n",
      "step: 257, acc: 0.898, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.0009636139377119952\n",
      "step: 258, acc: 0.938, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.0009636046522832612\n",
      "step: 259, acc: 0.914, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.0009635953670334754\n",
      "step: 260, acc: 0.914, loss: 0.415 (data_loss: 0.415, reg_loss: 0.000), lr: 0.0009635860819626322\n",
      "step: 261, acc: 0.953, loss: 0.256 (data_loss: 0.256, reg_loss: 0.000), lr: 0.0009635767970707265\n",
      "step: 262, acc: 0.914, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000), lr: 0.0009635675123577534\n",
      "step: 263, acc: 0.891, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000), lr: 0.0009635582278237074\n",
      "step: 264, acc: 0.891, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009635489434685835\n",
      "step: 265, acc: 0.922, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009635396592923765\n",
      "step: 266, acc: 0.891, loss: 0.496 (data_loss: 0.496, reg_loss: 0.000), lr: 0.0009635303752950812\n",
      "step: 267, acc: 0.898, loss: 0.314 (data_loss: 0.314, reg_loss: 0.000), lr: 0.0009635210914766924\n",
      "step: 268, acc: 0.867, loss: 0.534 (data_loss: 0.534, reg_loss: 0.000), lr: 0.000963511807837205\n",
      "step: 269, acc: 0.906, loss: 0.350 (data_loss: 0.350, reg_loss: 0.000), lr: 0.000963502524376614\n",
      "step: 270, acc: 0.898, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000), lr: 0.0009634932410949137\n",
      "step: 271, acc: 0.875, loss: 0.349 (data_loss: 0.349, reg_loss: 0.000), lr: 0.0009634839579920994\n",
      "step: 272, acc: 0.883, loss: 0.364 (data_loss: 0.364, reg_loss: 0.000), lr: 0.0009634746750681657\n",
      "step: 273, acc: 0.922, loss: 0.261 (data_loss: 0.261, reg_loss: 0.000), lr: 0.0009634653923231079\n",
      "step: 274, acc: 0.898, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.00096345610975692\n",
      "step: 275, acc: 0.852, loss: 0.488 (data_loss: 0.488, reg_loss: 0.000), lr: 0.0009634468273695974\n",
      "step: 276, acc: 0.898, loss: 0.375 (data_loss: 0.375, reg_loss: 0.000), lr: 0.000963437545161135\n",
      "step: 277, acc: 0.875, loss: 0.376 (data_loss: 0.376, reg_loss: 0.000), lr: 0.0009634282631315272\n",
      "step: 278, acc: 0.930, loss: 0.289 (data_loss: 0.289, reg_loss: 0.000), lr: 0.0009634189812807692\n",
      "step: 279, acc: 0.906, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.0009634096996088558\n",
      "step: 280, acc: 0.914, loss: 0.377 (data_loss: 0.377, reg_loss: 0.000), lr: 0.0009634004181157815\n",
      "step: 281, acc: 0.914, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009633911368015414\n",
      "step: 282, acc: 0.914, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000), lr: 0.0009633818556661303\n",
      "step: 283, acc: 0.891, loss: 0.424 (data_loss: 0.424, reg_loss: 0.000), lr: 0.0009633725747095432\n",
      "step: 284, acc: 0.922, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.0009633632939317746\n",
      "step: 285, acc: 0.938, loss: 0.225 (data_loss: 0.225, reg_loss: 0.000), lr: 0.0009633540133328195\n",
      "step: 286, acc: 0.914, loss: 0.243 (data_loss: 0.243, reg_loss: 0.000), lr: 0.0009633447329126729\n",
      "step: 287, acc: 0.867, loss: 0.454 (data_loss: 0.454, reg_loss: 0.000), lr: 0.0009633354526713293\n",
      "step: 288, acc: 0.938, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.0009633261726087836\n",
      "step: 289, acc: 0.898, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.000963316892725031\n",
      "step: 290, acc: 0.906, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.0009633076130200658\n",
      "step: 291, acc: 0.883, loss: 0.369 (data_loss: 0.369, reg_loss: 0.000), lr: 0.000963298333493883\n",
      "step: 292, acc: 0.922, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000), lr: 0.0009632890541464778\n",
      "step: 293, acc: 0.930, loss: 0.231 (data_loss: 0.231, reg_loss: 0.000), lr: 0.0009632797749778446\n",
      "step: 294, acc: 0.867, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000), lr: 0.0009632704959879785\n",
      "step: 295, acc: 0.922, loss: 0.375 (data_loss: 0.375, reg_loss: 0.000), lr: 0.000963261217176874\n",
      "step: 296, acc: 0.898, loss: 0.301 (data_loss: 0.301, reg_loss: 0.000), lr: 0.0009632519385445264\n",
      "step: 297, acc: 0.891, loss: 0.416 (data_loss: 0.416, reg_loss: 0.000), lr: 0.0009632426600909302\n",
      "step: 298, acc: 0.930, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000), lr: 0.0009632333818160802\n",
      "step: 299, acc: 0.945, loss: 0.249 (data_loss: 0.249, reg_loss: 0.000), lr: 0.0009632241037199714\n",
      "step: 300, acc: 0.906, loss: 0.348 (data_loss: 0.348, reg_loss: 0.000), lr: 0.0009632148258025988\n",
      "step: 301, acc: 0.898, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.0009632055480639569\n",
      "step: 302, acc: 0.922, loss: 0.340 (data_loss: 0.340, reg_loss: 0.000), lr: 0.0009631962705040405\n",
      "step: 303, acc: 0.898, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.000963186993122845\n",
      "step: 304, acc: 0.945, loss: 0.291 (data_loss: 0.291, reg_loss: 0.000), lr: 0.0009631777159203645\n",
      "step: 305, acc: 0.891, loss: 0.334 (data_loss: 0.334, reg_loss: 0.000), lr: 0.0009631684388965942\n",
      "step: 306, acc: 0.930, loss: 0.347 (data_loss: 0.347, reg_loss: 0.000), lr: 0.000963159162051529\n",
      "step: 307, acc: 0.930, loss: 0.258 (data_loss: 0.258, reg_loss: 0.000), lr: 0.0009631498853851637\n",
      "step: 308, acc: 0.891, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.0009631406088974929\n",
      "step: 309, acc: 0.891, loss: 0.393 (data_loss: 0.393, reg_loss: 0.000), lr: 0.0009631313325885117\n",
      "step: 310, acc: 0.922, loss: 0.282 (data_loss: 0.282, reg_loss: 0.000), lr: 0.000963122056458215\n",
      "step: 311, acc: 0.898, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009631127805065973\n",
      "step: 312, acc: 0.867, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000), lr: 0.0009631035047336537\n",
      "step: 313, acc: 0.883, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000), lr: 0.0009630942291393791\n",
      "step: 314, acc: 0.930, loss: 0.243 (data_loss: 0.243, reg_loss: 0.000), lr: 0.000963084953723768\n",
      "step: 315, acc: 0.906, loss: 0.325 (data_loss: 0.325, reg_loss: 0.000), lr: 0.0009630756784868154\n",
      "step: 316, acc: 0.914, loss: 0.251 (data_loss: 0.251, reg_loss: 0.000), lr: 0.0009630664034285163\n",
      "step: 317, acc: 0.930, loss: 0.255 (data_loss: 0.255, reg_loss: 0.000), lr: 0.0009630571285488656\n",
      "step: 318, acc: 0.922, loss: 0.299 (data_loss: 0.299, reg_loss: 0.000), lr: 0.0009630478538478577\n",
      "step: 319, acc: 0.922, loss: 0.282 (data_loss: 0.282, reg_loss: 0.000), lr: 0.0009630385793254878\n",
      "step: 320, acc: 0.906, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009630293049817507\n",
      "step: 321, acc: 0.906, loss: 0.363 (data_loss: 0.363, reg_loss: 0.000), lr: 0.000963020030816641\n",
      "step: 322, acc: 0.891, loss: 0.346 (data_loss: 0.346, reg_loss: 0.000), lr: 0.0009630107568301537\n",
      "step: 323, acc: 0.906, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.000963001483022284\n",
      "step: 324, acc: 0.891, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.000962992209393026\n",
      "step: 325, acc: 0.898, loss: 0.417 (data_loss: 0.417, reg_loss: 0.000), lr: 0.0009629829359423751\n",
      "step: 326, acc: 0.906, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.0009629736626703259\n",
      "step: 327, acc: 0.883, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.0009629643895768734\n",
      "step: 328, acc: 0.898, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0009629551166620124\n",
      "step: 329, acc: 0.914, loss: 0.271 (data_loss: 0.271, reg_loss: 0.000), lr: 0.0009629458439257376\n",
      "step: 330, acc: 0.930, loss: 0.300 (data_loss: 0.300, reg_loss: 0.000), lr: 0.0009629365713680441\n",
      "step: 331, acc: 0.898, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009629272989889264\n",
      "step: 332, acc: 0.906, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.0009629180267883795\n",
      "step: 333, acc: 0.922, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000), lr: 0.0009629087547663983\n",
      "step: 334, acc: 0.891, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000), lr: 0.0009628994829229777\n",
      "step: 335, acc: 0.938, loss: 0.268 (data_loss: 0.268, reg_loss: 0.000), lr: 0.0009628902112581123\n",
      "step: 336, acc: 0.930, loss: 0.261 (data_loss: 0.261, reg_loss: 0.000), lr: 0.0009628809397717971\n",
      "step: 337, acc: 0.914, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.0009628716684640272\n",
      "step: 338, acc: 0.938, loss: 0.203 (data_loss: 0.203, reg_loss: 0.000), lr: 0.0009628623973347969\n",
      "step: 339, acc: 0.883, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.0009628531263841014\n",
      "step: 340, acc: 0.930, loss: 0.249 (data_loss: 0.249, reg_loss: 0.000), lr: 0.0009628438556119356\n",
      "step: 341, acc: 0.844, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000), lr: 0.0009628345850182939\n",
      "step: 342, acc: 0.906, loss: 0.332 (data_loss: 0.332, reg_loss: 0.000), lr: 0.0009628253146031716\n",
      "step: 343, acc: 0.891, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.0009628160443665632\n",
      "step: 344, acc: 0.898, loss: 0.376 (data_loss: 0.376, reg_loss: 0.000), lr: 0.0009628067743084641\n",
      "step: 345, acc: 0.906, loss: 0.341 (data_loss: 0.341, reg_loss: 0.000), lr: 0.0009627975044288685\n",
      "step: 346, acc: 0.883, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.0009627882347277715\n",
      "step: 347, acc: 0.945, loss: 0.225 (data_loss: 0.225, reg_loss: 0.000), lr: 0.0009627789652051682\n",
      "step: 348, acc: 0.867, loss: 0.433 (data_loss: 0.433, reg_loss: 0.000), lr: 0.0009627696958610532\n",
      "step: 349, acc: 0.883, loss: 0.360 (data_loss: 0.360, reg_loss: 0.000), lr: 0.0009627604266954211\n",
      "step: 350, acc: 0.859, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000), lr: 0.0009627511577082673\n",
      "step: 351, acc: 0.914, loss: 0.271 (data_loss: 0.271, reg_loss: 0.000), lr: 0.000962741888899586\n",
      "step: 352, acc: 0.914, loss: 0.321 (data_loss: 0.321, reg_loss: 0.000), lr: 0.0009627326202693725\n",
      "step: 353, acc: 0.891, loss: 0.378 (data_loss: 0.378, reg_loss: 0.000), lr: 0.0009627233518176217\n",
      "step: 354, acc: 0.922, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.0009627140835443282\n",
      "step: 355, acc: 0.930, loss: 0.282 (data_loss: 0.282, reg_loss: 0.000), lr: 0.0009627048154494869\n",
      "step: 356, acc: 0.891, loss: 0.400 (data_loss: 0.400, reg_loss: 0.000), lr: 0.0009626955475330926\n",
      "step: 357, acc: 0.922, loss: 0.270 (data_loss: 0.270, reg_loss: 0.000), lr: 0.0009626862797951404\n",
      "step: 358, acc: 0.914, loss: 0.293 (data_loss: 0.293, reg_loss: 0.000), lr: 0.0009626770122356248\n",
      "step: 359, acc: 0.922, loss: 0.246 (data_loss: 0.246, reg_loss: 0.000), lr: 0.0009626677448545408\n",
      "step: 360, acc: 0.875, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000), lr: 0.0009626584776518835\n",
      "step: 361, acc: 0.938, loss: 0.304 (data_loss: 0.304, reg_loss: 0.000), lr: 0.0009626492106276474\n",
      "step: 362, acc: 0.938, loss: 0.246 (data_loss: 0.246, reg_loss: 0.000), lr: 0.0009626399437818273\n",
      "step: 363, acc: 0.859, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000), lr: 0.0009626306771144182\n",
      "step: 364, acc: 0.875, loss: 0.415 (data_loss: 0.415, reg_loss: 0.000), lr: 0.0009626214106254152\n",
      "step: 365, acc: 0.883, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0009626121443148127\n",
      "step: 366, acc: 0.859, loss: 0.353 (data_loss: 0.353, reg_loss: 0.000), lr: 0.0009626028781826057\n",
      "step: 367, acc: 0.945, loss: 0.214 (data_loss: 0.214, reg_loss: 0.000), lr: 0.0009625936122287891\n",
      "step: 368, acc: 0.898, loss: 0.335 (data_loss: 0.335, reg_loss: 0.000), lr: 0.000962584346453358\n",
      "step: 369, acc: 0.922, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.0009625750808563067\n",
      "step: 370, acc: 0.883, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.0009625658154376305\n",
      "step: 371, acc: 0.922, loss: 0.308 (data_loss: 0.308, reg_loss: 0.000), lr: 0.0009625565501973242\n",
      "step: 372, acc: 0.938, loss: 0.258 (data_loss: 0.258, reg_loss: 0.000), lr: 0.0009625472851353822\n",
      "step: 373, acc: 0.938, loss: 0.244 (data_loss: 0.244, reg_loss: 0.000), lr: 0.0009625380202517999\n",
      "step: 374, acc: 0.930, loss: 0.256 (data_loss: 0.256, reg_loss: 0.000), lr: 0.0009625287555465721\n",
      "step: 375, acc: 0.914, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000), lr: 0.0009625194910196931\n",
      "step: 376, acc: 0.906, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.0009625102266711584\n",
      "step: 377, acc: 0.930, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000), lr: 0.0009625009625009624\n",
      "step: 378, acc: 0.898, loss: 0.280 (data_loss: 0.280, reg_loss: 0.000), lr: 0.0009624916985091005\n",
      "step: 379, acc: 0.883, loss: 0.341 (data_loss: 0.341, reg_loss: 0.000), lr: 0.0009624824346955668\n",
      "step: 380, acc: 0.922, loss: 0.379 (data_loss: 0.379, reg_loss: 0.000), lr: 0.0009624731710603566\n",
      "step: 381, acc: 0.906, loss: 0.325 (data_loss: 0.325, reg_loss: 0.000), lr: 0.0009624639076034649\n",
      "step: 382, acc: 0.938, loss: 0.290 (data_loss: 0.290, reg_loss: 0.000), lr: 0.0009624546443248863\n",
      "step: 383, acc: 0.906, loss: 0.351 (data_loss: 0.351, reg_loss: 0.000), lr: 0.0009624453812246155\n",
      "step: 384, acc: 0.906, loss: 0.336 (data_loss: 0.336, reg_loss: 0.000), lr: 0.0009624361183026477\n",
      "step: 385, acc: 0.922, loss: 0.266 (data_loss: 0.266, reg_loss: 0.000), lr: 0.0009624268555589776\n",
      "step: 386, acc: 0.867, loss: 0.376 (data_loss: 0.376, reg_loss: 0.000), lr: 0.0009624175929935999\n",
      "step: 387, acc: 0.930, loss: 0.240 (data_loss: 0.240, reg_loss: 0.000), lr: 0.0009624083306065097\n",
      "step: 388, acc: 0.891, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000), lr: 0.0009623990683977018\n",
      "step: 389, acc: 0.906, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000), lr: 0.000962389806367171\n",
      "step: 390, acc: 0.925, loss: 0.200 (data_loss: 0.200, reg_loss: 0.000), lr: 0.0009623805445149121\n",
      "training, acc: 0.905, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.0009623805445149121\n",
      "validation, acc: 0.908, loss: 0.325\n"
     ]
    }
   ],
   "source": [
    "model.train(data.X_train, data.y_train, validation_data=(data.X_test, data.y_test), epochs=10, batch_size=128, print_every=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T14:34:56.000039600Z",
     "start_time": "2023-11-19T14:34:08.221036600Z"
    }
   },
   "id": "3acedb0d8084f911"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification report"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "219a2df573109d0d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       980\n",
      "           1       0.95      0.97      0.96      1135\n",
      "           2       0.92      0.87      0.89      1032\n",
      "           3       0.90      0.89      0.89      1010\n",
      "           4       0.91      0.92      0.91       982\n",
      "           5       0.87      0.87      0.87       892\n",
      "           6       0.92      0.94      0.93       958\n",
      "           7       0.93      0.90      0.91      1028\n",
      "           8       0.86      0.87      0.87       974\n",
      "           9       0.89      0.88      0.89      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(data.X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = data.y_test\n",
    "\n",
    "report = classification_report(y_true, y_pred_classes, target_names=[str(i) for i in range(10)])\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T14:35:02.012254900Z",
     "start_time": "2023-11-19T14:35:01.876416600Z"
    }
   },
   "id": "4f6ff1b904b70ebd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning Curves\n",
    "### Plot the learning curves to evaluate the training process.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "203dedeab31d45de"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(model):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(model.train_acc_history, label='Training Accuracy')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(model.train_loss_history, label='Training Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T14:35:04.584906Z",
     "start_time": "2023-11-19T14:35:04.114857400Z"
    }
   },
   "id": "39b3a192c5e6ab28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Latent features visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe830346dead8935"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Layer_Dense.forward() missing 1 required positional argument: 'training'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m example_indices \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(data\u001B[38;5;241m.\u001B[39mX_test)), \u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m      2\u001B[0m examples \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mX_test[example_indices]\n\u001B[1;32m----> 4\u001B[0m activations \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_activations\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexamples\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NeuralNetworksLab1\\models\\model.py:436\u001B[0m, in \u001B[0;36mModel.get_activations\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    433\u001B[0m input_data \u001B[38;5;241m=\u001B[39m X\n\u001B[0;32m    435\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m--> 436\u001B[0m     \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    437\u001B[0m     activations\u001B[38;5;241m.\u001B[39mappend(layer\u001B[38;5;241m.\u001B[39moutput)\n\u001B[0;32m    438\u001B[0m     input_data \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39moutput\n",
      "\u001B[1;31mTypeError\u001B[0m: Layer_Dense.forward() missing 1 required positional argument: 'training'"
     ]
    }
   ],
   "source": [
    "example_indices = np.random.choice(range(len(data.X_test)), 10)\n",
    "examples = data.X_test[example_indices]\n",
    "\n",
    "activations = model.get_activations(examples)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T14:35:07.281632100Z",
     "start_time": "2023-11-19T14:35:06.732070200Z"
    }
   },
   "id": "fb72e844457e4e03"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "for i, activation in enumerate(activations):\n",
    "    plt.figure(figsize=(10, 1))\n",
    "    sns.heatmap(activation, cmap=\"viridis\", yticklabels=False)\n",
    "    plt.title(f\"Layer {i+1} Activation\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:23:30.153528700Z"
    }
   },
   "id": "95e4c77849fc1baa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "weights = model.get_weights()\n",
    "biases = model.get_biases()\n",
    "\n",
    "num_layers = len(weights)\n",
    "\n",
    "fig, axes = plt.subplots(num_layers, 2, figsize=(12, num_layers * 4))\n",
    "\n",
    "for i in range(num_layers):\n",
    "    ax = axes[i, 0]\n",
    "    sns.heatmap(weights[i], ax=ax, cmap=\"viridis\")\n",
    "    ax.set_title(f'Layer {i+1} Weights')\n",
    "\n",
    "    ax = axes[i, 1]\n",
    "    sns.heatmap(biases[i].reshape(1, -1), ax=ax, cmap=\"viridis\")\n",
    "    ax.set_title(f'Layer {i+1} Biases')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:23:30.153528700Z"
    }
   },
   "id": "dbadf898bbf1714b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter search using grid search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11463232fed04e6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning_rates = [1e-2, 1e-3, 1e-4]\n",
    "batch_sizes = [32, 64, 128]\n",
    "epochs_options = [5, 10, 20]\n",
    "\n",
    "best_hyperparams = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for epochs in epochs_options:\n",
    "\n",
    "            model = Model()\n",
    "            model.add(Layer_Dense(1600, 128)) \n",
    "            model.add(Activation_ReLU())\n",
    "            model.add(Layer_Dense(128, 10)) \n",
    "            model.add(Activation_Softmax())\n",
    "            model.set(\n",
    "                loss=Loss_CategoricalCrossentropy(),\n",
    "                optimizer=Optimizer_Adam(learning_rate=learning_rate),\n",
    "                accuracy=Accuracy_Categorical()\n",
    "            )\n",
    "            model.finalize()\n",
    "\n",
    "            model.train(data.X_train, data.y_train, validation_data=(data.X_test, data.y_test), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "            validation_loss, validation_accuracy = model.evaluate(data.X_test, data.y_test)\n",
    "\n",
    "            if validation_accuracy > best_accuracy:\n",
    "                best_accuracy = validation_accuracy\n",
    "                best_hyperparams = {'learning_rate': learning_rate, 'batch_size': batch_size, 'epochs': epochs}\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hyperparams)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:23:30.153528700Z"
    }
   },
   "id": "252e9277ca871036"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Measuring impact of neural network dimensionality"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1d6b37f88499a26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "layer_options = [1, 2, 3]\n",
    "layer_results = []\n",
    "\n",
    "for num_layers in layer_options:\n",
    "    model = Model()\n",
    "\n",
    "    model.add(Layer_Dense(1600, 32)) \n",
    "    model.add(Activation_ReLU())\n",
    "\n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Layer_Dense(32, 32)) \n",
    "        model.add(Activation_ReLU())\n",
    "\n",
    "    model.add(Layer_Dense(32, 10)) \n",
    "    model.add(Activation_Softmax())\n",
    "\n",
    "    model.set(\n",
    "        loss=Loss_CategoricalCrossentropy(),\n",
    "        optimizer=Optimizer_Adam(learning_rate=learning_rate),\n",
    "        accuracy=Accuracy_Categorical()\n",
    "    )\n",
    "    model.finalize()\n",
    "\n",
    "    model.train(data.X_train, data.y_train, validation_data=(data.X_test, data.y_test), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    validation_loss, validation_accuracy = model.evaluate(data.X_test, data.y_test)\n",
    "\n",
    "    layer_results.append({\n",
    "        'num_layers': num_layers,\n",
    "        'loss': validation_loss,\n",
    "        'accuracy': validation_accuracy\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:23:30.165045400Z"
    }
   },
   "id": "d9a98eec2508086"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_layers_list = [result['num_layers'] for result in layer_results]\n",
    "losses = [result['loss'] for result in layer_results]\n",
    "accuracies = [result['accuracy'] for result in layer_results]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(num_layers_list, losses, marker='o')\n",
    "plt.title('Validation Loss vs. Number of Layers')\n",
    "plt.xlabel('Number of Layers')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(num_layers_list, accuracies, marker='o')\n",
    "plt.title('Validation Accuracy vs. Number of Layers')\n",
    "plt.xlabel('Number of Layers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:23:30.168107200Z"
    }
   },
   "id": "32fdf1db01ecd63c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:23:30.168107200Z"
    }
   },
   "id": "f7b58f8eed74dc00"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
